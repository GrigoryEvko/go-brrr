% Part VIII: Security Analysis - Information Flow and Taint
% Fragment file - no \documentclass or \begin{document}

\part{Security Analysis --- Information Flow and Taint}
\label{part:security-analysis}

\begin{warningbox}[title={Effect Absence Enables Zero False-Positive Detection}]
\textbf{Source}: \textbf{[Leijen14]} (Koka), Theorems 2--4 --- See Section 12.27

\textbf{Critical Insight}: Effect inference provides \emph{mathematically proven} safety. If an effect is \textbf{absent} from the inferred effect row, the corresponding bug class is \textbf{impossible}---not just unlikely, but provably cannot occur.

\textbf{Effect-Based Bug Classification}:
\begin{center}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Condition} & \textbf{Guarantee} \\
\midrule
$\mathtt{exn} \notin \mathit{effects}$ & \textbf{Proven exception-safe} (Theorem 12.27.1) \\
                                       & No unhandled exceptions possible---0\% false positive \\
\addlinespace
$\mathtt{div} \notin \mathit{effects}$ & \textbf{Proven terminating} (Theorem 12.27.2) \\
                                       & Guaranteed to halt---no infinite loops possible \\
\addlinespace
$\mathtt{st}\langle h \rangle \notin \mathit{effects}$ & \textbf{Proven heap-isolated} (Theorem 12.27.3) \\
                                       & Cannot modify/observe heap $h$---state encapsulated \\
\addlinespace
$\mathtt{IO} \notin \mathit{effects}$ & \textbf{Proven no external I/O} \\
                                       & Taint cannot exfiltrate via I/O sinks \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Application to Taint Analysis}: Effect absence \emph{strengthens} taint findings by eliminating false positives:
\begin{itemize}
\item Exception sinks unreachable if $\mathtt{exn} \notin \mathit{effects}$
\item Heap-based taint flows impossible if $\mathtt{st}\langle h \rangle \notin \mathit{effects}$
\item External data exfiltration impossible if $\mathtt{IO} \notin \mathit{effects}$
\end{itemize}

\textbf{Integration}: Use effect inference \emph{before} taint analysis to prune impossible flows. Remaining flows have higher true-positive rate.

\textbf{Cross-references}: Section 12.27 for effect absence theorems and proofs; Section 12.34 for robust declassification theorems; Section 6.1.3 for effect row definitions.
\end{warningbox}

%==================================================
\chapter{Information Flow and Taint Analysis}
\label{chap:information-flow-taint}
%==================================================

\begin{pillarbox}[title={Foundational Papers}]
\textbf{[Denning77]}, \textbf{[Livshits05]}, \textbf{[Tripp09]}
\end{pillarbox}

Security vulnerabilities are fundamentally about improper information flow: untrusted data reaching sensitive operations without proper validation.

%--------------------------------------------------
\section{Denning's Lattice Model}
\label{sec:denning-lattice}
%--------------------------------------------------

\begin{definition}[Security Lattice \textbf{[Denning77]}]
Security levels form a \emph{lattice}:
\begin{center}
\begin{tikzpicture}[node distance=1.5cm]
\node (top) {$\top$ (most secret)};
\node (secret) [below left=of top] {SECRET};
\node (private) [below right=of top] {PRIVATE};
\node (public) [below right=of secret] {PUBLIC};
\node (bottom) [below=of public] {$\bot$ (least secret)};
\draw (top) -- (secret);
\draw (top) -- (private);
\draw (secret) -- (public);
\draw (private) -- (public);
\draw (public) -- (bottom);
\end{tikzpicture}
\end{center}
\end{definition}

\begin{definition}[Information Flow Rule]
Information can flow from level $L_1$ to level $L_2$ \emph{only if} $L_1 \sqsubseteq L_2$ ($L_1$ is below or equal to $L_2$):
\begin{itemize}
\item[$\checkmark$] $\mathsf{PUBLIC} \to \mathsf{SECRET}$ (upgrading is safe)
\item[$\times$] $\mathsf{SECRET} \to \mathsf{PUBLIC}$ (leaking is dangerous)
\end{itemize}
\end{definition}

\subsection{Taint Mapping}

For taint analysis, we assign:
\begin{align*}
\mathsf{UNTAINTED} &= \text{safe} = \text{low security} \\
\mathsf{TAINTED} &= \text{dangerous} = \text{high security}
\end{align*}
Improper flow: $\mathsf{TAINTED} \to \mathit{sensitive\_operation}$

\subsection{The 4-Point Lattice with Integrity}

Denning's original model tracks only \textbf{confidentiality} (secrecy). For robust declassification (Section~\ref{sec:declassification}, Section 12.34), we need \textbf{integrity} too.

\begin{definition}[Confidentiality and Integrity]
\begin{itemize}
\item \textbf{Confidentiality}: Can the adversary \emph{observe} this data?
  \begin{itemize}
  \item $C_{\mathsf{Low}}$ = Public (adversary can observe)
  \item $C_{\mathsf{High}}$ = Secret (adversary cannot observe)
  \end{itemize}
\item \textbf{Integrity}: Can the adversary \emph{influence} this data?
  \begin{itemize}
  \item $I_{\mathsf{Low}}$ = Untrusted (adversary can control)
  \item $I_{\mathsf{High}}$ = Trusted (adversary cannot control)
  \end{itemize}
\end{itemize}
\end{definition}

\begin{definition}[4-Point Product Lattice]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
\node (hi-hi) {$(C_{\mathsf{High}}, I_{\mathsf{High}})$};
\node (hi-lo) [below left=of hi-hi] {$(C_{\mathsf{High}}, I_{\mathsf{Low}})$};
\node (lo-hi) [below right=of hi-hi] {$(C_{\mathsf{Low}}, I_{\mathsf{High}})$};
\node (lo-lo) [below right=of hi-lo] {$(C_{\mathsf{Low}}, I_{\mathsf{Low}})$};
\draw (hi-hi) -- (hi-lo);
\draw (hi-hi) -- (lo-hi);
\draw (hi-lo) -- (lo-lo);
\draw (lo-hi) -- (lo-lo);
\end{tikzpicture}
\end{center}
Where:
\begin{itemize}
\item $(C_{\mathsf{High}}, I_{\mathsf{High}})$: Secret and Trusted (e.g., system password)
\item $(C_{\mathsf{High}}, I_{\mathsf{Low}})$: Secret but Untrusted
\item $(C_{\mathsf{Low}}, I_{\mathsf{High}})$: Public and Trusted
\item $(C_{\mathsf{Low}}, I_{\mathsf{Low}})$: Public and Untrusted (adversary-controlled input)
\end{itemize}

\textbf{Ordering}: $(c_1, i_1) \sqsubseteq (c_2, i_2)$ iff $c_1 \sqsubseteq_C c_2$ \textbf{and} $i_1 \sqsupseteq_I i_2$

Note: Integrity ordering is \emph{inverted} (higher integrity = lower risk).
\end{definition}

\begin{warningbox}[title={Why Integrity Matters}]
For \textbf{robust declassification} (Section~\ref{sec:declassification}), we must ensure:
\begin{itemize}
\item Adversary cannot control \emph{which} secret gets declassified
\item Adversary cannot influence the \emph{value} being declassified
\end{itemize}
This requires tracking integrity of control flow and data dependencies.
\end{warningbox}

\textbf{Mapping Taint to 4-Point Lattice}:
\begin{itemize}
\item Taint source (user input) $\Rightarrow \{ \mathit{conf} = C_{\mathsf{Low}}; \mathit{integ} = I_{\mathsf{Low}} \}$
\item Secret source (password) $\Rightarrow \{ \mathit{conf} = C_{\mathsf{High}}; \mathit{integ} = I_{\mathsf{High}} \}$
\item Public constant $\Rightarrow \{ \mathit{conf} = C_{\mathsf{Low}}; \mathit{integ} = I_{\mathsf{High}} \}$
\end{itemize}

Cross-reference: Section 12.34 for complete formalization and theorems.

%--------------------------------------------------
\section{The Taint Analysis Framework}
\label{sec:taint-framework}
%--------------------------------------------------

The taint analysis framework provides the core infrastructure for tracking untrusted data as it flows through a program. The following F* code defines the fundamental types used throughout the analysis:

\begin{itemize}
\item \textbf{Taint sources} represent entry points where untrusted data enters the system (HTTP parameters, environment variables, file reads, etc.)
\item \textbf{Taint sinks} represent sensitive operations where untrusted data could cause harm (SQL queries, shell commands, HTML output, etc.)
\item \textbf{Sanitizers} represent functions that transform untrusted data into safe values for specific contexts
\end{itemize}

The types are designed to be language-agnostic, supporting analysis across Python, JavaScript, Go, Rust, and other languages in the brrr-machine framework.

\begin{fstarcode}[title={Taint Analysis Core Types}]
(* ==================================================
   TAINT ANALYSIS
   Sources: Denning 1977, Livshits 2005, Tripp 2009
   ================================================== *)
module BrrrMachine.Security.Taint

(* --------------------------------------------------
   TAINT SOURCES --- Where untrusted data enters
   -------------------------------------------------- *)
type taint_source =
  (* User input *)
  | SrcHttpParam : param:string -> taint_source
  | SrcHttpHeader : header:string -> taint_source
  | SrcHttpBody : taint_source
  | SrcCookie : name:string -> taint_source
  | SrcUrlPath : taint_source
  (* Environment *)
  | SrcEnvVar : var:string -> taint_source
  | SrcCommandArg : index:nat -> taint_source
  | SrcStdin : taint_source
  (* External data *)
  | SrcFileRead : taint_source
  | SrcNetworkRead : taint_source
  | SrcDatabaseRead : taint_source
  | SrcDeserialize : format:string -> taint_source
  (* Language-specific *)
  | SrcEval : taint_source  (* JS eval, Python exec *)
  | SrcReflection : taint_source
\end{fstarcode}

\begin{fstarcode}[title={Taint Sinks --- Where Tainted Data is Dangerous}]
type taint_sink =
  (* Injection vulnerabilities *)
  | SinkSqlQuery : taint_sink
  | SinkSqlParam : taint_sink
  | SinkShellCommand : taint_sink
  | SinkShellArg : taint_sink
  | SinkLdapQuery : taint_sink
  | SinkXPathQuery : taint_sink
  | SinkRegexPattern : taint_sink
  (* XSS *)
  | SinkHtmlOutput : taint_sink
  | SinkHtmlAttribute : taint_sink
  | SinkJavaScript : taint_sink
  | SinkCssValue : taint_sink
  (* Path traversal *)
  | SinkFilePath : taint_sink
  | SinkFileOpen : taint_sink
  (* Deserialization *)
  | SinkDeserialize : format:string -> taint_sink
  | SinkYamlLoad : taint_sink
  | SinkPickle : taint_sink
  (* Code execution *)
  | SinkEval : taint_sink
  | SinkExec : taint_sink
  | SinkReflection : taint_sink
  (* Sensitive data exposure *)
  | SinkLog : taint_sink
  | SinkHttpResponse : taint_sink
  | SinkErrorMessage : taint_sink
  (* SSRF *)
  | SinkHttpRequest : taint_sink
  | SinkUrlFetch : taint_sink
\end{fstarcode}

\begin{fstarcode}[title={Sanitizers --- Functions that Make Tainted Data Safe}]
(* CRITICAL DISTINCTION (see Section 8.1.4.3, 12.34.9):
   - Sanitizer: Changes VALUE, preserves LABEL (e.g., HTML escape)
   - Declassification: Preserves VALUE, changes LABEL (policy decision)

   Both may be needed: sanitize to prevent injection, declassify to
   allow controlled observation of secrets. *)

type sanitizer =
  | SanHtmlEscape : sanitizer
  | SanUrlEncode : sanitizer
  | SanSqlEscape : sanitizer
  | SanSqlParameterize : sanitizer
  | SanShellEscape : sanitizer
  | SanPathCanonicalize : sanitizer
  | SanInputValidation : pattern:string -> sanitizer
  | SanTypeCheck : expected:string -> sanitizer
  | SanLengthCheck : max_len:nat -> sanitizer
  | SanWhitelist : allowed:list string -> sanitizer
  | SanCustom : name:string -> sanitizer

(* Which sinks does a sanitizer protect? *)
let sanitizer_protects (san : sanitizer) (sink : taint_sink) : bool =
  match san, sink with
  | SanHtmlEscape, (SinkHtmlOutput | SinkHtmlAttribute) -> true
  | SanSqlEscape, (SinkSqlQuery | SinkSqlParam) -> true
  | SanSqlParameterize, (SinkSqlQuery | SinkSqlParam) -> true
  | SanShellEscape, (SinkShellCommand | SinkShellArg) -> true
  | SanUrlEncode, SinkHttpRequest -> true
  | SanPathCanonicalize, (SinkFilePath | SinkFileOpen) -> true
  | SanInputValidation _, _ -> true  (* Depends on pattern *)
  | _, _ -> false
\end{fstarcode}

\begin{fstarcode}[title={Vulnerability Types and Analysis Results}]
type vulnerability_type =
  | VulnSqlInjection
  | VulnCommandInjection
  | VulnXss
  | VulnPathTraversal
  | VulnSsrf
  | VulnDeserializationRce
  | VulnLdapInjection
  | VulnXPathInjection
  | VulnLogInjection
  | VulnReDoS
  | VulnOpenRedirect
  | VulnHeaderInjection
  | VulnTemplateInjection

let sink_to_vuln (sink : taint_sink) : vulnerability_type =
  match sink with
  | SinkSqlQuery | SinkSqlParam -> VulnSqlInjection
  | SinkShellCommand | SinkShellArg -> VulnCommandInjection
  | SinkHtmlOutput | SinkHtmlAttribute | SinkJavaScript -> VulnXss
  | SinkFilePath | SinkFileOpen -> VulnPathTraversal
  | SinkHttpRequest | SinkUrlFetch -> VulnSsrf
  | SinkDeserialize _ | SinkYamlLoad | SinkPickle -> VulnDeserializationRce
  | SinkLdapQuery -> VulnLdapInjection
  | SinkXPathQuery -> VulnXPathInjection
  | SinkLog -> VulnLogInjection
  | SinkRegexPattern -> VulnReDoS
  | SinkEval | SinkExec -> VulnCommandInjection
  | _ -> VulnXss  (* Default *)

type taint_flow = {
  source : taint_source;
  source_location : node_id;
  sink : taint_sink;
  sink_location : node_id;
  path : list node_id;  (* Nodes on the taint path *)
  vuln_type : vulnerability_type;
  confidence : float;  (* 0.0 - 1.0, LEGACY - see Section 12.3 for Manifest/Latent *)
}

type taint_analysis_result = {
  flows : list taint_flow;
  source_count : nat;
  sink_count : nat;
  sanitizer_count : nat;
}
\end{fstarcode}

The taint analysis is formulated as an IFDS problem (see Section 4.1 for the IFDS framework). The key insight is that taint facts form a finite set (at most one fact per variable/access path), making the analysis tractable. The flow function propagates taint through assignments, kills taint at sanitizers, and generates taint at sources.

\begin{fstarcode}[title={Taint Analysis via IFDS}]
val run_taint_analysis :
  cpg ->
  sources:(node_id -> option taint_source) ->
  sinks:(node_id -> option taint_sink) ->
  sanitizers:(node_id -> option sanitizer) ->
  taint_analysis_result

let run_taint_analysis cpg sources sinks sanitizers =
  (* Build IFDS problem *)
  let problem = {
    supergraph = cpg;
    domain = (* all taint facts *);
    zero = TaintZero;
    flow_function = fun edge d ->
      let n = edge.source in
      (* Check for source *)
      begin match sources n with
      | Some src ->
          let var = get_assigned_var cpg n in
          Set.add (TaintedVar var src) (Set.singleton d)
      | None -> Set.singleton d
      end
      |>
      (* Check for sanitizer *)
      begin match sanitizers n with
      | Some san ->
          Set.filter (fun t -> not (sanitizes san t))
      | None -> identity
      end
      |>
      (* Propagate through assignments *)
      propagate_taint cpg n;
    (* ... call/return flows ... *)
  } in
  (* Solve IFDS *)
  let solution = solve problem in
  (* Check for tainted values at sinks *)
  let flows = ref [] in
  Map.iter (fun node facts ->
    match sinks node with
    | Some sink ->
        Set.iter (fun fact ->
          match fact with
          | TaintedVar var src ->
              flows := {
                source = src;
                source_location = 0; (* TODO: track *)
                sink = sink;
                sink_location = node;
                path = []; (* TODO: reconstruct *)
                vuln_type = sink_to_vuln sink;
                confidence = 1.0;
              } :: !flows
          | _ -> ()
        ) facts
    | None -> ()
  ) solution;
  { flows = !flows;
    source_count = count_sources cpg sources;
    sink_count = count_sinks cpg sinks;
    sanitizer_count = count_sanitizers cpg sanitizers }
\end{fstarcode}

%--------------------------------------------------
\section{Hybrid Thin Slicing}
\label{sec:thin-slicing}
%--------------------------------------------------

\begin{pillarbox}[title={TAJ Insight \textbf{[Tripp09]}}]
Full taint analysis is expensive. Most paths are irrelevant. \textbf{Thin slicing}: Only follow dependencies that are \emph{relevant} to the sink.
\end{pillarbox}

\textbf{Example}:
\begin{verbatim}
  x = user_input()      # Source
  y = sanitize(x)       # Sanitizer
  z = y + " suffix"     # Relevant
  w = unrelated()       # NOT relevant
  log(w)                # NOT relevant
  query(z)              # Sink
\end{verbatim}

\textbf{Full backward slice} from \texttt{query(z)}:
\begin{itemize}
\item \texttt{query(z)} $\leftarrow$ \texttt{z} $\leftarrow$ \texttt{y} $\leftarrow$ \texttt{sanitize} $\leftarrow$ \texttt{x} $\leftarrow$ \texttt{user\_input} \quad $\checkmark$ Relevant
\item \texttt{query(z)} $\leftarrow$ \texttt{z} $\leftarrow$ \texttt{" suffix"} \quad Partially relevant
\item \texttt{log(w)} $\leftarrow$ \texttt{w} $\leftarrow$ \texttt{unrelated()} \quad $\times$ Not relevant!
\end{itemize}

\textbf{Thin slice}: Only follow \texttt{z} backward, ignoring \texttt{w}.

\textbf{Implementation}:
\begin{enumerate}
\item Start from sink argument
\item Track which variables are ``relevant''
\item Only follow data dependencies for relevant variables
\item Stop at sanitizers for the sink type
\end{enumerate}
This dramatically reduces analysis scope.

\begin{fstarcode}[title={Thin Slicing Implementation}]
val thin_slice_taint :
  cpg ->
  sink_node:node_id ->
  sink_arg:string ->
  sanitizers:(node_id -> option sanitizer) ->
  set node_id  (* Nodes in the thin slice *)

let thin_slice_taint cpg sink_node sink_arg sanitizers =
  let rec slice visited frontier relevant_vars =
    if Set.is_empty frontier then visited
    else
      (* Get predecessors via data dependence *)
      let edges = get_data_dep_edges cpg frontier in
      (* Filter to relevant variables only *)
      let relevant_edges = List.filter (fun e ->
        let defined_var = get_defined_var cpg e.source in
        Set.mem defined_var relevant_vars
      ) edges in
      (* Stop at sanitizers *)
      let unsanitized = List.filter (fun e ->
        match sanitizers e.source with
        | Some san -> not (sanitizer_protects san (get_sink_type sink_node))
        | None -> true
      ) relevant_edges in
      let new_nodes = Set.of_list (List.map (fun e -> e.source) unsanitized) in
      let new_nodes' = Set.diff new_nodes visited in
      (* Update relevant variables *)
      let new_vars = Set.concat_map (fun n ->
        get_used_vars cpg n
      ) new_nodes' in
      slice (Set.union visited new_nodes')
            new_nodes'
            (Set.union relevant_vars new_vars)
  in
  slice (Set.singleton sink_node)
        (Set.singleton sink_node)
        (Set.singleton sink_arg)
\end{fstarcode}

\begin{fstarcode}[title={Priority-Driven Taint Propagation (TAJ 2009)}]
(* Key insight: Most taint flows are LOCAL - tainted values are typically
   used close to where they were introduced. Processing near-source nodes
   first finds vulnerabilities faster and enables early termination.
   This is the "locality-of-taint" principle: prioritize analysis of nodes
   that are closer (in the PDG) to known taint sources.
   Cross-reference: Uses IFDS foundation from Section 4.1 (Reps 1995) *)

module BrrrMachine.Security.PriorityTaint

type taint_priority_queue = {
  queue : priority_queue (node_id * taint_fact);
  distance_from_source : map node_id nat;
  source_nodes : set node_id;
}

(* Initialize with sources at priority 0 *)
val init_priority_queue : cpg -> (node_id -> option taint_source) -> taint_priority_queue
let init_priority_queue cpg sources =
  let source_set = Set.filter (fun n -> Option.is_some (sources n)) (all_nodes cpg) in
  let initial_dist = Set.fold (fun acc n -> Map.add n 0 acc) Map.empty source_set in
  {
    queue = PQueue.of_list (List.map (fun n -> (n, initial_taint n, 0))
                                     (Set.to_list source_set));
    distance_from_source = initial_dist;
    source_nodes = source_set;
  }

(* Priority = distance from nearest source (lower = higher priority) *)
val priority_of_node : taint_priority_queue -> node_id -> nat
let priority_of_node pq node =
  match Map.find node pq.distance_from_source with
  | Some d -> d
  | None -> max_int  (* Unknown nodes have lowest priority *)

(* Process taint in priority order - finds vulnerabilities faster *)
val process_priority_order :
  cpg ->
  taint_priority_queue ->
  sinks:(node_id -> option taint_sink) ->
  max_findings:nat ->
  list taint_flow

let rec process_priority_order cpg pq sinks max_findings =
  if max_findings = 0 then []
  else match PQueue.pop pq.queue with
  | None -> []  (* Queue exhausted *)
  | Some ((node, fact), queue') ->
      let pq' = { pq with queue = queue' } in
      (* Check if we reached a sink *)
      match sinks node with
      | Some sink ->
          let flow = { source = fact.source; sink = sink; path = [];
                       confidence = 1.0 } in
          flow :: process_priority_order cpg pq' sinks (max_findings - 1)
      | None ->
          (* Propagate to successors with updated priorities *)
          let successors = get_taint_successors cpg node fact in
          let pq'' = List.fold_left (fun acc (succ_node, succ_fact) ->
            let acc' = update_distance acc node succ_node in
            let priority = priority_of_node acc' succ_node in
            { acc' with queue = PQueue.push (succ_node, succ_fact) priority acc'.queue }
          ) pq' successors in
          process_priority_order cpg pq'' sinks max_findings
\end{fstarcode}

\begin{pillarbox}[title={Empirical Result (TAJ 2009)}]
Priority-driven processing finds first vulnerability \textbf{10--100x faster} than breadth-first or depth-first orderings on large codebases.
\end{pillarbox}

\subsection{Taint Finding Classification}

Cross-reference: Section 12.3 (Manifest/Latent Framework)

After detecting taint flow via IFDS (Section 4.1) or TAJ priority-driven analysis, classify each finding using the Manifest/Latent framework:

\begin{enumerate}
\item Build ISL triple from taint path:
\[
[\mathsf{emp}] \; \mathit{source\text{-}to\text{-}sink\text{-}path} \; [\mathit{tainted\_at\_sink}; E_r]
\]

\item Check manifest conditions (\textbf{[Le22]} Definition 3.3):
\begin{itemize}
\item Empty presumption (any input triggers)?
\item Satisfiable result (path reachable)?
\item All heap locs existential?
\item Pure constraints universally satisfiable?
\end{itemize}

\item Report based on classification:
\begin{itemize}
\item \textbf{Manifest taint} $\to$ CRITICAL (0\% FP guaranteed by theorem)
\item \textbf{Latent taint} $\to$ Report with triggering context
\item \textbf{Refuted} $\to$ Filter out (was false positive from IFDS)
\end{itemize}
\end{enumerate}

This eliminates the heuristic ``confidence score'' approach. A manifest taint vulnerability is \emph{proven} to be exploitable.

%--------------------------------------------------
\section{Extended Information Flow Control}
\label{sec:extended-ifc}
%--------------------------------------------------

\begin{warningbox}[title={Beyond Simple Taint: Complete IFC for Real-World Security}]
\begin{description}
\item[8.1.4.1 Implicit Flow (PC Label):] Flows through control structure\\
\texttt{if (h) \{ l := 1 \}} --- leaks \texttt{h} via branch taken

\item[8.1.4.2 Multi-Principal (DLM):] Multiple independent flow policies\\
\texttt{\{alice: alice,hospital; bob: bob,insurance\}}

\item[8.1.4.3 Declassification:] Controlled release of secrets\\
\texttt{declassify(secret, newLabel)} with robust declassification

\item[8.1.4.4 Covert Channels:] Timing, termination, side channels\\
\texttt{while(secret)\{\}} leaks via termination; timing attacks on crypto

\item[8.1.4.5 Concurrent IFC:] Thread interleavings as channels\\
Scheduler-dependent flows, internal timing
\end{description}
\end{warningbox}

%--------------------------------------------------
\subsection{Implicit Flow Analysis via PC Label}
\label{sec:implicit-flow}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Paper}]
\textbf{[Sabelfeld03]} (Sabelfeld \& Myers 2003)
\end{pillarbox}

\begin{warningbox}[title={Critical Insight}]
Explicit-only taint analysis is \textbf{insufficient} for security. Implicit flows through control structure leak secrets equally well.
\end{warningbox}

\textbf{Example} --- Both are insecure:
\begin{verbatim}
  l := h;                    // EXPLICIT flow (synthesis tracks this)

  if (h == secret) {         // IMPLICIT flow (synthesis MISSES this!)
      l := 1;
  }
\end{verbatim}

In the second case, the \emph{value} of \texttt{h} is revealed by whether \texttt{l} becomes 1. The assignment itself uses only low data, but the \emph{branch} depends on high data.

\begin{definition}[PC Label]
The \emph{program counter} (pc) label tracks the security level of the current control context. It is elevated when entering high branches.

\textbf{Rule}: An assignment is secure only if:
\[
\mathit{level}(\mathit{rhs}) \sqcup \mathit{pc} \sqsubseteq \mathit{level}(\mathit{lhs})
\]

This rejects \texttt{l := 1} when \texttt{pc} is high and \texttt{l} is low.
\end{definition}

\begin{fstarcode}[title={Implicit Flow Analysis}]
(* ==================================================
   IMPLICIT FLOW ANALYSIS
   Source: Sabelfeld & Myers 2003
   ================================================== *)
module BrrrMachine.Security.ImplicitFlow

(* Extended taint state: includes PC label *)
type implicit_flow_state = {
  var_label : map string security_level;
  pc : security_level;           (* Program counter security level *)
  pc_sources : list node_id;     (* Where PC elevation came from *)
}

(* Security level operations *)
let level_join l1 l2 = match l1, l2 with
  | SHigh, _ | _, SHigh -> SHigh
  | SLow, SLow -> SLow

let level_leq l1 l2 = match l1, l2 with
  | SLow, _ -> true
  | SHigh, SHigh -> true
  | _, _ -> false

(* Transfer function with implicit flow detection *)
type implicit_finding =
  | ExplicitFlow : var:string -> source:node_id -> implicit_finding
  | ImplicitFlow : var:string -> pc_source:node_id -> implicit_finding
  | TerminationChannel : loop_loc:node_id -> implicit_finding

val transfer_implicit : cpg_node -> implicit_flow_state ->
                        (implicit_flow_state * list implicit_finding)

let transfer_implicit node state =
  match node.kind with
  (* Assignment: check BOTH explicit AND implicit flow *)
  | NAssign var ->
      let rhs_level = compute_expr_level state (get_rhs node) in
      (* CRITICAL: Include PC in effective level *)
      let effective_level = level_join rhs_level state.pc in
      let var_declared = get_declared_label var in
      if not (level_leq effective_level var_declared) then
        let finding =
          if state.pc = SHigh && rhs_level = SLow then
            ImplicitFlow var (List.hd state.pc_sources)  (* Pure implicit *)
          else
            ExplicitFlow var (get_source_node state)     (* Explicit *)
        in
        (state, [finding])
      else
        ({ state with var_label = Map.add var effective_level state.var_label }, [])

  (* Conditional: ELEVATE PC *)
  | NIf ->
      let cond_level = compute_expr_level state (get_condition node) in
      let new_pc = level_join state.pc cond_level in
      ({ state with pc = new_pc;
                    pc_sources = if cond_level = SHigh
                                 then node.id :: state.pc_sources
                                 else state.pc_sources }, [])

  (* Loop: ELEVATE PC + warn about termination channel *)
  | NWhile ->
      let cond_level = compute_expr_level state (get_condition node) in
      let findings = if cond_level = SHigh
                     then [TerminationChannel node.id]
                     else [] in
      ({ state with pc = level_join state.pc cond_level;
                    pc_sources = node.id :: state.pc_sources }, findings)

  (* Scope exit: RESTORE PC (static analysis advantage!) *)
  | NJoin ->
      ({ state with pc = get_enclosing_pc node;
                    pc_sources = get_enclosing_sources node }, [])
  | _ -> (state, [])

(* Noninterference soundness theorem --- See Section 12.2 for full statement
   implicit_analysis_sound: If analysis reports no leaks, noninterference holds. *)
\end{fstarcode}

%--------------------------------------------------
\subsection{Multi-Principal Labels (DLM)}
\label{sec:dlm}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Paper}]
\textbf{[Myers97]} (Decentralized Label Model)
\end{pillarbox}

\begin{warningbox}[title={Why DLM, Not Simple Taint}]
Simple taint lattice: $T_{\bot} < T_{\mathsf{Untainted}} < T_{\mathsf{Maybe}} < T_{\mathsf{Tainted}}$

\textbf{Problem}: Cannot express ``Alice's data readable by Alice+Hospital, Bob's data readable by Bob+Insurance'' --- two independent policies.

\textbf{DLM Solution}: Labels have \emph{multiple owners}, each with their own reader sets.

\textbf{Example}: \texttt{\{alice: alice,hospital; bob: bob,insurance\}} --- two independent flow policies in the same label.

DLM \emph{subsumes} simple taint:
\begin{itemize}
\item $T_{\mathsf{Tainted}} = \{\mathit{source}: \mathit{source}\}$ (only source can read)
\item $T_{\mathsf{Untainted}} = \{\}$ (empty label, anyone can read)
\end{itemize}
\end{warningbox}

\begin{fstarcode}[title={Decentralized Label Model (DLM)}]
(* ==================================================
   DECENTRALIZED LABEL MODEL (DLM)
   Source: Myers 1997
   ================================================== *)
module BrrrMachine.Security.DLM

type principal = string

(* DLM LABEL: Multiple owners, each with their own reader set
   Label = {o1: r1,r2; o2: r3,r4}
   means: owner o1 allows readers r1,r2
          owner o2 allows readers r3,r4 *)
type dlm_label = {
  owners : set principal;
  readers : principal -> set principal;  (* readers for each owner *)
}

(* Empty label: anyone can read (public) *)
let dlm_public : dlm_label = { owners = Set.empty; readers = fun _ -> Set.all }

(* Tainted label: only source can read *)
let dlm_tainted (source : principal) : dlm_label = {
  owners = Set.singleton source;
  readers = fun o -> if o = source then Set.singleton source else Set.all;
}

(* Effective reader set: intersection of all owner's reader sets *)
let effective_readers (l : dlm_label) : set principal =
  if Set.is_empty l.owners then Set.all
  else Set.fold (fun acc owner ->
    Set.inter acc (l.readers owner)
  ) Set.all l.owners

(* DLM LATTICE OPERATIONS *)

(* Join: union owners, intersect readers --- more restrictive *)
let dlm_join (l1 l2 : dlm_label) : dlm_label = {
  owners = Set.union l1.owners l2.owners;
  readers = fun o ->
    let r1 = if Set.mem o l1.owners then l1.readers o else Set.all in
    let r2 = if Set.mem o l2.owners then l2.readers o else Set.all in
    Set.inter r1 r2;
}

(* Restriction check: l1 <= l2 iff l1 allows at least what l2 allows *)
let dlm_leq (l1 l2 : dlm_label) : bool =
  (* l2 has subset of owners *)
  Set.subset l2.owners l1.owners &&
  (* For each owner in l2, l2's readers subset of l1's readers *)
  Set.for_all (fun o ->
    Set.subset (l2.readers o) (l1.readers o)
  ) l2.owners
\end{fstarcode}

\begin{fstarcode}[title={Principal Hierarchy and Declassification}]
(* Principal hierarchy (acts-for relation)
   Enables groups, roles, and delegation.
   If p acts-for q, then p can do anything q can do. *)
type principal_hierarchy = {
  principals : set principal;
  acts_for : principal -> principal -> bool;
  (* Reflexive and transitive *)
  acts_for_refl : squash (forall p. acts_for p p);
  acts_for_trans : squash (forall p q r.
    acts_for p q && acts_for q r ==> acts_for p r);
}

(* Can process acting as 'actor' declassify data owned by 'owner'? *)
let can_declassify (ph : principal_hierarchy) (actor owner : principal) : bool =
  ph.acts_for actor owner

(* DECLASSIFICATION: Authorized release of information
   Rule 1 (Restriction): Anyone can make data MORE restrictive
   Rule 2 (Declassification): Only owner (or delegate) can make LESS restrictive *)
type relabel_result = RelabelOK | RelabelDenied of string

let check_relabel
  (ph : principal_hierarchy)
  (actor : principal)
  (from_label to_label : dlm_label)
  : relabel_result =
  if dlm_leq from_label to_label then
    (* Restriction: always allowed (making more restrictive) *)
    RelabelOK
  else
    (* Declassification: need authority *)
    let owners_losing_restriction =
      Set.filter (fun o ->
        not (Set.subset (to_label.readers o) (from_label.readers o))
      ) from_label.owners in
    if Set.for_all (can_declassify ph actor) owners_losing_restriction then
      RelabelOK
    else
      RelabelDenied ("Actor " ^ actor ^
                     " cannot declassify for all affected owners")
\end{fstarcode}

%--------------------------------------------------
\subsection{Declassification and Endorsement}
\label{sec:declassification}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Papers}]
\textbf{[Zdancewic01]}, \textbf{[Chong04]} (Security Policies for Downgrading), \textbf{[Sabelfeld09]}
\end{pillarbox}

\begin{warningbox}[title={Declassification: Secure Downgrading under Adversarial Conditions}]
\textbf{Key Insight}: Declassification is not just ``allow this flow'' --- it requires precise specification of \textbf{WHAT}, \textbf{WHERE}, \textbf{WHO}, and \textbf{WHEN} information is released. Without robustness, attackers can manipulate what gets declassified.

Cross-reference: Section 12.34 for complete F* formalization.
\end{warningbox}

\subsubsection{The Fundamental Problem}

Strict noninterference is \textbf{too restrictive} for real systems. Real systems \emph{must} release some secrets:
\begin{itemize}
\item Password comparison results (boolean)
\item Encrypted versions of data
\item Statistical aggregates over private data
\item Authentication tokens derived from secrets
\end{itemize}

But \textbf{uncontrolled} declassification creates ``laundering'' vulnerabilities where attackers can influence \emph{what} gets declassified.

\subsubsection{Semantic Security under Declassification}

Traditional noninterference:
\[
M_1 \sim_L M_2 \implies P(M_1) \sim_L P(M_2)
\]
``Low-equivalent inputs produce low-equivalent outputs''

Security under declassification \textbf{[Chong04]}:
\[
M_1 \sim_L M_2 \implies \mathit{visible}(P(M_1)) \sim_L \mathit{visible}(P(M_2))
\]
where $\mathit{visible}(\mathit{trace})$ extracts \emph{only} the declassified values.

The key change: we don't require \emph{all} outputs to be equivalent, only the \emph{observable} outputs (public + explicitly declassified).

\subsubsection{Delimited Release: WHAT Can Be Released}

\begin{verbatim}
  declassify(expression, target_label)
\end{verbatim}

The \textbf{expression} defines an ``escape hatch'' --- only the information computed by that expression may be released.

\begin{itemize}
\item \textbf{Good}: \texttt{declassify(password == guess, public)}\\
Only releases \textbf{boolean} (one bit), not the password.

\item \textbf{Bad}: \texttt{declassify(password, public)}\\
Releases entire password --- too much!
\end{itemize}

\subsubsection{Robust Declassification: Integrity-Based Security}

\textbf{The Attack Model}: Attacker controls LOW inputs (low integrity) but should \textbf{not} be able to:
\begin{enumerate}
\item Influence \emph{which} secret gets declassified
\item Influence \emph{how much} of a secret gets declassified
\end{enumerate}

\textbf{Non-Robust (Vulnerable)}:
\begin{verbatim}
  if (attacker_controlled) {
    declassify(secret1, public)
  } else {
    declassify(secret2, public)
  }
  // Attacker controls WHICH secret is released!
\end{verbatim}

\textbf{Robust Declassification Condition}: For expression $e$ in \texttt{declassify(e, L)}:
\begin{itemize}
\item The PC (program counter) must have \textbf{high integrity} at declassification
\item Expression $e$ must \textbf{not} depend on low integrity inputs
\item The \textbf{path} to declassification must be attacker-independent
\end{itemize}

\begin{warningbox}[title={Critical Insight}]
Robustness requires tracking \textbf{integrity}, not just confidentiality. The synthesis upgrades to 4-point security labels.
\end{warningbox}

\subsubsection{The Four Dimensions of Declassification \textbf{[Sabelfeld09]}}

\begin{enumerate}
\item \textbf{WHAT} --- What information is released (delimited release)\\
Escape hatches define the \emph{function} of secrets that is released.

\item \textbf{WHERE} --- At what program points declassification is allowed\\
Only specific code locations may perform declassification.\\
E.g., only the authentication module may release auth results.

\item \textbf{WHO} --- By whose authority\\
Principals must have ownership of the secret to authorize release.\\
Integrates with DLM (Section~\ref{sec:dlm}): acts-for hierarchy.

\item \textbf{WHEN} --- Under what conditions\\
State-dependent policies: ``release only after encryption''\\
Temporal constraints: ``release only during session''

\item \textbf{SPECULATION-AWARE} (SPECTECTOR extension, Section~\ref{sec:speculative}):
Declassification must \textbf{not} occur on \textbf{speculative} paths!
\end{enumerate}

\subsubsection{Endorsement: The Integrity Dual}

Endorsement is the dual of declassification for \textbf{integrity}:
\begin{itemize}
\item \textbf{Declassification}: $\mathit{high\_confidentiality} \to \mathit{low\_confidentiality}$
\item \textbf{Endorsement}: $\mathit{low\_integrity} \to \mathit{high\_integrity}$
\end{itemize}

\begin{verbatim}
  endorse(untrusted_input, high_integrity)
\end{verbatim}

\textbf{Robust Endorsement Condition} (dual of robust declassification): High-\emph{confidentiality} code cannot influence \emph{what} gets endorsed. This prevents secrets from leaking via the choice of trusted values.

\subsubsection{Sanitizers vs Declassification: Critical Distinction}

\begin{warningbox}[title={These are DIFFERENT operations --- do not conflate them!}]
\textbf{Sanitizer}: Changes \textbf{value}, keeps \textbf{label}
\begin{verbatim}
sanitize(user_input) -> safe_value
\end{verbatim}
The value is \emph{transformed} (e.g., HTML escaping). The security label remains unchanged (still ``from user input'').

\textbf{Declassification}: Keeps \textbf{value}, changes \textbf{label}
\begin{verbatim}
declassify(secret, public) -> secret
\end{verbatim}
The value is \emph{unchanged}. The security label is downgraded (high $\to$ low confidentiality).

\textbf{Both} are needed for complete security analysis:
\begin{itemize}
\item Sanitizers prevent injection attacks (transform dangerous values)
\item Declassification allows controlled information release (change policy)
\end{itemize}
\end{warningbox}

\begin{fstarcode}[title={Declassification and Endorsement Analysis}]
(* ==================================================
   DECLASSIFICATION AND ENDORSEMENT ANALYSIS
   Source: Chong & Myers 2004 "Security Policies for Downgrading"

   KEY INSIGHT: Security under declassification requires tracking BOTH
   confidentiality AND integrity. Robustness is an INTEGRITY property.

   Cross-reference: Section 12.34 for complete theorems and proofs.
   ================================================== *)
module BrrrMachine.Security.Declassification

(* SECURITY LABELS WITH BOTH CONFIDENTIALITY AND INTEGRITY
   This is the critical upgrade from simple taint: 4-point lattice. *)
type confidentiality_level = CLow | CHigh
type integrity_level = ILow | IHigh

type security_label = {
  conf : confidentiality_level;    (* Can information be observed? *)
  integ : integrity_level;         (* Can information be trusted? *)
}

(* Label ordering: (c1, i1) <= (c2, i2) iff c1 <= c2 AND i1 >= i2
   Higher confidentiality = more secret = higher in conf lattice
   Higher integrity = more trusted = LOWER risk = inverted ordering *)
val label_leq : security_label -> security_label -> bool
let label_leq l1 l2 =
  (l1.conf = CLow || l2.conf = CHigh) &&   (* conf: Low <= High *)
  (l1.integ = IHigh || l2.integ = ILow)    (* integ: High <= Low (inverted!) *)

val label_join : security_label -> security_label -> security_label
let label_join l1 l2 = {
  conf = if l1.conf = CHigh || l2.conf = CHigh then CHigh else CLow;
  integ = if l1.integ = ILow || l2.integ = ILow then ILow else IHigh;
}
\end{fstarcode}

\begin{fstarcode}[title={Declassification Policy and Violations}]
(* DECLASSIFICATION POLICY: Full Four-Dimensional Specification *)
type declassification_policy = {
  what : list escape_hatch;             (* WHAT can be released *)
  where : set node_id;                  (* WHERE declassification allowed *)
  who : set principal;                  (* WHO can authorize *)
  when_conditions : list ir_expr;       (* WHEN conditions required *)
  robust_required : bool;               (* Require integrity-based robustness *)
}

(* VIOLATION TYPES: Comprehensive Error Reporting *)
type declassify_violation =
  (* Robustness violations - attacker influence detected *)
  | LowIntegrityControl : declass_node:node_id -> influencing_node:node_id ->
      declassify_violation
      (* Low-integrity code path can reach declassification *)
  | LowIntegrityData : var:string -> declass_node:node_id ->
      declassify_violation
      (* Low-integrity data flows into declassified expression *)

  (* Policy violations *)
  | ExcessiveRelease : released:ir_expr -> allowed:ir_expr ->
      declassify_violation
      (* Expression releases more than escape hatch allows *)
  | Unauthorized : required:principal -> actual:principal ->
      declassify_violation
      (* Principal lacks authority to declassify *)
  | WrongLocation : actual:node_id -> allowed:set node_id ->
      declassify_violation
      (* Declassification at unauthorized code location *)
  | ConditionNotMet : required:ir_expr -> actual_state:ir_state ->
      declassify_violation
      (* When-condition not satisfied *)
\end{fstarcode}

\begin{fstarcode}[title={Robustness Check: Integrity-Based Verification}]
(* This is the key contribution of Chong & Myers 2004. *)
val check_robustness :
  cpg:cpg ->
  declass_node:node_id ->
  hatch:escape_hatch ->
  option declassify_violation

let check_robustness cpg declass_node hatch =
  (* CHECK 1: PC integrity must be HIGH at declassification point
     If low-integrity code can reach this point, attacker controls
     WHETHER declassification occurs. *)
  let pc_integ = get_pc_integrity cpg declass_node in
  if pc_integ = ILow then
    let influencing = get_pc_integrity_source cpg declass_node in
    Some (LowIntegrityControl declass_node influencing)
  else
    (* CHECK 2: No low-integrity data dependencies
       If the declassified expression depends on attacker-controlled data,
       attacker influences WHAT is declassified. *)
    let expr = get_declassified_expr cpg declass_node in
    let deps = backward_slice cpg expr in
    let low_integ_deps = Set.filter (fun n ->
      (get_label cpg n).integ = ILow
    ) deps in
    if not (Set.is_empty low_integ_deps) then
      let bad_var = get_var_name (Set.choose low_integ_deps) in
      Some (LowIntegrityData bad_var declass_node)
    else
      (* CHECK 3: Expression matches escape hatch semantically *)
      if not (expr_semantically_matches expr hatch.expr) then
        Some (ExcessiveRelease expr hatch.expr)
      else
        (* CHECK 4: Authority check *)
        let current_principal = get_current_principal cpg declass_node in
        if not (has_authority current_principal hatch.authority) then
          Some (Unauthorized hatch.authority current_principal)
        else
          None
\end{fstarcode}

%--------------------------------------------------
\subsection{Covert Channels}
\label{sec:covert-channels}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Papers}]
\textbf{[Agat00]} (Timing), \textbf{[Sabelfeld00]} (Probabilistic)
\end{pillarbox}

\textbf{Covert Channels}: Information leaks through \emph{side effects} of computation.

\begin{enumerate}
\item \textbf{Termination Channel} (already in Section~\ref{sec:implicit-flow}):
\begin{verbatim}
while (secret) { loop_forever(); }
\end{verbatim}
Leaks secret via whether program terminates.

\item \textbf{Timing Channel}:
\begin{verbatim}
if (secret) { expensive_operation(); }
else { cheap_operation(); }
\end{verbatim}
Leaks secret via execution time difference.

\item \textbf{Cache Timing}:
\begin{verbatim}
array[secret * 256]  // Cache side channel (Spectre-style)
\end{verbatim}
Memory access patterns leak secret.\\
See Section~\ref{sec:speculative} for speculative execution attacks (Spectre).\\
See Section~\ref{sec:constant-time} for constant-time verification (CT-Verif).

\item \textbf{Storage Channel}:\\
Allocation patterns, file sizes, etc.
\end{enumerate}

\begin{definition}[Timing-Sensitive Noninterference \textbf{[Agat00]}]
Programs must take \emph{same time} regardless of secrets.

\textbf{Requirement}: All branches on secrets must be ``balanced'':
\begin{verbatim}
if (secret) { A } else { B }
\end{verbatim}
requires: $\mathit{time}(A) = \mathit{time}(B)$

\textbf{Cross-copying transformation}:
\begin{verbatim}
if (secret) { A; skip_B } else { skip_A; B }
\end{verbatim}
where \texttt{skip\_X} takes same time as \texttt{X} but does nothing.
\end{definition}

\textbf{Timing Security Layers} (complete coverage):
\begin{enumerate}
\item Instruction timing (\textbf{[Agat00]}) --- balance branch execution
\item Memory access patterns (CT-Verif, Section~\ref{sec:constant-time}) --- constant-time verification
\item Speculative execution (SPECTECTOR, Section~\ref{sec:speculative}) --- microarchitectural security
\item Countermeasure verification --- LFENCE, SLH placement
\end{enumerate}

\begin{fstarcode}[title={Timing Channel Analysis}]
type timing_violation =
  | UnbalancedBranch : branch:node_id -> diff:time_estimate -> timing_violation
  | SecretDependentLoop : loop:node_id -> timing_violation
  | VariableTimeOp : op:node_id -> op_name:string -> timing_violation

type time_estimate =
  | Constant of nat
  | Linear of string      (* Linear in variable *)
  | Unknown

val analyze_timing : cpg -> list timing_violation
let analyze_timing cpg =
  let violations = ref [] in
  (* Check all branches on secret conditions *)
  iter_nodes cpg (fun node ->
    match node.kind with
    | NIf when condition_is_secret cpg node ->
        let then_time = estimate_time cpg (get_then_branch node) in
        let else_time = estimate_time cpg (get_else_branch node) in
        if not (times_equal then_time else_time) then
          violations := UnbalancedBranch node (time_diff then_time else_time)
                        :: !violations
    | NWhile when condition_is_secret cpg node ->
        violations := SecretDependentLoop node :: !violations
    | NCall when is_variable_time_op cpg node ->
        if any_arg_is_secret cpg node then
          violations := VariableTimeOp node (get_func_name node) :: !violations
    | _ -> ()
  );
  !violations

(* Variable-time operations to flag *)
let variable_time_ops = [
  "strcmp"; "memcmp";           (* String comparison - timing varies *)
  "division"; "modulo";         (* Some CPUs have variable-time div *)
  "branch_on_secret";           (* Any conditional on secret *)
]
\end{fstarcode}

%--------------------------------------------------
\subsection{Concurrent Information Flow}
\label{sec:concurrent-ifc}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Papers}]
\textbf{[Smith98]} (Smith \& Volpano 1998), \textbf{[Russo06]} (Russo \& Sabelfeld 2006)
\end{pillarbox}

\textbf{Concurrent IFC Challenges}:

\begin{enumerate}
\item \textbf{Internal Timing}:
\begin{verbatim}
Thread 1: if (secret) { sleep(1000); } l1 := 1;
Thread 2: sleep(500); l2 := l1;
\end{verbatim}
Thread 2 observes \emph{whether} Thread 1 took the branch via timing.

\item \textbf{Scheduler Channels}:\\
Thread scheduling decisions may depend on secrets. Especially problematic with priority inheritance.

\item \textbf{Shared Memory Races}:
\begin{verbatim}
Thread 1: if (secret) { x := 1; }
Thread 2: l := x;
\end{verbatim}
Value of \texttt{l} depends on interleaving \emph{and} secret.
\end{enumerate}

\textbf{Solutions}:
\begin{enumerate}
\item \textbf{Observational Determinism} (\textbf{[McLean92]}): Low-equivalent inputs $\Rightarrow$ same low observations regardless of scheduler
\item \textbf{Strong Security} (Sabelfeld \& Sands): Require timing-insensitivity \emph{plus} scheduler-independence
\item \textbf{Practical Approach}:
\begin{itemize}
\item Ban races on shared variables with different security levels
\item Require synchronized access to shared secrets
\item Flag any shared variable accessed by threads with different clearances
\end{itemize}
\end{enumerate}

\begin{fstarcode}[title={Concurrent IFC Analysis}]
type concurrent_ifc_violation =
  | SharedSecretRace : var:string -> threads:list thread_id ->
      concurrent_ifc_violation
  | InternalTimingLeak : high_thread:thread_id -> observer:thread_id ->
      concurrent_ifc_violation
  | UnsyncedCrossLevelAccess : var:string -> writer_level:security_level ->
      reader_level:security_level -> concurrent_ifc_violation

val analyze_concurrent_ifc : cpg -> list concurrent_ifc_violation
let analyze_concurrent_ifc cpg =
  let violations = ref [] in
  let shared_vars = find_shared_variables cpg in
  Set.iter (fun var ->
    let accessors = get_accessing_threads cpg var in
    let levels = List.map (fun t -> get_thread_clearance t) accessors in
    (* Check 1: Race on secret *)
    if get_var_level var = SHigh && has_race cpg var then
      violations := SharedSecretRace var accessors :: !violations;
    (* Check 2: Cross-level access without sync *)
    let writers = get_writers cpg var in
    let readers = get_readers cpg var in
    List.iter (fun w ->
      List.iter (fun r ->
        if get_level w <> get_level r && not (synced_access cpg w r) then
          violations := UnsyncedCrossLevelAccess var (get_level w)
                        (get_level r) :: !violations
      ) readers
    ) writers;
  ) shared_vars;
  !violations
\end{fstarcode}

%--------------------------------------------------
\subsection{Speculative Execution Security}
\label{sec:speculative}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Paper}]
\textbf{[Guarnieri20]} (SPECTECTOR --- Guarnieri, Kopf, Morales, Reineke, Sanchez 2020)
\end{pillarbox}

\textbf{Speculative execution} creates covert channels through \emph{microarchitectural} state. Even with perfect constant-time code, speculative execution can leak secrets through cache side channels (Spectre family attacks).

\textbf{The Problem}: Modern CPUs speculatively execute past branches before they resolve. On misprediction, \textbf{architectural} state rolls back. But \textbf{microarchitectural} state (caches) is \emph{not} rolled back. This creates observable side channels.

\textbf{Spectre Gadget Example}:
\begin{verbatim}
if (x < array1_size) {           // Mispredicted as true when false
  y = array1[x];                 // Speculatively loads secret
  z = array2[y * 256];           // Leaks secret via cache
}                                // Rollback - but cache state persists!
\end{verbatim}

\begin{definition}[Speculative Non-Interference (SNI)]
Two low-equivalent initial memories produce distinguishable speculative observations \emph{only if} they produce distinguishable non-speculative observations.

Formally:
\[
\forall M_1, M_2.\; \mathit{low\_equiv}(M_1, M_2) \implies
\]
\[
(\mathit{obs\_eq}(\mathit{run\_spec}(P, M_1), \mathit{run\_spec}(P, M_2)) \implies
 \mathit{obs\_eq}(\mathit{run\_std}(P, M_1), \mathit{run\_std}(P, M_2)))
\]
\end{definition}

\textbf{Key Insight: Worst-Case Branch Predictor Abstraction}

Instead of modeling specific CPUs, use a predictor that \textbf{always mispredicts}. Sound: secure against worst-case $\Rightarrow$ secure against any real predictor.

This is a Galois connection:
\begin{center}
Concrete predictors $\{$1-bit, 2-bit, neural, ...$\}$ \\
$\downarrow$ (abstraction) \\
Abstract predictor: always-mispredict (worst case)
\end{center}

\textbf{Observer Model} (compatible with Section~\ref{sec:covert-channels}):
\begin{enumerate}
\item Memory access addresses (cache timing)
\item Jump targets (branch prediction)
\end{enumerate}

\textbf{Countermeasure Verification}: SPECTECTOR can verify that mitigations are correctly placed:
\begin{itemize}
\item \textbf{LFENCE}: Serializing instruction forces rollback
\item \textbf{SLH} (Speculative Load Hardening): Masks speculative values
\item \textbf{Retpoline}: Return trampoline for indirect branches
\end{itemize}

\begin{fstarcode}[title={Speculative Execution Security (SPECTECTOR)}]
module BrrrMachine.Security.Speculative

(* Observation types for cache timing attacks *)
type observation =
  | ObsMemAccess : addr:nat -> observation
  | ObsJumpTarget : target:nat -> observation

type obs_trace = list observation

(* Speculation state *)
type spec_state = {
  pc : nat;
  regs : map nat int;
  mem : map nat int;
  spec_depth : nat;                          (* Current speculation depth *)
  mispredict_stack : list (nat * map nat int); (* Recovery points *)
  trace : obs_trace;                         (* Accumulated observations *)
}

(* Speculation window bound (typical for Intel CPUs) *)
let max_spec_window : nat = 200

(* Speculative step: fork on BOTH branch outcomes *)
val spec_branch : spec_state -> nat -> nat -> list spec_state
let spec_branch st true_target false_target =
  if st.spec_depth < max_spec_window then
    let cond_val = eval_condition st in
    let (correct, wrong) = if cond_val then (true_target, false_target)
                           else (false_target, true_target) in
    [
      (* Non-speculative: take correct path *)
      record_jump { st with pc = correct } correct;
      (* Speculative: take WRONG path (misprediction) *)
      record_jump {
        st with
        pc = wrong;
        spec_depth = st.spec_depth + 1;
        mispredict_stack = (correct, st.regs) :: st.mispredict_stack
      } wrong
    ]
  else
    (* Speculation window exhausted - rollback *)
    rollback st
\end{fstarcode}

\begin{fstarcode}[title={Spectre Gadget Detection and Countermeasure Verification}]
type spectre_gadget = {
  secret_load : node_id;           (* Load that accesses secret *)
  dependent_access : node_id;      (* Memory access dependent on secret *)
  speculation_path : list node_id; (* Path through speculative execution *)
}

val detect_spectre_gadgets :
  cpg -> (nat -> security_level) -> nat -> list spectre_gadget
let detect_spectre_gadgets cpg policy window =
  (* Symbolic execution under speculative semantics *)
  let spec_states = symbolic_spec_execute cpg window in
  List.filter_map (fun state ->
    let spec_loads = get_speculative_secret_loads state policy in
    let dependent = get_dependent_memory_accesses state spec_loads in
    if List.length dependent > 0 then
      Some {
        secret_load = List.hd spec_loads;
        dependent_access = List.hd dependent;
        speculation_path = state.path
      }
    else None
  ) spec_states

type countermeasure =
  | LFENCE : loc:node_id -> countermeasure
  | SLH : loc:node_id -> masked_reg:nat -> countermeasure
  | Retpoline : loc:node_id -> countermeasure

val countermeasure_blocks_gadget :
  cpg -> spectre_gadget -> countermeasure -> bool
let countermeasure_blocks_gadget cpg gadget cm =
  match cm with
  | LFENCE loc ->
      (* LFENCE must dominate the vulnerable load *)
      dominates cpg loc gadget.secret_load &&
      (* No speculative path bypasses the fence *)
      not (exists_speculative_bypass cpg loc gadget.speculation_path)
  | SLH loc masked_reg ->
      (* SLH must mask the value used in dependent access *)
      slh_masks_dependency cpg loc gadget.dependent_access masked_reg
  | Retpoline loc ->
      (* Retpoline must replace indirect branch *)
      is_indirect_branch cpg loc &&
      loc `List.mem` gadget.speculation_path

(* Theorem: Correctly placed countermeasure establishes SNI *)
val countermeasure_soundness :
  cpg:cpg ->
  gadget:spectre_gadget ->
  cm:countermeasure ->
  policy:(nat -> security_level) ->
  window:nat ->
  Lemma (requires countermeasure_blocks_gadget cpg gadget cm)
        (ensures sni (apply_countermeasure (cpg_to_ir cpg) cm) policy window)
\end{fstarcode}

%--------------------------------------------------
\subsection{Constant-Time Verification via Product Programs}
\label{sec:constant-time}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Paper}]
\textbf{[Almeida16]} (CT-Verif --- Almeida, Barbosa, Barthe, Dupressoir, Emmi 2016)
\end{pillarbox}

\textbf{Constant-Time Security}: Execution time and memory access patterns must be independent of secret data.

\textbf{The Problem}:
\begin{enumerate}
\item Execution time variations leak via branch timing
\item Memory access patterns leak via cache timing
\item Variable-time operations (div, modulo) leak via operand-dependent timing
\item Compiler optimizations may introduce violations
\end{enumerate}

\textbf{Constant-Time is a 2-Safety Hyperproperty}: Relates \emph{two} executions of the same program. Cannot be verified by analyzing single executions.

\begin{definition}[CT-Verif Insight: Product Program Reduction]
Given program $P$, construct product program $Q$ that:
\begin{itemize}
\item Maintains two shadow copies of state (original + shadow)
\item Executes both copies in lockstep along identical control paths
\item Asserts observations match at each step
\end{itemize}

$P$ is constant-time $\iff$ $Q$ is assertion-safe

Reduction verified in Coq.
\end{definition}

\textbf{Leakage Models} (parameterized observer power):
\begin{enumerate}
\item \textbf{PC Model}: Only control flow visible (branch-prediction attacks)
\item \textbf{Memory Model}: PC + memory addresses (cache-timing attacks)
\item \textbf{Operand Model}: PC + addresses + operand values (variable-time instructions)
\end{enumerate}

\textbf{Output-Sensitive Security}: Allow intentional leaks bounded by public outputs. Distinguishes benign leaks from true vulnerabilities.

\textbf{Architecture-Aware Variable-Time Operations}:

\begin{center}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Operation} & \textbf{x86\_64} & \textbf{ARM\_v8} & \textbf{RISC-V} \\
\midrule
\texttt{div}       & VAR              & VAR              & CONST           \\
\texttt{mod}       & VAR              & VAR              & CONST           \\
\texttt{fdiv}      & VAR              & VAR              & VAR             \\
\texttt{strcmp}    & VAR              & VAR              & VAR             \\
\texttt{memcmp}    & VAR              & VAR              & VAR             \\
\bottomrule
\end{tabular}
\end{center}

\begin{fstarcode}[title={Constant-Time Verification via Product Programs}]
module BrrrMachine.Security.ConstantTime

(* LEAKAGE MODELS *)
type leakage_model =
  | LeakPC       (* Control flow only - branch prediction attacks *)
  | LeakMemory   (* PC + memory addresses - cache timing attacks *)
  | LeakOperand  (* Full operand values - variable-time instructions *)

type ct_observation =
  | ObsPC : pc:nat -> ct_observation
  | ObsMem : pc:nat -> addr:nat -> ct_observation
  | ObsOp : pc:nat -> addr:nat -> operands:list nat -> ct_observation

(* CONSTANT-TIME SECURITY DEFINITION *)
type program_state = map string int
type trace = list ct_observation

(* Two states are i-equivalent if they agree on public inputs *)
val i_equivalent : program_state -> program_state -> set string -> bool
let i_equivalent s1 s2 public_vars =
  Set.for_all (fun v -> s1 v = s2 v) public_vars

(* DEFINITION: Constant-time security *)
val is_constant_time :
  ir_program ->
  leakage_model ->
  secrets:set string ->
  outputs:list public_output ->
  bool
let is_constant_time prog model secrets outputs =
  let public = Set.complement secrets in
  forall s1 s2.
    i_equivalent s1 s2 public ==>
    (let (t1, s1') = execute_with_trace prog model s1 in
     let (t2, s2') = execute_with_trace prog model s2 in
     o_equivalent s1' s2' outputs ==> t1 = t2)
\end{fstarcode}

\begin{fstarcode}[title={Product Program Construction}]
type product_state = {
  orig : program_state;
  shadow : program_state;
}

(* Rename variables to shadow namespace *)
val rename_to_shadow : ir_instr -> ir_instr
let rename_to_shadow instr =
  map_vars (fun v -> "shadow_" ^ v) instr

(* Construct observation assertion for leakage model *)
val observation_assertion : ir_instr -> leakage_model -> ir_instr
let observation_assertion instr model =
  match model with
  | LeakPC ->
      IAssert (EBinOp Eq (EVar "pc") (EVar "shadow_pc"))
  | LeakMemory ->
      let addr = get_memory_addr instr in
      let shadow_addr = get_shadow_memory_addr instr in
      IAssert (EBinOp And
        (EBinOp Eq (EVar "pc") (EVar "shadow_pc"))
        (EBinOp Eq addr shadow_addr))
  | LeakOperand ->
      let ops = get_operands instr in
      let shadow_ops = get_shadow_operands instr in
      IAssert (all_equal ops shadow_ops)

(* Product program transformation *)
val construct_product_instr : ir_instr -> leakage_model -> list ir_instr
let construct_product_instr instr model =
  [
    instr;                              (* Original instruction *)
    rename_to_shadow instr;             (* Shadow instruction *)
    observation_assertion instr model   (* Assert observations match *)
  ]

(* THEOREM: Product construction is sound and complete *)
val product_reduction_correct :
  prog:ir_program ->
  model:leakage_model ->
  secrets:set string ->
  outputs:list public_output ->
  Lemma (
    is_constant_time prog model secrets outputs <==>
    is_assertion_safe (construct_product prog model)
  )
\end{fstarcode}

\begin{fstarcode}[title={Constant-Time Violations and Analysis}]
type ct_violation =
  | SecretBranch : condition:ir_expr -> secret_deps:set string ->
                   location:node_id -> ct_violation
  | SecretMemoryAccess : address:ir_expr -> secret_deps:set string ->
                         location:node_id -> ct_violation
  | VariableTimeOpOnSecret : op:string -> operand:ir_expr ->
                             secret_deps:set string -> location:node_id ->
                             ct_violation

val analyze_constant_time :
  cpg ->
  model:leakage_model ->
  secrets:set string ->
  outputs:list public_output ->
  list ct_violation
let analyze_constant_time cpg model secrets outputs =
  let prog = cpg_to_ir cpg in
  let product = construct_product prog model in
  let failed = find_failing_assertions product in
  List.map (fun (loc, _) ->
    let instr = get_instr_at cpg loc in
    match categorize_violation instr secrets with
    | VBranch cond deps -> SecretBranch cond deps loc
    | VMemAccess addr deps -> SecretMemoryAccess addr deps loc
    | VVariableOp op operand deps -> VariableTimeOpOnSecret op operand deps loc
  ) failed

(* Architecture-aware variable-time operation check *)
type architecture = X86_64 | ARM_v8 | RISC_V | PowerPC

val is_variable_time : string -> architecture -> bool
let is_variable_time op arch =
  match (op, arch) with
  | ("div", X86_64) | ("div", ARM_v8) -> true
  | ("mod", X86_64) | ("mod", ARM_v8) -> true
  | ("fdiv", _) -> true
  | ("strcmp", _) | ("memcmp", _) -> true
  | _ -> false
\end{fstarcode}

%--------------------------------------------------
\section{Report Optimization and Taint Carriers (TAJ 2009)}
\label{sec:taj-optimization}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Paper}]
\textbf{[Tripp09]} (Tripp, Pistoia, Fink, Sridharan, Weisman 2009)
\end{pillarbox}

\begin{warningbox}[title={Problem: Raw Taint Analysis Produces Too Many Reports}]
A large codebase may have thousands of potential taint flows. Developers cannot review them all --- they need \textbf{actionable} findings.

\textbf{TAJ Solutions}:
\begin{itemize}
\item 8.1.5.1 Library Call Point (LCP) Grouping --- reduce report volume
\item 8.1.5.2 Taint Carrier Detection --- find nested/indirect taint
\end{itemize}

\textbf{Cross-references}:
\begin{itemize}
\item Findings feed into Manifest/Latent classification (Section 12.3)
\item Taint on object state relates to typestate tracking (Section 7.2.1)
\end{itemize}
\end{warningbox}

\subsection{Library Call Point (LCP) Grouping}

\textbf{The Insight}: Multiple taint flows often share the \emph{same root cause} --- a single API call where tainted data enters the system.

\textbf{Example}:
\begin{verbatim}
line 100: data = request.get_param("user")    # LCP: taint enters here
line 110: query1 = "SELECT * FROM users WHERE name = '" + data + "'"
line 120: query2 = "SELECT * FROM orders WHERE user = '" + data + "'"
line 130: query3 = "DELETE FROM sessions WHERE user = '" + data + "'"
\end{verbatim}

Raw analysis reports 3 SQL injection vulnerabilities. But the \textbf{fix} is \textbf{one} location: sanitize at line 100.

\textbf{LCP Grouping}:
\begin{itemize}
\item Group all findings by the Library Call Point where taint enters
\item Report \textbf{one} representative finding per LCP group
\item Developer fixes \textbf{one} location, addresses \textbf{all} variants
\end{itemize}

\textbf{Benefit}:
\begin{itemize}
\item 10--100x reduction in report volume
\item Each finding is actionable (one fix location)
\item Prioritize by LCP with most flows (highest impact fixes)
\end{itemize}

\begin{fstarcode}[title={Library Call Point Grouping}]
module BrrrMachine.Security.LCPGrouping

type library_call_point = {
  api_function : string;          (* e.g., "request.get_param" *)
  call_site : node_id;            (* Location in source code *)
  sink_types : set taint_sink;    (* Types of sinks this LCP reaches *)
}

type lcp_grouped_report = {
  lcp : library_call_point;
  representative_flow : taint_flow;      (* Shortest/clearest example *)
  all_flows : list taint_flow;           (* All flows from this LCP *)
  impact_score : nat;                    (* Number of sinks affected *)
}

(* Extract LCP from a taint flow - the source is the LCP *)
val extract_lcp : taint_flow -> library_call_point
let extract_lcp flow =
  {
    api_function = get_source_api flow.source;
    call_site = flow.source_location;
    sink_types = Set.singleton (get_sink_type flow.sink);
  }

(* Create deduplicated report - one entry per LCP *)
val deduplicate_reports : list taint_flow -> list lcp_grouped_report
let deduplicate_reports flows =
  let groups = group_by_lcp flows in
  Map.fold (fun lcp group acc ->
    (* Pick shortest path as representative - clearest to understand *)
    let representative = List.min_by (fun f -> List.length f.path) group in
    (* Compute impact: number of distinct sinks *)
    let all_sinks = List.fold_left (fun s f ->
      Set.add (get_sink_type f.sink) s
    ) Set.empty group in
    {
      lcp = { lcp with sink_types = all_sinks };
      representative_flow = representative;
      all_flows = group;
      impact_score = List.length group;
    } :: acc
  ) groups []

(* Sort by impact - highest impact LCPs first *)
val prioritize_reports : list lcp_grouped_report -> list lcp_grouped_report
let prioritize_reports reports =
  List.sort (fun a b -> compare b.impact_score a.impact_score) reports
\end{fstarcode}

\subsection{Taint Carrier Detection}

\textbf{The Problem}: Taint stored in \textbf{heap objects} may reach sinks indirectly. Standard taint tracking may miss these ``carrier'' objects.

\textbf{Example}:
\begin{verbatim}
line 10: user_data = request.get_param("data")   # Taint source
line 20: obj.field = user_data                   # Store taint in carrier
line 30: process(obj)                            # Pass carrier
line 40: def process(o):
line 50:     query(o.field)                      # Taint reaches sink!
\end{verbatim}

The taint flows through the \textbf{carrier object} \texttt{obj}. Without heap graph analysis, we might miss that \texttt{obj.field} is tainted when it reaches the sink.

\textbf{Solution}: Build a heap graph from pointer analysis. Track which objects have tainted fields. At sinks, check reachability from tainted fields via heap graph.

Cross-reference: This relates to typestate tracking (Section 7.2.1, \textbf{[Bierhoff07]}) where object state (including tainted fields) must be tracked across calls.

\begin{fstarcode}[title={Taint Carrier Detection}]
module BrrrMachine.Security.TaintCarriers

type taint_carrier = {
  object_var : var_id;           (* Variable holding carrier object *)
  tainted_field : field_id;      (* Field that holds tainted data *)
  store_site : node_id;          (* Where taint was stored *)
  source : taint_source;         (* Original taint source *)
}

type heap_edge =
  | FieldEdge : base:abstract_loc -> field:field_id -> target:abstract_loc
      -> heap_edge
  | ArrayEdge : base:abstract_loc -> target:abstract_loc -> heap_edge

type heap_graph = {
  nodes : set abstract_loc;
  edges : set heap_edge;
  tainted_locs : map abstract_loc (set (field_id * taint_source));
}

(* Build heap graph from pointer analysis + taint stores *)
val build_heap_graph : cpg -> pts_solution -> heap_graph
let build_heap_graph cpg pts =
  let nodes = collect_all_locs pts in
  let edges = collect_heap_edges cpg pts in
  let tainted = find_taint_stores cpg pts in
  { nodes; edges; tainted_locs = tainted }

(* Check if a sink argument can receive tainted data via carrier *)
val check_carrier_taint :
  heap_graph ->
  sink_arg:abstract_loc ->
  option (taint_carrier * list heap_edge)  (* Carrier + path to sink *)

let rec check_carrier_taint hg sink_arg =
  (* Direct check: is sink_arg a tainted location? *)
  match Map.find_opt sink_arg hg.tainted_locs with
  | Some taints when not (Set.is_empty taints) ->
      let (field, source) = Set.choose taints in
      Some ({ object_var = loc_to_var sink_arg;
              tainted_field = field;
              store_site = 0; (* TODO: track *)
              source = source }, [])
  | _ ->
      (* Transitive check: can we reach a tainted location via heap edges? *)
      bfs_find_taint hg sink_arg
\end{fstarcode}

\begin{warningbox}[title={Integration: TAJ Report Pipeline}]
\begin{enumerate}
\item Run standard IFDS taint analysis (Section~\ref{sec:taint-framework})
\item Detect taint carriers via heap graph (Section 8.1.5.2)
\item Merge direct + carrier taint flows
\item Group by LCP (Section 8.1.5.1)
\item Prioritize by impact score
\item Feed into Manifest/Latent classification (Section 12.3)
\end{enumerate}

\textbf{Result}: Actionable, prioritized, deduplicated vulnerability reports.
\end{warningbox}

%--------------------------------------------------
\section{Lifecycle-Aware Taint Analysis (FlowDroid)}
\label{sec:flowdroid}
%--------------------------------------------------

\begin{pillarbox}[title={Foundational Paper}]
\textbf{[Arzt14]} (Arzt, Rasthofer, Fritz, Bodden, Bartel, Klein, Le Traon, Octeau, McDaniel 2014)
\end{pillarbox}

\begin{warningbox}[title={Critical Insight: Framework Applications are NOT Standalone Programs}]
Android apps, Django views, Express handlers, etc.\ are \textbf{plugins} into a framework that invokes callbacks based on system events.

\textbf{Without lifecycle modeling}: Analysis misses many real leaks

\textbf{With lifecycle modeling}: 93\% recall vs 25--76\% for tools without it
\end{warningbox}

\textbf{The Challenge}:
\begin{itemize}
\item Framework invokes app callbacks in arbitrary order
\item Callbacks share state via instance fields
\item Taint may flow: callback1 $\to$ field $\to$ callback2 $\to$ sink
\item Without modeling \emph{all} callbacks, we miss these flows
\end{itemize}

\textbf{Example (Android)}:
\begin{verbatim}
class LeakyActivity extends Activity {
  String secret;

  void onCreate(Bundle b) {
    secret = getDeviceId();  // Source: IMEI
  }
  void onResume() {
    sendToServer(secret);    // Sink: network
  }
}
\end{verbatim}

\textbf{Standard analysis}: Sees only \texttt{onCreate} \emph{or} \texttt{onResume}, misses the flow.

\textbf{FlowDroid}: Models that \texttt{onResume} follows \texttt{onCreate}, finds the leak.

\textbf{Solution: Dummy Main Method}

Generate a synthetic entry point that models all possible callback orderings:
\begin{verbatim}
void dummyMain() {
  Activity a = new LeakyActivity();
  while (true) {  // Non-deterministic loop = all orderings
    switch (nondet()) {
      case 0: a.onCreate(null); break;
      case 1: a.onStart(); break;
      case 2: a.onResume(); break;
      case 3: a.onPause(); break;
      case 4: a.onStop(); break;
      case 5: a.onDestroy(); break;
    }
  }
}
\end{verbatim}

The loop structure allows analysis to consider all orderings without explicit enumeration ($2^n$ combinations).

\subsection{Activation Statements for Flow-Sensitive Heap Taint}

\begin{warningbox}[title={Problem: Standard IFDS Loses Flow-Sensitivity for Heap-Stored Taint}]
\begin{verbatim}
p1.f = source();    // Line 1: taint stored in heap
sink(p2.f);         // Line 2: should NOT report (p1 != p2 yet)
p1 = p2;            // Line 3: now aliased!
sink(p2.f);         // Line 4: SHOULD report (p1 == p2)
\end{verbatim}

\textbf{Without flow-sensitivity}: BOTH sinks flagged (false positive at line 2)

\textbf{With activation statements}: Only line 4 flagged (precise)
\end{warningbox}

\textbf{Solution: Activation Statements}

When backward alias analysis finds a potential alias, record \emph{where} it was found. Mark the taint as \textbf{inactive} until forward analysis passes that point.

\begin{enumerate}
\item Forward finds heap write: \texttt{p1.f = tainted}\\
$\to$ Spawn backward analysis to find aliases of \texttt{p1.f}

\item Backward finds: at line 3, \texttt{p2} becomes aliased to \texttt{p1}\\
$\to$ Create fact: \texttt{(p2.f, INACTIVE, activation=line3)}

\item Forward propagates inactive taint past line 3\\
$\to$ Fact becomes: \texttt{(p2.f, ACTIVE, activation=line3)}

\item At sink: only report \textbf{active} taints\\
$\to$ Line 2: \texttt{p2.f} is INACTIVE $\to$ no report\\
$\to$ Line 4: \texttt{p2.f} is ACTIVE $\to$ \textbf{report leak}
\end{enumerate}

The F* formalization below introduces \textbf{access paths} --- a representation that tracks not just variables, but entire field access chains (e.g., \texttt{x.f.g.h}). Access paths enable field-sensitive taint tracking:

\begin{itemize}
\item \texttt{base}: The root variable
\item \texttt{fields}: A list of field identifiers forming the access chain
\item \texttt{array\_wildcard}: When true, matches any array index (e.g., \texttt{x.f[*]})
\end{itemize}

The \texttt{max\_access\_path\_length} constant (typically 5) bounds path length to ensure termination. Longer paths are approximated using array wildcards.

\begin{fstarcode}[title={Activation-Aware Taint Analysis}]
(* Source: Arzt 2014 (FlowDroid Section 4.3) *)
module BrrrMachine.Security.ActivationTaint

(* Access path = variable + field chain for precise heap tracking *)
type access_path = {
  base : var_id;
  fields : list field_id;    (* x.f.g.h represented as [f; g; h] *)
  array_wildcard : bool;     (* x.f[*] matches any array index *)
}

(* Maximum path length to ensure termination *)
let max_access_path_length : nat = 5

(* Taint state with activation tracking *)
type taint_activation_state =
  | TaintActive                            (* Can trigger leak at sink *)
  | TaintInactive : activation:node_id ->  (* Waiting to pass activation *)
      taint_activation_state

(* Extended taint fact with activation *)
type activation_taint_fact = {
  path : access_path;
  state : taint_activation_state;
  source : taint_source;
  source_location : node_id;
}

(* At sink: only report if taint is ACTIVE *)
val check_sink_with_activation :
  node:node_id ->
  facts:set activation_taint_fact ->
  sink:taint_sink ->
  list taint_flow

let check_sink_with_activation node facts sink =
  (* CRITICAL: Filter to ACTIVE taints only *)
  let active_facts = Set.filter (fun f ->
    match f.state with
    | TaintActive -> true
    | TaintInactive _ -> false
  ) facts in
  Set.to_list active_facts |> List.map (fun fact ->
    { source = fact.source;
      source_location = fact.source_location;
      sink = sink;
      sink_location = node;
      path = [];
      vuln_type = sink_to_vuln sink;
      confidence = 1.0 }
  )
\end{fstarcode}

\subsubsection{Bidirectional IFDS Extension}

FlowDroid extends standard IFDS with \textbf{bidirectional analysis}. The forward phase propagates taint from sources, while the backward phase finds heap aliases to tainted locations. These two directions \emph{spawn} each other:

\begin{itemize}
\item \textbf{Forward} $\to$ finds heap write $\to$ \textbf{spawns Backward}
\item \textbf{Backward} $\to$ finds alias $\to$ \textbf{spawns Forward} (with INACTIVE taint)
\end{itemize}

\begin{warningbox}[title={Note: Not Pure IFDS}]
This is \emph{not} pure IFDS because may-alias is non-distributive. The backward phase uses on-demand alias analysis. A cleaner formalization would use IDE (the non-distributive extension of IFDS) for the backward phase.

Cross-reference: Section 4.1 for standard IFDS (Reps 1995).
\end{warningbox}

\begin{fstarcode}[title={Bidirectional IFDS Extension}]
(* Bidirectional analysis direction *)
type analysis_direction =
  | Forward : analysis_direction
  | Backward : analysis_direction

(* Worklist for bidirectional analysis *)
noeq type bidirectional_worklist = {
  forward : list (int * activation_taint_fact);     (* node * fact *)
  backward : list (int * access_path * int);        (* node * path * activation_stmt *)
}

(* Propagate taint through statement, handling activation *)
val propagate_with_activation :
  cpg:cpg ->
  node:node_id ->
  fact:activation_taint_fact ->
  set activation_taint_fact

let propagate_with_activation cpg node fact =
  (* Check if we're passing the activation point *)
  let fact' = match fact.state with
    | TaintInactive activation when node = activation ->
        { fact with state = TaintActive }  (* ACTIVATE! *)
    | _ -> fact
  in
  (* Standard taint propagation *)
  propagate_taint_fact cpg node fact'
\end{fstarcode}

The bidirectional worklist maintains separate queues for forward and backward work items. When forward analysis encounters a heap write of tainted data, it spawns backward analysis to find all aliases. When backward analysis discovers an alias, it spawns forward analysis with an inactive taint fact that will be activated when passing the alias point.

\subsection{Framework Lifecycle Modeling}

The FlowDroid lifecycle modeling creates a synthetic ``dummy main'' that captures all possible orderings of framework callbacks. The following F* code generalizes this beyond Android to support Django, Express, and other frameworks. The key insight is that lifecycle callbacks can be modeled as non-deterministic choices within a loop, ensuring the analysis considers all possible callback orderings without explicitly enumerating $2^n$ combinations.

\begin{fstarcode}[title={Framework Lifecycle Modeling}]
(* Generalized beyond Android to support multiple frameworks. *)
module BrrrMachine.Analysis.Lifecycle

(* Generic component type (framework-agnostic) *)
type component_kind =
  | CompActivity         (* Android Activity, Django View *)
  | CompService          (* Android Service, background worker *)
  | CompReceiver         (* Android BroadcastReceiver, event handler *)
  | CompProvider         (* Android ContentProvider, data source *)
  | CompMiddleware       (* Express/Django middleware *)
  | CompHandler          (* HTTP handler, route handler *)

(* Lifecycle callback specification *)
type lifecycle_callback = {
  component_kind : component_kind;
  method_pattern : string;          (* e.g., "on*", "handle*" *)
  phase : lifecycle_phase;
  can_access_state : bool;          (* Can read/write instance fields *)
}

type lifecycle_phase =
  | PhaseInit       (* Constructor, onCreate *)
  | PhaseStart      (* onStart, request received *)
  | PhaseActive     (* onResume, handling request *)
  | PhasePause      (* onPause, request complete *)
  | PhaseStop       (* onStop, cleanup *)
  | PhaseDestroy    (* onDestroy, teardown *)

(* Generate dummy main from detected components *)
val generate_dummy_main :
  components:list (component_kind * string * list method_id) ->
  lifecycle:lifecycle_graph ->
  ir_func

let generate_dummy_main components lifecycle =
  (* 1. Instantiate all components *)
  let instantiations = List.map (fun (kind, class_name, _) ->
    let var = fresh_var kind in
    SLet var (TRef (TStruct class_name)) (ENew class_name [])
  ) components in
  (* 2. Build non-deterministic callback invocation *)
  let callback_calls = List.concat_map (fun (kind, class_name, methods) ->
    List.map (fun method_id ->
      SCall None (EMethodCall (EVar (var_for kind)) method_id) []
    ) methods
  ) components in
  (* 3. Wrap in while(true) for all orderings *)
  let body = SWhile (EVal (VBool true)) (SNondet callback_calls) in
  { id = "dummyMain"; name = "dummyMain";
    params = []; return_type = TUnit;
    body = SSeq (SSeq_many instantiations) body;
    effect_sig = effect_any; is_public = true;
    source_lang = "java" }
\end{fstarcode}

\subsection{Taint Wrappers for Library Methods}

Real-world applications depend heavily on library methods whose source code may be unavailable or too expensive to analyze. FlowDroid's \textbf{taint wrappers} provide explicit specifications of how taint propagates through these APIs. The wrapper rules specify:

\begin{itemize}
\item \texttt{PassThrough}: Taint flows from one parameter to another
\item \texttt{Kill}: Taint is sanitized/removed at a parameter
\item \texttt{Source}: The method introduces new taint
\item \texttt{Sink}: The method is a security-sensitive operation
\end{itemize}

The F* code below models these wrapper rules. The \texttt{param\_spec} type allows precise specification of taint flow through the receiver (\texttt{this}), arguments, return values, and fields.

\begin{fstarcode}[title={Taint Wrappers for Library Methods}]
(* Library methods (whose code is unavailable) need explicit taint
   propagation rules. Wrappers specify how taint flows through APIs. *)
module BrrrMachine.Security.TaintWrapper

type taint_wrapper_rule =
  | WrapperPassThrough : from:param_spec -> to:param_spec -> taint_wrapper_rule
      (* Taint flows from 'from' to 'to' *)
  | WrapperKill : param:param_spec -> taint_wrapper_rule
      (* Taint is removed at this parameter *)
  | WrapperSource : to:param_spec -> source:taint_source -> taint_wrapper_rule
      (* Method introduces taint *)
  | WrapperSink : from:param_spec -> sink:taint_sink -> taint_wrapper_rule
      (* Method is a sensitive sink *)

type param_spec =
  | ParamThis                              (* The 'this' pointer *)
  | ParamArg : index:nat -> param_spec     (* Argument by index *)
  | ParamReturn                            (* Return value *)
  | ParamFieldOfThis : field:string -> param_spec
  | ParamFieldOfArg : index:nat -> field:string -> param_spec

type taint_wrapper = {
  method_signature : string;
  rules : list taint_wrapper_rule;
}

(* Standard library wrappers *)
val string_wrappers : list taint_wrapper
let string_wrappers = [
  (* String.concat: if either arg tainted, result tainted *)
  { method_signature = "java.lang.String.concat";
    rules = [WrapperPassThrough (ParamArg 0) ParamReturn;
             WrapperPassThrough ParamThis ParamReturn] };
  (* StringBuilder.append: arg taints this and return *)
  { method_signature = "java.lang.StringBuilder.append";
    rules = [WrapperPassThrough (ParamArg 0) ParamThis;
             WrapperPassThrough ParamThis ParamReturn] };
]

val collection_wrappers : list taint_wrapper
let collection_wrappers = [
  (* List.add: if arg tainted, list becomes tainted *)
  { method_signature = "java.util.List.add";
    rules = [WrapperPassThrough (ParamArg 0) ParamThis] };
  (* List.get: if list tainted, return tainted *)
  { method_signature = "java.util.List.get";
    rules = [WrapperPassThrough ParamThis ParamReturn] };
  (* Map.put: both key and value taint the map *)
  { method_signature = "java.util.Map.put";
    rules = [WrapperPassThrough (ParamArg 0) ParamThis;
             WrapperPassThrough (ParamArg 1) ParamThis] };
]
\end{fstarcode}

\begin{warningbox}[title={Tension: TAJ Taint Carriers vs FlowDroid Activation}]
\textbf{TAJ}: Uses heap graph BFS reachability --- \textbf{fast} but flow-insensitive

\textbf{FlowDroid}: Uses activation statements --- \textbf{precise} but more expensive

\textbf{Resolution}: Configurable strategy based on analysis budget
\begin{itemize}
\item For quick scans: TAJ carrier detection (Section 8.1.5.2)
\item For precision: FlowDroid activation statements (Section 8.1.6.1)
\item For hybrid: Use TAJ for initial candidates, FlowDroid to verify
\end{itemize}
\end{warningbox}

\begin{fstarcode}[title={Heap Taint Strategy Selection}]
type heap_taint_strategy =
  | StrategyTAJCarriers       (* Fast heap graph BFS - Section 8.1.5.2 *)
  | StrategyActivation        (* Precise activation statements - Section 8.1.6.1 *)
  | StrategyHybrid            (* TAJ for candidates, activation to verify *)
\end{fstarcode}

%--------------------------------------------------
\section{Incremental Taint Analysis}
\label{sec:incremental-taint}
%--------------------------------------------------

\textbf{Cross-reference}: Section 10.1.3 (DRedL), Section 10.1.4 (Infer Deployment)

\textbf{Incremental Taint Analysis for IDE/CI Integration}:

When code changes, we can incrementally update taint analysis results using the techniques from \textbf{[Szabo18]} (DRedL) and \textbf{[Distefano19]} (Infer).

\textbf{Strategy}:
\begin{enumerate}
\item File change detected\\
$\to$ Adapton marks affected CPG thunks dirty (Section 10.1.1)

\item Re-parse changed file via tree-sitter (fast, $<$ 50ms typically)

\item Convert CPG changes to Datalog tuple changes:
\begin{itemize}
\item New taint sources/sinks $\to$ insertions
\item Removed sources/sinks $\to$ deletions
\item Modified flow edges $\to$ increasing/decreasing replacements
\end{itemize}

\item Use DRedL (Section 10.1.3) to update taint relations:
\begin{itemize}
\item Taint lattice: $\mathsf{UNTAINTED} < \mathsf{TAINTED}$ (simple 2-point)
\item Adding taint source $\to$ increasing replacement (monotonic)
\item Removing taint source $\to$ anti-monotonic, needs re-derivation
\end{itemize}

\item Only report flows involving \textbf{changed} code (diff-time principle)
\end{enumerate}

\textbf{Expected Performance} (based on IncA benchmarks \textbf{[Szabo18]}):
\begin{itemize}
\item Median update time: 2--5ms
\item Speedup vs from-scratch: 65x--243x
\item Target: sub-second for IDE integration
\end{itemize}

\textbf{Integration with IFDS}: Taint analysis is often formulated as IFDS (Section 4.1). Encode IFDS path edges as Datalog relations:
\begin{verbatim}
PathEdge(d1, n1, d2, n2) :-
  FlowFunction(n1, n2, d1, d2).
PathEdge(d1, n1, d3, n3) :-
  PathEdge(d1, n1, d2, n2),
  PathEdge(d2, n2, d3, n3).
\end{verbatim}

Then use DRedL to incrementally maintain \texttt{PathEdge} relations.

\textbf{Zoncolan Experience} \textbf{[Distefano19]}:

Facebook's security taint analyzer for 100M LOC Hack codebase:
\begin{itemize}
\item Compositional summary-based taint propagation
\item Diff-time deployment in CI pipeline
\item Outperforms other security detection methods
\item Thousands of security fixes deployed
\end{itemize}

\begin{fstarcode}[title={Incremental Taint via DRedL}]
val incremental_taint_update :
  prev_solution:ifds_solution ->
  cpg_changes:list cpg_change ->
  (ifds_solution * list taint_flow)

let incremental_taint_update prev cpg_changes =
  (* Convert CPG changes to Datalog tuple changes *)
  let datalog_changes = List.concat_map cpg_change_to_tuples cpg_changes in
  (* Use DRedL to maintain IFDS relations incrementally *)
  let new_solution = maintain_incrementally
    ifds_program prev.relations prev.support datalog_changes in
  (* Extract new taint flows from changed relations *)
  let new_flows = extract_taint_flows_from_solution new_solution in
  (new_solution, new_flows)
\end{fstarcode}

%==================================================
% End of Part VIII
%==================================================
