% ==================================================
% PART IV: ANALYSIS ALGORITHMS (FIRST HALF)
% Sections: 4.1 IFDS, 4.2 CFL-Reachability, 4.3 Under-Approximate Analysis
% ==================================================

\part{Analysis Algorithms}
\label{part:analysis-algorithms}

\begin{pillarbox}[title={Critical Tension: IFDS vs Bi-Abduction/Eval}]
\textbf{IFDS (Section~\ref{sec:ifds}):}
\begin{itemize}
  \item Requires DISTRIBUTIVE transfer functions: $f(a \sqcup b) = f(a) \sqcup f(b)$
  \item Tracks DATAFLOW FACTS
  \item $\BigO{ED^3}$ guaranteed complexity
  \item Path-INSENSITIVE
\end{itemize}

\textbf{Bi-Abduction/Eval (Section~\ref{sec:under-approx}):}
\begin{itemize}
  \item NOT distributive
  \item Multiple valid $(M, F)$ pairs
  \item Tracks SEPARATION LOGIC assertions
  \item May be exponential
  \item Path-SENSITIVE
\end{itemize}

\textbf{These are different algorithms for different problems:}
\begin{itemize}
  \item Taint analysis $\rightarrow$ IFDS (fast, whole-program)
  \item Shape/memory analysis $\rightarrow$ Eval (precise, local)
  \item Hybrid: IFDS finds candidates, Eval verifies (Section~\ref{sec:ifds-eval-hybrid})
\end{itemize}

\textbf{DO NOT} try to force bi-abduction into IFDS framework! The mathematical properties are incompatible.
\end{pillarbox}

\begin{pillarbox}[title={Tension Resolution: IFDS vs Set Constraints}]
\textbf{Source}: Aiken 1999. See Appendix~D.10.1 for full analysis.

\textbf{Insight}: IFDS is a RESTRICTED FRAGMENT of set constraints.
\begin{itemize}
  \item IFDS requires distributive transfer functions
  \item Set constraints (Section~12.18) handle non-distributive cases
  \item Pointer analysis is NOT distributive---cannot use IFDS directly
\end{itemize}

\textbf{Resolution}:
\begin{itemize}
  \item Use IFDS for taint, reaching definitions, live variables (distributive)
  \item Use set constraints for type inference, pointer analysis (general)
  \item Section~12.18 provides unified constraint framework
\end{itemize}
\end{pillarbox}

\begin{pillarbox}[title={Tension Resolution: Datalog Interpretation vs Compilation}]
\textbf{Sources}: Jordan 2016 (Souffle), Madsen 2016 (Flix)

\textbf{Old View}: ``Don't build custom Datalog engine, use existing or skip''

\textbf{New View}: COMPILE Datalog rules to specialized code, don't interpret

Jordan 2016 demonstrates: Souffle achieves 50x+ speedup over bddbddb by eliminating interpretation overhead via staged specialization:
\begin{enumerate}
  \item Stage 1: Datalog $\rightarrow$ RAM (Relational Algebra Machine)
  \item Stage 2: RAM $\rightarrow$ Optimized RAM (Dilworth indices, join ordering)
  \item Stage 3: RAM $\rightarrow$ C++/Rust (specialized, parallel)
\end{enumerate}

\textbf{Resolution for brrr-machine}:
\begin{itemize}
  \item Development: Use interpreted Datalog (Crepe, Souffle -interpreter)
  \item Production: Compile analysis rules to specialized Rust
  \item See Section~\ref{sec:datalog-compilation} for compilation strategy details
\end{itemize}
\end{pillarbox}

\begin{pillarbox}[title={Key Insight: Flix Unifies IFDS/IDE/Value Analysis}]
\textbf{Source}: Madsen 2016

\textbf{Standard Datalog}: Relations (finite sets of tuples)

\textbf{Flix Extension}: Lattice predicates (map from keys to lattice elements)

This unifies:
\begin{itemize}
  \item IFDS = Flix where lattice is powerset of dataflow facts
  \item IDE = Flix where lattice is micro-function space
  \item Constant propagation = Flix where lattice is constant domain
\end{itemize}

All require MONOTONE transfer functions for soundness. See Section~\ref{sec:flix-lattice} for lattice-extended Datalog details.
\end{pillarbox}


%==================================================
\chapter{IFDS: Interprocedural Finite Distributive Subset}
\label{sec:ifds}
%==================================================

\textbf{Paper}: Reps, Horwitz, Sagiv 1995

\IFDS{} is the workhorse algorithm for precise interprocedural dataflow analysis \textbf{when transfer functions are DISTRIBUTIVE} ($f(a \sqcup b) = f(a) \sqcup f(b)$). Its genius is reducing dataflow problems to graph reachability.

\textbf{Important}: \IFDS{} does NOT apply to pointer analysis (non-distributive). See Section~12.18 for set constraints handling non-distributive cases.

\begin{pillarbox}[title={Flix Perspective (Madsen 2016)}]
\IFDS{} is lattice-extended Datalog where:
\begin{itemize}
  \item Lattice = powerset of dataflow facts (finite)
  \item Transfer = gen/kill functions (distributive)
  \item Distributivity = transfer distributes over join
\end{itemize}

\IDE{} extends \IFDS{} where:
\begin{itemize}
  \item Lattice = micro-function space (environment transformers)
  \item Transfer = function composition
  \item Enables: constant propagation, linear constant propagation
\end{itemize}

\textbf{Souffle Perspective (Jordan 2016)}:
\IFDS{} expressed as Datalog can be COMPILED, not just interpreted:
\begin{enumerate}
  \item Stage 1: \IFDS{} $\rightarrow$ Datalog rules (declarative specification)
  \item Stage 2: Datalog $\rightarrow$ RAM (semi-naive evaluation, index selection)
  \item Stage 3: RAM $\rightarrow$ Rust/C++ (specialized code via templates)
\end{enumerate}
This achieves 50x+ speedup over interpreted Datalog (bddbddb, muZ). See Section~\ref{sec:datalog-compilation} for compilation strategy details.
\end{pillarbox}


%--------------------------------------------------
\section{The Key Insight}
\label{sec:ifds-insight}
%--------------------------------------------------

\textbf{The Problem}: Interprocedural analysis is hard because:
\begin{itemize}
  \item Must track calling context (don't mix up callers)
  \item Must handle recursion
  \item Naive approach: exponential in call depth
\end{itemize}

\textbf{Example (imprecise without context)}:
\begin{verbatim}
def f(x):
  return x + 1
a = f(1)   # Should be 2
b = f(10)  # Should be 11
\end{verbatim}

Without context sensitivity: \texttt{f} receives $\{1, 10\}$, returns $\{2, 11\}$, so both \texttt{a} and \texttt{b} get $\{2, 11\}$ --- IMPRECISE!

With context sensitivity: Call 1 has \texttt{f} receive 1, return 2; Call 2 has \texttt{f} receive 10, return 11. Thus $a = 2$, $b = 11$ --- PRECISE!

\textbf{The Reps Insight}: Frame the problem as GRAPH REACHABILITY with context encoded as MATCHED PARENTHESES:
\begin{itemize}
  \item $(_{1} \ldots )_{1}$ means: call site 1, return to site 1
  \item $(_{1} (_{2} )_{2} )_{1}$ means: nested call, properly matched
\end{itemize}

INVALID paths like $(_{1} )_{2}$ are automatically rejected. This is \CFL{}-reachability with the Dyck language.


%--------------------------------------------------
\section{The Exploded Supergraph}
\label{sec:exploded-supergraph}
%--------------------------------------------------

\textbf{Construction}: Given:
\begin{itemize}
  \item Program with procedures $p_1, \ldots, p_n$
  \item \CFG{} for each procedure
  \item Finite set $D$ of dataflow facts ($|D| = d$)
\end{itemize}

Build the \textbf{Exploded Supergraph} $G^\#$:
\begin{align*}
\text{NODES} &: \{ \langle n, d \rangle \mid n \text{ is a program point}, d \in D \cup \{0\} \} \\
\text{EDGES} &: \text{For each CFG edge } n_1 \rightarrow n_2 \text{ and its transfer function } f: \\
&\quad \text{Add edge } \langle n_1, d_1 \rangle \rightarrow \langle n_2, d_2 \rangle \text{ iff } d_2 \in f(\{d_1\})
\end{align*}

The $0$ fact represents ``nothing'' --- it's the identity for the dataflow function.

\begin{theorem}[Reps 1995]
Fact $d$ holds at program point $n$ if and only if there exists a \textbf{realizable path} from $\langle s_{\text{main}}, 0 \rangle$ to $\langle n, d \rangle$.

Realizable = matched call/return parentheses.
\end{theorem}


%--------------------------------------------------
\section{The Tabulation Algorithm}
\label{sec:ifds-tabulation}
%--------------------------------------------------

The tabulation algorithm is the heart of IFDS. It computes \emph{path edges} that track same-level realizable paths through the exploded supergraph, and \emph{summary edges} that capture the input-output behavior of procedures. The algorithm uses a worklist to propagate facts, handling four cases: intraprocedural edges, call edges (entering callees), exit edges (leaving procedures), and call-to-return edges (bypassing calls). The key insight is that summary edges allow reusing procedure analysis across multiple call sites.

The following F* code defines the core data structures: \texttt{path\_edge} represents a realizable path from procedure entry with fact \texttt{d1} to node \texttt{n} with fact \texttt{d2}; \texttt{summary\_edge} captures a procedure's effect from call site to return site. The \texttt{solve} function implements the worklist algorithm, achieving $O(ED^3)$ complexity where $E$ is the number of edges and $D$ is the domain size.

\begin{fstarcode}[title={\IFDS{} Tabulation Algorithm (RHS95, Figure 5)}]
module BrrrMachine.IFDS

(* --------------------------------------------------
   PROBLEM DEFINITION
   -------------------------------------------------- *)

(* An IFDS problem instance *)
type ifds_problem (d : Type) = {
  (* The supergraph *)
  supergraph : cpg;
  (* The dataflow domain --- MUST BE FINITE *)
  domain : finite_set d;
  (* The zero fact *)
  zero : d;
  (* Flow functions for each edge type *)
  flow_function : cpg_edge -> d -> set d;
  (* Call flow: how facts map at call site *)
  call_flow : node_id -> d -> set d;
  (* Return flow: how facts map at return *)
  return_flow : node_id -> node_id -> d -> d -> set d;
  (* Call-to-return flow: for facts not passed to callee *)
  call_to_return_flow : node_id -> d -> set d;
}

(* --------------------------------------------------
   DATA STRUCTURES
   -------------------------------------------------- *)

(* Path edge: same-level realizable path *)
type path_edge (d : Type) = {
  (* Procedure containing this path *)
  proc_entry : node_id;
  (* Starting fact at procedure entry *)
  d1 : d;
  (* Current node reached *)
  n : node_id;
  (* Current fact *)
  d2 : d;
}

(* Summary edge: captures procedure's effect *)
type summary_edge (d : Type) = {
  (* Call site *)
  call_site : node_id;
  (* Fact at call *)
  d1 : d;
  (* Return site *)
  return_site : node_id;
  (* Fact at return *)
  d2 : d;
}

(* Solver state *)
type ifds_state (d : Type) = {
  path_edges : set (path_edge d);
  summary_edges : set (summary_edge d);
  worklist : list (path_edge d);
}

(* --------------------------------------------------
   THE ALGORITHM
   -------------------------------------------------- *)

val solve : #d:Type -> ifds_problem d -> set (node_id * d)
let solve #d prob =
  (* Initialize with entry points *)
  let entries = get_entry_points prob.supergraph in
  let init_edges = Set.of_list (List.map (fun entry ->
    { proc_entry = entry; d1 = prob.zero; n = entry; d2 = prob.zero }
  ) entries) in
  let init_state = {
    path_edges = init_edges;
    summary_edges = Set.empty;
    worklist = Set.to_list init_edges;
  } in

  (* Main loop *)
  let rec process state =
    match state.worklist with
    | [] -> state
    | edge :: rest ->
      let state' = { state with worklist = rest } in
      let state'' = process_edge prob edge state' in
      process state''
  in
  let final = process init_state in
  (* Extract results *)
  Set.map (fun pe -> (pe.n, pe.d2)) final.path_edges

val process_edge : #d:Type -> ifds_problem d -> path_edge d ->
                   ifds_state d -> ifds_state d
let process_edge #d prob edge state =
  let n = edge.n in
  let d2 = edge.d2 in
  match get_node_type prob.supergraph n with

  (* ---------------------------------------------------------------------
     CASE 1: Call node
     --------------------------------------------------------------------- *)
  | NCall ->
    let callee = get_callee prob.supergraph n in
    let callee_entry = get_entry_node prob.supergraph callee in
    let return_site = get_return_site prob.supergraph n in

    (* Propagate to callee entry *)
    let callee_facts = prob.call_flow n d2 in
    let callee_edges = Set.map (fun d3 ->
      { proc_entry = callee_entry; d1 = d3; n = callee_entry; d2 = d3 }
    ) callee_facts in

    (* Apply existing summaries *)
    let matching_summaries = Set.filter (fun se ->
      se.call_site = n && Set.mem se.d1 callee_facts
    ) state.summary_edges in
    let summary_edges = Set.map (fun se ->
      { proc_entry = edge.proc_entry; d1 = edge.d1;
        n = return_site; d2 = se.d2 }
    ) matching_summaries in

    (* Call-to-return flow (for facts not passed to callee) *)
    let ctr_facts = prob.call_to_return_flow n d2 in
    let ctr_edges = Set.map (fun d3 ->
      { proc_entry = edge.proc_entry; d1 = edge.d1;
        n = return_site; d2 = d3 }
    ) ctr_facts in
    propagate_all (Set.unions [callee_edges; summary_edges; ctr_edges]) state

  (* ---------------------------------------------------------------------
     CASE 2: Exit node
     --------------------------------------------------------------------- *)
  | NExit proc ->
    let callers = get_call_sites prob.supergraph proc in
    (* For each caller with matching entry fact *)
    let new_edges = Set.concat_map (fun call_site ->
      let return_site = get_return_site prob.supergraph call_site in
      (* Find path edges reaching this call with matching callee entry fact *)
      let matching_paths = Set.filter (fun pe ->
        pe.n = call_site &&
        Set.mem edge.d1 (prob.call_flow call_site pe.d2)
      ) state.path_edges in
      Set.concat_map (fun caller_edge ->
        let d4 = caller_edge.d2 in
        let d5 = prob.return_flow call_site return_site d4 d2 in
        (* Create summary edge *)
        let new_summary = {
          call_site = call_site; d1 = edge.d1;
          return_site = return_site; d2 = d2
        } in
        (* Propagate to return site *)
        let return_edges = Set.map (fun d5' ->
          { proc_entry = caller_edge.proc_entry; d1 = caller_edge.d1;
            n = return_site; d2 = d5' }
        ) d5 in
        (new_summary, return_edges)
      ) matching_paths
    ) callers in
    let (new_summaries, new_path_edges) = Set.partition_pair new_edges in
    let state' = { state with
      summary_edges = Set.union state.summary_edges new_summaries
    } in
    propagate_all (Set.flatten new_path_edges) state'

  (* ---------------------------------------------------------------------
     CASE 3: Ordinary node
     --------------------------------------------------------------------- *)
  | _ ->
    let successors = get_cfg_successors prob.supergraph n in
    let new_edges = Set.concat_map (fun succ ->
      let d3_set = prob.flow_function
        { source = n; target = succ; label = CfgNext } d2 in
      Set.map (fun d3 ->
        { proc_entry = edge.proc_entry; d1 = edge.d1; n = succ; d2 = d3 }
      ) d3_set
    ) successors in
    propagate_all new_edges state

val propagate_all : #d:Type -> set (path_edge d) -> ifds_state d -> ifds_state d
let propagate_all #d edges state =
  let new_edges = Set.diff edges state.path_edges in
  { state with
    path_edges = Set.union state.path_edges new_edges;
    worklist = Set.to_list new_edges @ state.worklist }
\end{fstarcode}

\textbf{Complexity Analysis}: Let $N$ = number of nodes in supergraph, $E$ = number of edges, $D$ = size of dataflow domain.

\textbf{Space}: Path edges: $\BigO{N \times D^2}$ --- bounded by (proc\_entry, $d_1$, $n$, $d_2$). Summary edges: $\BigO{\text{Call\_sites} \times D^2}$. Total: $\BigO{N \times D^2}$.

\textbf{Time}: Each path edge processed once: $\BigO{N \times D^2}$ iterations. Each iteration: $\BigO{D}$ work for flow functions. Total: $\BigO{N \times D^3} = \BigO{E \times D^3}$ since $E \geq N$.

\textbf{Key Insight}: Polynomial in $D$, not exponential! This is because we track (entry\_fact, current\_fact) pairs, not full paths through the exploded graph.

\begin{pillarbox}[title={Bidirectional IFDS Extension (FlowDroid)}]
\textbf{Source}: Arzt 2014 (FlowDroid). Cross-reference: Section~8.1.6.

For HEAP-SENSITIVE taint analysis, standard forward-only \IFDS{} is insufficient. FlowDroid extends \IFDS{} with bidirectional analysis:
\begin{itemize}
  \item \textbf{Forward}: Propagate taint from sources, spawn backward on heap writes
  \item \textbf{Backward}: Find heap aliases, spawn forward with INACTIVE taint
\end{itemize}

The two directions SPAWN each other:
\begin{itemize}
  \item Forward $\rightarrow$ finds \texttt{p.f = tainted} $\rightarrow$ spawns Backward to find aliases of \texttt{p.f}
  \item Backward $\rightarrow$ finds \texttt{q} aliased to \texttt{p} $\rightarrow$ spawns Forward with (\texttt{q.f}, INACTIVE)
\end{itemize}

\textbf{Important}: This is NOT pure \IFDS{}!
\begin{itemize}
  \item Forward taint propagation: \IFDS{} (distributive)
  \item Backward alias finding: NOT \IFDS{} (may-alias is non-distributive)
  \item Integration: Ad-hoc spawning mechanism
\end{itemize}

A cleaner formalization would use \IDE{} (Section~\ref{sec:flix-lattice}) for the backward phase. See Section~8.1.6.1 for full activation statement semantics.
\end{pillarbox}


%--------------------------------------------------
\section{Common IFDS Problems}
\label{sec:ifds-problems}
%--------------------------------------------------

IFDS is a general framework that can express many dataflow analyses. Each instantiation requires defining: (1) a finite domain $D$ of dataflow facts, (2) flow functions for different edge types, and (3) the distributive merge operation (set union). The following code demonstrates two classic instantiations:

\textbf{Reaching Definitions}: The domain consists of (variable, definition-site) pairs. Flow functions implement gen/kill: assignments \emph{generate} new definitions and \emph{kill} previous definitions of the same variable. This analysis answers: ``Which definitions of variable $v$ can reach program point $p$?''

\textbf{Taint Analysis}: The domain tracks tainted variables and fields. Sources introduce taint, sanitizers remove it, and assignments propagate it. This analysis answers: ``Can user input reach a security-sensitive sink?'' The taint analysis problem is foundational for detecting injection vulnerabilities.

\begin{fstarcode}[title={Instantiations of IFDS for Common Analyses}]
(* --------------------------------------------------
   REACHING DEFINITIONS
   -------------------------------------------------- *)

type reaching_def = { var : string; def_site : node_id }

let reaching_definitions_problem (cpg : cpg) : ifds_problem reaching_def = {
  supergraph = cpg;
  domain = all_definitions cpg;
  zero = { var = ""; def_site = 0 };  (* Dummy zero *)

  flow_function = fun edge d ->
    let n = edge.source in
    match get_defined_var cpg n with
    | Some v when d.var = v ->
        (* Kill: this definition kills previous defs of same var *)
        Set.empty
    | Some v ->
        (* Gen: add this definition, keep others *)
        Set.add { var = v; def_site = n } (Set.singleton d)
    | None ->
        Set.singleton d;  (* Pass through *)

  call_flow = fun call_site d ->
    (* Pass definitions through call *)
    Set.singleton d;

  return_flow = fun call_site return_site d_call d_exit ->
    (* Definitions from callee flow back *)
    Set.singleton d_exit;

  call_to_return_flow = fun call_site d ->
    (* Local definitions not affected by call *)
    if is_local_def cpg d.var then Set.singleton d else Set.empty;
}

(* --------------------------------------------------
   TAINT ANALYSIS (via IFDS)
   Source: Livshits 2005
   -------------------------------------------------- *)

type taint_fact =
  | TaintedVar : var:string -> taint_fact
  | TaintedField : base:string -> field:string -> taint_fact
  | TaintedReturn : taint_fact  (* Return value is tainted *)

let taint_analysis_problem
  (cpg : cpg)
  (sources : set node_id)
  (sanitizers : set node_id)
: ifds_problem taint_fact = {
  supergraph = cpg;
  domain = all_taint_facts cpg;
  zero = TaintedVar "";  (* Dummy *)

  flow_function = fun edge d ->
    let n = edge.source in
    (* Source: introduce taint *)
    if Set.mem n sources then
      match get_assigned_var cpg n with
      | Some v -> Set.add (TaintedVar v) (Set.singleton d)
      | None -> Set.singleton d
    (* Sanitizer: remove taint *)
    else if Set.mem n sanitizers then
      match get_assigned_var cpg n with
      | Some v when d = TaintedVar v -> Set.empty
      | _ -> Set.singleton d
    (* Assignment: propagate taint *)
    else match get_assignment cpg n with
    | Some (lhs, rhs_vars) ->
        let rhs_tainted = List.exists (fun v -> d = TaintedVar v) rhs_vars in
        if rhs_tainted then
          Set.add (TaintedVar lhs) (Set.singleton d)
        else if d = TaintedVar lhs then
          Set.empty  (* Overwritten with clean value *)
        else
          Set.singleton d
    | None -> Set.singleton d;

  call_flow = fun call_site d ->
    (* Map tainted actuals to tainted formals *)
    match d with
    | TaintedVar v ->
        let param_index = get_arg_index cpg call_site v in
        begin match param_index with
        | Some i -> Set.singleton (TaintedVar (get_formal cpg call_site i))
        | None -> Set.empty
        end
    | _ -> Set.empty;

  return_flow = fun call_site return_site d_call d_exit ->
    (* Map tainted return to tainted result variable *)
    match d_exit with
    | TaintedReturn ->
        begin match get_result_var cpg return_site with
        | Some v -> Set.singleton (TaintedVar v)
        | None -> Set.empty
        end
    | _ -> Set.empty;

  call_to_return_flow = fun call_site d ->
    (* Taint of locals not affected by call *)
    match d with
    | TaintedVar v when not (is_arg cpg call_site v) -> Set.singleton d
    | _ -> Set.empty;
}

(* LIMITATION: This basic IFDS taint is FLOW-INSENSITIVE for heap.
   For PRECISE heap taint with flow-sensitivity, see Section 8.1.6.1
   (FlowDroid activation statements) which extends IFDS with:
     - Access paths (x.f.g) instead of simple variables
     - Bidirectional analysis (forward taint + backward alias)
     - Activation statements for flow-sensitive heap precision

   For CROSS-LANGUAGE taint, see Section 9.1.4 (PolyCruise) which uses
   LISR for language-agnostic def/use analysis. *)

(* --------------------------------------------------
   UNINITIALIZED VARIABLE ANALYSIS
   -------------------------------------------------- *)

type uninit_fact =
  | Uninitialized : var:string -> uninit_fact

let uninitialized_analysis_problem (cpg : cpg) : ifds_problem uninit_fact = {
  supergraph = cpg;
  domain = Set.map (fun v -> Uninitialized v) (all_variables cpg);
  zero = Uninitialized "";

  flow_function = fun edge d ->
    let n = edge.source in
    match d with
    | Uninitialized v ->
        (* Declaration without init: add uninit fact *)
        if is_decl_without_init cpg n v then
          Set.singleton (Uninitialized v)
        (* Assignment: remove uninit fact *)
        else if assigns_to cpg n v then
          Set.empty
        (* Use of uninit var: REPORT BUG *)
        else if uses_var cpg n v then
          let _ = report_uninit_use cpg n v in
          Set.singleton d  (* Keep tracking *)
        else
          Set.singleton d;
  (* ... call/return flows ... *)
}
\end{fstarcode}


%--------------------------------------------------
\section{IFDS Implementation Optimizations}
\label{sec:ifds-optimizations}
%--------------------------------------------------

\textbf{Sources}: Reps, Horwitz, Sagiv 1995; Naeem et al. 2010

\begin{pillarbox}[title={Cross-References}]
\begin{itemize}
  \item \IFDS{} is DISTRIBUTIVE fragment only --- see Section~12.18 (Set Constraints) and Appendix~D.10.1 for non-distributive alternatives
  \item Taint analysis is classic \IFDS{} application --- see Section~8.1
  \item \IFDS{} is OVER-approximate; for under-approximate bug finding use Eval algorithm --- see Section~\ref{sec:under-approx}
  \item For SOURCE-SINK problems (leak detection), consider SVF (Section~5.6) as alternative --- SVF uses sparse value-flow graphs instead of exploded supergraph, which can be more efficient when memory regions $R \ll$ domain $D$
\end{itemize}
\end{pillarbox}


\subsection{Representation Relations}
\label{sec:repr-relations}

\begin{fstarcode}[title={Representation Relations (RHS95 Section 4)}]
(* ==================================================
   Key insight: Distributive functions can be compactly represented.
   ================================================== *)

(* --------------------------------------------------
   THEOREM: A function f : 2^D -> 2^D is distributive iff:
     f(X \cup  Y) = f(X) \cup  f(Y)

   Such functions can be encoded as a RELATION R \subseteq  (D \cup  {0}) \times  D
   where (d_1, d_2) \in  R means "if d_1 holds, then d_2 is generated"

   SPACE COMPLEXITY: O(D^2) instead of O(2^D) for arbitrary functions
   COMPOSITION: R_1 ; R_2 = { (a,c) | \exists b. (a,b) \in  R_1 \land  (b,c) \in  R_2 }
                Relation composition = Function composition!
   -------------------------------------------------- *)

type repr_relation (d : Type) = set (option d * d)
  (* None represents the "zero" fact - unconditional generation *)

(* Convert a transfer function to its representation relation *)
val repr_of_transfer : #d:Type -> all_facts:set d -> (set d -> set d) ->
                       repr_relation d
let repr_of_transfer #d all_facts f =
  (* For each input fact (including 0), compute generated facts *)
  let zero_gen = f Set.empty in  (* Unconditional generation: f({}) *)
  let zero_edges = Set.map (fun d2 -> (None, d2)) zero_gen in
  (* For each fact d1, compute what d1 generates *)
  let fact_edges = Set.concat_map (fun d1 ->
    let out = f (Set.singleton d1) in
    Set.map (fun d2 -> (Some d1, d2)) out
  ) all_facts in
  Set.union zero_edges fact_edges

(* Compose two representation relations *)
val compose_repr : #d:Type -> repr_relation d -> repr_relation d ->
                   repr_relation d
let compose_repr #d r1 r2 =
  (* R_1 ; R_2 = relational composition *)
  Set.concat_map (fun (a, b) ->
    let matching = Set.filter (fun (b', c) ->
      match (b, b') with
      | (Some x, Some y) -> x = y
      | (None, None) -> true
      | _ -> false
    ) r2 in
    Set.map (fun (_, c) -> (a, c)) matching
  ) r1

(* Apply a representation relation to get output facts *)
val apply_repr : #d:Type -> repr_relation d -> set d -> set d
let apply_repr #d r input =
  (* Output = { d2 | (0, d2) \in  R } \cup  { d2 | \exists d1 \in  input. (d1, d2) \in  R } *)
  let from_zero = Set.filter_map (fun (src, tgt) ->
    match src with None -> Some tgt | Some _ -> None
  ) r in
  let from_facts = Set.concat_map (fun d1 ->
    Set.filter_map (fun (src, tgt) ->
      match src with Some d when d = d1 -> Some tgt | _ -> None
    ) r
  ) input in
  Set.union from_zero from_facts

(* --------------------------------------------------
   THEOREM (Correctness of Representation)
   For any distributive f and its representation R:
     apply_repr R input = f input
   -------------------------------------------------- *)

val repr_correct :
  #d:Type -> all_facts:set d -> f:(set d -> set d) ->
  Lemma (requires is_distributive f)
        (ensures forall input. apply_repr (repr_of_transfer all_facts f) input
                               = f input)
\end{fstarcode}


\subsection{H-Sparse Optimization}
\label{sec:h-sparse}

\begin{fstarcode}[title={H-Sparse Optimization (Naeem et al. 2010)}]
(* ==================================================
   Observation: Most transfer functions affect only h << D facts.
   "Sparse" = few facts generated or killed per edge.
   ================================================== *)

(*
  COMPLEXITY IMPROVEMENT:
    Standard IFDS:  O(E \cdot  D^3)
    H-sparse IFDS:  O(Call \cdot  D^3 + h \cdot  E \cdot  D^2)
    where h = max facts affected per edge (the "sparsity parameter")

  PRACTICAL EXAMPLES:
    For taint analysis: h \approx  2-3 (one source, one propagation per stmt)
    For null analysis:  h \approx  1-2 (one variable nullified per stmt)
    For live variables: h \approx  2   (one def, one use per stmt typically)

  INTUITION: Most statements touch few variables, so most transfer
  functions are nearly identity. Exploit this sparsity!
*)

type sparse_repr (d : Type) = {
  gen : set d;              (* Facts generated unconditionally *)
  kill : set d;             (* Facts killed (removed from input) *)
  propagate : set (d * d);  (* Conditional propagation: d1 \to  d2 *)
  (* INVARIANT: |gen| + |kill| + |propagate| \leq  h *)
}

(* Check if a representation relation is h-sparse *)
val is_h_sparse : #d:Type -> repr_relation d -> h:nat -> bool
let is_h_sparse #d r h =
  Set.size r <= h * h  (* At most h^2 edges in representation *)

(* Convert full representation to sparse form (if possible) *)
val to_sparse_repr : #d:Type -> all_facts:set d -> repr_relation d ->
                     option (sparse_repr d)
let to_sparse_repr #d all_facts r =
  (* gen = facts generated from zero (unconditional) *)
  let gen = Set.filter_map (fun (src, tgt) ->
    match src with None -> Some tgt | _ -> None
  ) r in
  (* identity = facts that map to themselves *)
  let identity_facts = Set.filter (fun d ->
    Set.mem (Some d, d) r
  ) all_facts in
  (* kill = facts in domain but NOT in identity *)
  let kill = Set.diff all_facts identity_facts in
  (* propagate = non-identity, non-zero mappings *)
  let propagate = Set.filter (fun (src, tgt) ->
    match src with
    | Some d when d <> tgt -> true
    | _ -> false
  ) r in
  Some { gen; kill;
         propagate = Set.map (fun (Some s, t) -> (s, t)) propagate }

(* Sparse propagation - only process affected facts *)
val propagate_sparse : #d:Type -> sparse_repr d -> set d -> set d
let propagate_sparse #d sr input =
  (* 1. Remove killed facts *)
  let after_kill = Set.diff input sr.kill in
  (* 2. Apply conditional propagations *)
  let propagated = Set.concat_map (fun d ->
    let targets = Set.filter_map (fun (d', d'') ->
      if d' = d then Some d'' else None
    ) sr.propagate in
    if Set.is_empty targets then Set.singleton d else targets
  ) after_kill in
  (* 3. Add generated facts *)
  Set.union sr.gen propagated

(* --------------------------------------------------
   THEOREM (Sparse Complexity)
   For h-sparse problems:
     Time:  O(Call \cdot  D^3 + h \cdot  E \cdot  D^2)
     Space: O(N \cdot  D^2 + Call \cdot  D^2)
   When h << D, this is significantly better than O(E \cdot  D^3)
   -------------------------------------------------- *)
\end{fstarcode}


\subsection{Locally Separable Problems (Gen/Kill)}
\label{sec:locally-separable}

\begin{fstarcode}[title={Locally Separable Problems (RHS95 Corollary)}]
(* ==================================================
   A problem is "locally separable" if ALL transfer functions are gen/kill:
     f(X) = gen \cup  (X \ kill)
   For such problems: O(E \cdot  D) instead of O(E \cdot  D^3) !!!
   ================================================== *)

(*
  EXAMPLES OF LOCALLY SEPARABLE PROBLEMS:
  1. REACHING DEFINITIONS:
     gen  = { def }                     -- this definition reaches
     kill = { prev defs of same var }  -- previous defs killed

  2. LIVE VARIABLES:
     gen  = { used vars }              -- used variables are live
     kill = { defined var }            -- defined var no longer live before

  3. AVAILABLE EXPRESSIONS:
     gen  = { computed expr }          -- expression now available
     kill = { exprs using modified var } -- invalidated expressions

  4. VERY BUSY EXPRESSIONS:
     gen  = { expr used on all paths } -- expression busy
     kill = { exprs with modified vars } -- no longer busy

  WHAT IS NOT LOCALLY SEPARABLE:
  - Pointer analysis (aliasing creates dependencies)
  - Constant propagation (values depend on other values)
  - Shape analysis (heap structure depends on operations)
*)

type gen_kill_function (d : Type) = {
  gen : set d;
  kill : set d;
}

(* Check if a transfer function is gen/kill form *)
val is_gen_kill : #d:Type -> (set d -> set d) -> option (gen_kill_function d)
let is_gen_kill #d f =
  (* A function is gen/kill iff:
     1. f({}) gives us the gen set
     2. For all d, either d \in  f({d}) (preserved) or d \notin  f({d}) (killed) *)
  let gen = f Set.empty in
  (* To find kill: facts d where d \notin  f({d}) *)
  (* This requires knowing the domain, simplified here *)
  Some { gen; kill = Set.empty (* computed from domain *) }

(* Check if an IFDS problem is locally separable *)
val is_locally_separable : #d:Type -> ifds_problem d -> bool
let is_locally_separable #d problem =
  (* All flow functions must be gen/kill *)
  forall_edges problem.supergraph (fun edge ->
    match is_gen_kill (problem.flow_function edge) with
    | Some _ -> true
    | None -> false
  )

(* --------------------------------------------------
   FAST SOLVER FOR LOCALLY SEPARABLE PROBLEMS
   Complexity: O(E \cdot  D) instead of O(E \cdot  D^3)
   KEY INSIGHT: For gen/kill, we don't need the full IFDS machinery.
   Each fact can be tracked independently!
   -------------------------------------------------- *)

val solve_gen_kill : #d:Type ->
  problem:ifds_problem d ->
  Lemma (requires is_locally_separable problem) ->
  (node_id -> set d)
let solve_gen_kill #d problem _ =
  (* For gen/kill, facts are independent - track each separately *)
  (* This is essentially running |D| separate bit-vector dataflows *)
  let solve_for_fact (fact : d) : set node_id =
    (* Standard worklist for single-fact reachability *)
    let rec worklist visited frontier =
      match frontier with
      | [] -> visited
      | n :: rest ->
          if Set.mem n visited then worklist visited rest
          else
            let visited' = Set.add n visited in
            let succs = get_successors problem.supergraph n in
            let live_succs = List.filter (fun succ ->
              let gk = get_gen_kill problem n succ in
              not (Set.mem fact gk.kill)  (* Not killed on this edge *)
            ) succs in
            worklist visited' (live_succs @ rest)
    in
    (* Also include nodes where fact is generated *)
    let gen_nodes = get_gen_nodes problem fact in
    worklist Set.empty (Set.to_list gen_nodes)
  in
  (* Combine results for all facts *)
  fun node ->
    Set.filter (fun fact ->
      Set.mem node (solve_for_fact fact)
    ) problem.domain

(*
  COMPLEXITY ANALYSIS:
    - For each fact: O(E) traversal
    - Total: O(D \cdot  E) = O(E \cdot  D)
    - Compare to IFDS: O(E \cdot  D^3)

  PRACTICAL SPEEDUP:
    For D = 1000 facts: 1000^3 = 10^9 vs 10^3 = factor of 10^6 improvement!
*)
\end{fstarcode}


\subsection{Demand-Driven IFDS}
\label{sec:demand-driven-ifds}

\begin{fstarcode}[title={Demand-Driven IFDS}]
(* ==================================================
   Standard IFDS: Compute ALL reachable facts (exhaustive, whole-program)
   Demand-driven: Only compute facts needed to answer a SPECIFIC QUERY
   ================================================== *)

(*
  USE CASE: "Is variable x tainted at line 42?"

  STANDARD IFDS:
    1. Run full taint analysis on entire program
    2. Look up result for (line 42, tainted(x))
    3. Cost: O(E \cdot  D^3) even if we only care about ONE fact at ONE location

  DEMAND-DRIVEN IFDS:
    1. Start from query point (line 42, tainted(x))
    2. Search BACKWARD: "how could this fact become true?"
    3. Stop when we reach a source or prove unreachable
    4. Cost: O(relevant subgraph) << O(full program)

  RELATION TO CFL-REACHABILITY (Section 4.2):
    Demand-driven IFDS is backward CFL-reachability in the exploded supergraph.
    The Dyck language ensures matched call/return context.

  DIFFERENCES FROM PURE CFL:
    - IFDS has transfer functions that transform facts
    - CFL just tracks reachability with grammar rules
    - Demand-driven IFDS = CFL + inverse transfer functions
*)

(* Query type: does a fact hold at a specific program point? *)
type ifds_query (d : Type) = {
  query_node : node_id;
  query_fact : d;
}

(* Demand-driven solver *)
val demand_driven_ifds :
  #d:Type ->
  problem : ifds_problem d ->
  query : ifds_query d ->
  bool  (* Does fact hold at node? *)

let demand_driven_ifds #d problem query =
  (* ALGORITHM: Backward search in exploded supergraph from query point *)
  let target = (query.query_node, query.query_fact) in
  let source = (start_main problem.supergraph, Zero) in

  (* Compute inverse transfer functions for backward search *)
  let inverse_flow edge d_out =
    (* Find d_in such that d_out \in  flow(edge)(d_in) *)
    Set.filter (fun d_in ->
      Set.mem d_out (problem.flow_function edge (Set.singleton d_in))
    ) (Set.add Zero problem.domain)
  in

  (* Backward reachability with context sensitivity *)
  let rec backward_search visited frontier =
    match frontier with
    | [] -> false  (* Query fact is not reachable from any source *)
    | (node, fact, call_stack) :: rest ->
        (* Check if we reached a source (entry of main with Zero fact) *)
        if node = fst source && fact = Zero then
          true  (* Found a valid path! *)
        else if Set.mem (node, fact, call_stack) visited then
          backward_search visited rest
        else
          let visited' = Set.add (node, fact, call_stack) visited in
          (* Get predecessors and inverse-flow facts *)
          let preds = get_predecessors problem.supergraph node in
          let new_frontier = List.concat_map (fun pred ->
            let edge = { source = pred; target = node } in
            let d_ins = inverse_flow edge fact in
            (* Handle call/return context *)
            match node_type problem.supergraph pred with
            | NCall call_site ->
                (* Push call site onto stack *)
                List.map (fun d -> (pred, d, call_site :: call_stack))
                         (Set.to_list d_ins)
            | NReturn ret_site ->
                (* Must match top of stack *)
                (match call_stack with
                 | call :: rest_stack when matches_return call ret_site ->
                     List.map (fun d -> (pred, d, rest_stack))
                              (Set.to_list d_ins)
                 | _ -> [])  (* Invalid context - prune this path *)
            | _ ->
                List.map (fun d -> (pred, d, call_stack)) (Set.to_list d_ins)
          ) preds in
          backward_search visited' (new_frontier @ rest)
  in
  backward_search Set.empty [(query.query_node, query.query_fact, [])]

(* --------------------------------------------------
   WHEN TO USE DEMAND-DRIVEN VS EXHAUSTIVE

   USE EXHAUSTIVE (standard IFDS) WHEN:
     - Need results for ALL program points
     - Building a whole-program summary
     - Analysis is cheap relative to program size

   USE DEMAND-DRIVEN WHEN:
     - Only need specific query answers
     - Interactive tools (IDE integration)
     - Incremental analysis after edits
     - Query is localized (few relevant paths)

   HYBRID APPROACH:
     1. Run fast over-approximate analysis (exhaustive)
     2. For reported issues, use demand-driven to verify
     3. See Section 4.3.3 for IFDS + Eval combination
   -------------------------------------------------- *)
\end{fstarcode}


\subsection{Summary: IFDS Complexity Variants}
\label{sec:ifds-complexity-summary}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Variant} & \textbf{Time Complexity} & \textbf{When to Use} \\
\hline
Standard IFDS & $\BigO{E \cdot D^3}$ & General distributive problems \\
H-sparse IFDS & $\BigO{\text{Call} \cdot D^3 + h \cdot E \cdot D^2}$ & Sparse facts (taint, null) \\
Locally separable & $\BigO{E \cdot D}$ & Gen/kill problems \\
Demand-driven & $\BigO{\text{relevant paths}}$ & Specific queries, IDE tools \\
\hline
\end{tabular}
\end{center}

Where: $E$ = edges in supergraph, $D$ = size of dataflow domain, $h$ = sparsity parameter (max facts affected per edge), Call = number of call sites.

\textbf{Reminder}: \IFDS{} requires DISTRIBUTIVE transfer functions! For non-distributive (pointer analysis): Use set constraints (Section~12.18). For under-approximate bug finding: Use Eval algorithm (Section~\ref{sec:under-approx}).


%--------------------------------------------------
\section{Datalog Compilation Strategy (Souffle)}
\label{sec:datalog-compilation}
%--------------------------------------------------

\textbf{Paper}: Jordan, Scholz, Subotic 2016 (CAV)

For high-performance deployment, \IFDS{} problems expressed as Datalog can be COMPILED to specialized code rather than interpreted.

\begin{pillarbox}[title={Key Insight: Compile, Don't Interpret}]
Jordan 2016 shows: Datalog-based analysis is elegant but SLOW when interpreted. Compilation achieves 50x+ speedup over bddbddb/muZ.

\textbf{Benchmark} (OpenJDK7: 1.4M variables, 350K objects, 160K methods):
\begin{itemize}
  \item Souffle (compiled): 35 seconds (CI points-to)
  \item bddbddb: 30 minutes
  \item SQLite: 6 hours 20 minutes
  \item muZ: Did not finish
\end{itemize}
\end{pillarbox}


\subsection{Staged Compilation via Futamura Projections}
\label{sec:futamura}

\textbf{Souffle Compilation Pipeline}:

\textbf{Stage 1}: Datalog $\rightarrow$ RAM (Relational Algebra Machine)
\[
P_{\text{RAM}} = \text{Mix}(\text{Int}_{\text{dl}}, I_{\text{db}})
\]
Where: $\text{Int}_{\text{dl}}$ = Semi-naive evaluation interpreter, $I_{\text{db}}$ = Intensional database (analysis rules). Result: Relational Algebra Machine program. Optimizations: Rule reordering, semi-naive transformation.

\textbf{Stage 2}: RAM $\rightarrow$ Optimized RAM. Index selection via DILWORTH'S THEOREM (see Section~\ref{sec:dilworth}). Join reordering for cache efficiency. Stratum computation for stratified negation.

\textbf{Stage 3}: RAM $\rightarrow$ C++/Rust
\[
P_{\text{C++}} = \text{Mix}(\text{Int}_{\text{RAM}}, P_{\text{RAM}})
\]
Via template metaprogramming: inlined comparison functions, specialized B-tree iterators, OpenMP parallel annotations.

\begin{theorem}[Semantic Preservation]
\[
\text{result} = \sem{\text{Int}}(\text{Source}, \text{Input}) = \sem{\text{Source}}_{\text{Int}}(\text{Input}) = \sem{\text{Mix}(\text{Int}, \text{Source})}(\text{Input}) = \sem{\text{Compiled}}(\text{Input})
\]
\end{theorem}


\subsection{Optimal Index Selection (Dilworth's Theorem)}
\label{sec:dilworth}

\textbf{Problem}: Given $N$ index requirements from queries, find MINIMAL set of indices such that each requirement is subsumed by at least one selected index.

\textbf{Insight}: Index subsumption forms a partial order. A lexicographic index $[a, b, c]$ subsumes $[a, b]$ and $[a]$. That is: if I can look up by $(a, b, c)$, I can also look up by $(a)$ or $(a, b)$.

\begin{theorem}[Dilworth's Theorem]
The width of a partial order equals the minimum number of chains needed to cover all elements.
\end{theorem}

\textbf{Algorithm} (polynomial time):
\begin{enumerate}
  \item Build lattice of required indices under subsumption
  \item Compute minimum chain partition (via bipartite matching)
  \item Select maximum element from each chain
\end{enumerate}

\textbf{Result}: For analyses with 100s of index requirements, reduces to minimal set. Each chain's maximum subsumes all requirements in that chain.

\textbf{Example}:
\begin{itemize}
  \item Required indices: $[a], [a,b], [a,c], [a,b,c], [b], [b,c]$
  \item Chain 1: $[a] < [a,b] < [a,b,c]$ $\rightarrow$ select $[a,b,c]$
  \item Chain 2: $[a,c]$ $\rightarrow$ select $[a,c]$
  \item Chain 3: $[b] < [b,c]$ $\rightarrow$ select $[b,c]$
  \item Minimal cover: $\{[a,b,c], [a,c], [b,c]\}$ instead of all 6 indices
\end{itemize}

\begin{fstarcode}[title={Datalog Compilation Types (Jordan et al. 2016)}]
module BrrrMachine.DatalogCompile

(* Relational Algebra Machine operations *)
type ram_expr =
  | RAMScan : relation:string -> ram_expr
  | RAMFilter : expr:ram_expr -> column:nat -> value:string -> ram_expr
  | RAMProject : expr:ram_expr -> columns:list nat -> ram_expr
  | RAMJoin : left:ram_expr -> right:ram_expr ->
              left_col:nat -> right_col:nat -> ram_expr
  | RAMUnion : left:ram_expr -> right:ram_expr -> ram_expr
  | RAMDiff : left:ram_expr -> right:ram_expr -> ram_expr

type ram_stmt =
  | RAMInsert : target:string -> source:ram_expr -> ram_stmt
  | RAMLoop : delta:string -> body:list ram_stmt -> ram_stmt  (* Semi-naive *)
  | RAMSeq : stmts:list ram_stmt -> ram_stmt

(* Index specification *)
type index_spec = {
  relation : string;
  key_columns : list nat;  (* Lexicographic order *)
}

(* Index subsumption: [a,b,c] subsumes [a,b] and [a] *)
let subsumes (super sub : index_spec) : bool =
  super.relation = sub.relation &&
  List.length sub.key_columns <= List.length super.key_columns &&
  List.for_all2 (=) sub.key_columns
    (List.take (List.length sub.key_columns) super.key_columns)

(* Dilworth-based minimal index selection *)
val compute_minimal_indices :
  required:list index_spec ->
  minimal:list index_spec{
    (* Every required index is subsumed by some minimal index *)
    forall r. List.mem r required ==>
      exists m. List.mem m minimal /\ subsumes m r
  }
\end{fstarcode}


\subsection{Implementation Strategy for brrr-machine}
\label{sec:brrr-datalog-strategy}

\begin{pillarbox}[title={Recommended Approach}]
\textbf{Development Mode}: Use interpreted Datalog for rapid iteration
\begin{itemize}
  \item Crepe (Rust embedded Datalog) for prototyping
  \item Souffle interpreter mode for debugging
  \item Modify rules without recompilation
\end{itemize}

\textbf{Production Mode}: Compile analysis rules to specialized Rust
\begin{itemize}
  \item Express \IFDS{}/\IDE{} as Datalog rules
  \item Compile via Souffle $\rightarrow$ C++ or custom Datalog$\rightarrow$Rust pipeline
  \item Link compiled analysis into brrr-machine
\end{itemize}

\textbf{Why not just use Souffle directly?}
\begin{itemize}
  \item Souffle generates C++, we want Rust integration
  \item We need lattice predicates (Section~\ref{sec:flix-lattice}) which Souffle lacks
  \item But Souffle's TECHNIQUES (RAM, Dilworth indices) are essential
\end{itemize}
\end{pillarbox}


%--------------------------------------------------
\section{Lattice-Extended Datalog and IDE (Flix)}
\label{sec:flix-lattice}
%--------------------------------------------------

\textbf{Paper}: Madsen, Yee, Lhotak 2016 (PLDI)

Standard Datalog operates on relations (finite sets). Many analyses require lattices with potentially infinite domains. Flix extends Datalog with lattice predicates, enabling elegant expression of \IFDS{}, \IDE{}, and value analyses.

\begin{pillarbox}[title={The Flix Insight: Relations vs Lattices}]
\textbf{Standard Datalog (rel)}:
\begin{verbatim}
rel Edge(x, y)
Multiple tuples = set
{Edge(1,2), Edge(1,3)} -> keeps both
\end{verbatim}

\textbf{Flix Extension (lat)}:
\begin{verbatim}
lat LocalVar(x: Var, v: Constant)
Same key = JOIN lattice values
{LocalVar(x, Cst(1)), LocalVar(x, Cst(2))} -> {LocalVar(x, Top)}
\end{verbatim}

\textbf{What this enables}:
\begin{itemize}
  \item Constant propagation (lattice = constants with Top)
  \item Interval analysis (lattice = intervals)
  \item \IDE{} algorithm (lattice = micro-function space)
  \item Strong update analysis (hybrid flow-sensitive/insensitive)
\end{itemize}
\end{pillarbox}


\subsection{Lattice Predicates and Transfer Functions}
\label{sec:flix-predicates}

\begin{verbatim}
// Standard Datalog relation - set semantics
rel AddExp(r: Var, x: Var, y: Var)    // r = x + y in source code

// Flix lattice predicate - join semantics
lat LocalVar(x: Var, v: Constant)     // x has abstract value v
//           ^^^^    ^^^^^^^^^^
//           key     lattice element (joined on same key)

// User-defined lattice
enum Constant {
  case Top,       // Unknown (join of all)
  case Cst(Int),  // Known constant
  case Bot        // Unreachable (bottom)
}

// Transfer function: MUST BE MONOTONE
def sum(e1: Constant, e2: Constant): Constant =
  match (e1, e2) with {
    case (Bot, _) | (_, Bot) => Bot      // Unreachable stays unreachable
    case (Cst(n1), Cst(n2))  => Cst(n1 + n2)
    case _                   => Top       // Unknown
  }

// Filter function: guards rule application
def isMaybeZero(e: Constant): Bool =
  match e with {
    case Bot    => false    // Unreachable - no error
    case Cst(n) => n == 0
    case Top    => true     // Could be zero
  }

// Flix rule with transfer function
LocalVar(r, sum(x, y)) :- AddExp(r, v1, v2),
                          LocalVar(v1, x),
                          LocalVar(v2, y).

// Flix rule with filter function
ArithmeticError(r) :- isMaybeZero(y),
                      DivExp(r, n, d),
                      LocalVar(d, y).
\end{verbatim}


\subsection{IDE as Flix with Micro-Function Lattice}
\label{sec:ide-flix}

\begin{pillarbox}[title={\IDE{} Is Not Complex---It's Just Flix with a Specific Lattice}]
\IFDS{} path edge: \texttt{PathEdge(d1, n, d2)} --- fact \texttt{d2} holds at \texttt{n}

\IDE{} path edge: \texttt{PathEdge(d1, n, d2, f)} --- with environment transformer $f$

The micro-function space forms a lattice under pointwise ordering:
\begin{align*}
\bot &= \lambda x.\, \bot \quad \text{(constant bottom function)} \\
\top &= \lambda x.\, \top \quad \text{(constant top function)} \\
f \sqcup g &= \lambda x.\, (f\, x) \sqcup (g\, x) \quad \text{(pointwise join)}
\end{align*}

\IDE{} key insight: transformers COMPOSE along paths:
\begin{verbatim}
PathEdge(d1, m, d3, compose(f, g)) :-
  PathEdge(d1, n, d2, f),
  CFG(n, m),
  EdgeFunction(n, d2, m, d3, g).
\end{verbatim}
\end{pillarbox}

\begin{fstarcode}[title={\IDE{} as Flix Instance (Madsen et al. 2016)}]
module BrrrMachine.IDE

(* Micro-function: environment transformer *)
type micro_fn (v : Type) = v -> v

(* Micro-functions form a lattice under pointwise ordering *)
instance micro_fn_lattice (v : Type) {| complete_lattice v |} :
  complete_lattice (micro_fn v) = {
  bot = (fun _ -> bot);
  top = (fun _ -> top);
  join = (fun f g -> fun x -> join (f x) (g x));
  meet = (fun f g -> fun x -> meet (f x) (g x));
  leq = (fun f g -> forall x. leq (f x) (g x));
}

(* IDE path edge: track micro-function along path *)
type ide_path_edge (d : Type) (v : Type) = {
  entry_fact : d;
  current_node : node_id;
  current_fact : d;
  transformer : micro_fn v;
}

(* Composition is the IDE transfer function *)
let ide_compose (#v:Type) (f g : micro_fn v) : micro_fn v =
  fun x -> f (g x)

(* Composition is monotone in both arguments *)
val ide_compose_monotone : #v:Type -> {| complete_lattice v |} ->
  f1:micro_fn v -> f2:micro_fn v -> g1:micro_fn v -> g2:micro_fn v ->
  Lemma (requires micro_fn_leq f1 f2 /\ micro_fn_leq g1 g2)
        (ensures micro_fn_leq (ide_compose f1 g1) (ide_compose f2 g2))

(* --------------------------------------------------
   WHEN TO USE IDE vs IFDS

   USE IFDS (Section 4.1):
     - Taint analysis (binary: tainted/untainted)
     - Uninitialized variables (set of "maybe uninitialized")
     - Typestate (finite state machine)
     - Any analysis where facts are BINARY or small finite set

   USE IDE:
     - Constant propagation (need to track actual constant values)
     - Linear constant propagation (x = a*y + b transformers)
     - Copy constant analysis (track "which variable copied from")
     - Any analysis where you need VALUE TRANSFORMATIONS along paths
   -------------------------------------------------- *)
\end{fstarcode}


\subsection{Semi-Naive Evaluation for Lattices}
\label{sec:semi-naive-lattice}

\textbf{Standard Semi-Naive (for relations)}:
\[
\delta_R = \text{new TUPLES added to } R
\]

\textbf{Flix Semi-Naive (for lattices)}:
\[
\delta_L = (\text{key}, \text{old\_value}, \text{new\_value}) \text{ where } \text{new\_value} \sqsupset \text{old\_value}
\]

The iteration terminates when no lattice element strictly increases.

\begin{theorem}[Madsen 2016, Theorem 1]
Every Flix program has a unique minimal model, computable via iteration, PROVIDED all transfer functions are monotone.
\end{theorem}

\textbf{Monotonicity Requirement}: For soundness, all transfer functions $f$ must satisfy:
\[
x \sqsubseteq y \implies f(x) \sqsubseteq f(y)
\]
This is the Flix equivalent of \IFDS{} distributivity requirement.

\begin{fstarcode}[title={Semi-Naive Evaluation for Lattice Predicates}]
(* Transfer function monotonicity - critical for soundness *)
type monotone_transfer (#l:Type) {| complete_lattice l |} =
  f:(l -> l){ forall x y. leq x y ==> leq (f x) (f y) }

(* Binary monotone transfer (e.g., addition in constant lattice) *)
type monotone_transfer2 (#l:Type) {| complete_lattice l |} =
  f:(l -> l -> l){
    forall x1 x2 y1 y2.
      leq x1 x2 /\ leq y1 y2 ==> leq (f x1 y1) (f x2 y2)
  }

(* Semi-naive iteration for lattice predicates *)
type lat_delta (k l : Type) = {
  changed_keys : set k;
  old_values : k -> l;
  new_values : k -> l;
  (* Invariant: forall k in changed_keys. old_values k \sqsubset  new_values k *)
}

val flix_semi_naive :
  #k:Type -> #l:Type -> {| complete_lattice l |} ->
  rules:list flix_rule ->
  initial:lat_predicate k l ->
  lat_predicate k l  (* Returns minimal model *)
\end{fstarcode}


%==================================================
\chapter{CFL-Reachability}
\label{sec:cfl-reachability}
%==================================================

\textbf{Paper}: Reps 1997

\CFL{}-reachability generalizes \IFDS{} by allowing arbitrary context-free grammars to describe valid paths, not just matched parentheses.


%--------------------------------------------------
\section{The Framework}
\label{sec:cfl-framework}
%--------------------------------------------------

\begin{definition}[CFL-Reachability]
Given:
\begin{itemize}
  \item Graph $G = (V, E)$ with edge labels from alphabet $\Sigma$
  \item Context-free grammar $\mathcal{G}$ with terminals $\Sigma$
  \item Start symbol $S$
\end{itemize}

\textbf{Question}: For which pairs $(u, v)$ is there a path from $u$ to $v$ whose edge labels form a string in $L(\mathcal{G})$?
\end{definition}

\textbf{The Dyck Language (matched parentheses)}:
\[
S \rightarrow S\, S \mid (_i\, S\, )_i \mid \varepsilon \quad \text{for each call site } i
\]
This is exactly what \IFDS{} uses for context sensitivity.

\textbf{Other Useful Grammars}:

\textit{Field-sensitive alias analysis}:
\begin{align*}
\text{FlowsTo} &\rightarrow \texttt{new} \\
&\mid \text{FlowsTo}\ \texttt{assign} \\
&\mid \text{FlowsTo}\ \texttt{load}\ \text{FlowsTo}\ \texttt{store}
\end{align*}
``x flows to y if there's a path: new, then assigns, then matched load/store on same field''

\textit{Typestate analysis}:
\begin{align*}
\text{Valid} &\rightarrow \texttt{open}\ \text{Valid}\ (\texttt{read} \mid \texttt{write})^*\ \texttt{close} \\
&\mid \text{Valid}\ \text{Valid}
\end{align*}
``Valid use is: open, then reads/writes, then close''


%--------------------------------------------------
\section{Demand-Driven Analysis via CFL}
\label{sec:demand-cfl}
%--------------------------------------------------

\textbf{Paper}: Sridharan 2005

Demand-driven analysis answers specific queries without computing the full solution. For points-to analysis, instead of computing $\mathit{pts}(v)$ for all variables (expensive), we compute on-demand for a single variable at a specific program point. This is implemented as \emph{backward} CFL-reachability: starting from the query $(p, x)$, we search backward through assignments and field accesses until we reach allocation sites.

The CFL grammar for demand-driven points-to is: $\text{FlowsTo} \to \texttt{new} \mid \texttt{assign}\ \text{FlowsTo} \mid \texttt{load}_f\ \text{PointsTo}\ \texttt{store}_f\ \text{FlowsTo}$. The matched parentheses ensure field-sensitivity (only matching load/store on the same field). This approach achieves significant speedups when few queries are needed, as is common in IDE tools and incremental analysis.

\begin{fstarcode}[title={Demand-Driven Points-To Analysis (Sridharan et al. 2005)}]
(*
  KEY INSIGHT:
  Instead of computing points-to for ALL variables (expensive),
  compute on-demand for specific queries.

  Query: "What does variable x point to at program point p?"

  Algorithm:
    1. Start backward search from (p, x)
    2. Follow assign edges backward: x = y means search for y
    3. Follow load/store with matched fields: x = y.f, z.f = w
    4. Stop at allocation sites: new T

  This is CFL-reachability with grammar:
    FlowsTo -> new
            | assign FlowsTo
            | load_f PointsTo store_f FlowsTo
*)

type pts_edge_label =
  | New : alloc_site:node_id -> pts_edge_label
  | Assign : pts_edge_label
  | Load : field:string -> pts_edge_label
  | Store : field:string -> pts_edge_label

(* Demand-driven points-to query *)
val points_to_query : cpg -> node_id -> string -> set node_id
let points_to_query cpg point var =
  (* Build PEG (Pointer Expression Graph) *)
  let peg = build_peg cpg in
  (* Backward CFL-reachability from (point, var) *)
  let rec search visited (node, var) =
    if Set.mem (node, var) visited then Set.empty
    else
      let visited' = Set.add (node, var) visited in
      (* Check incoming edges *)
      let edges = get_incoming_peg_edges peg (node, var) in
      Set.concat_map (fun edge ->
        match edge.label with
        | New alloc_site ->
            Set.singleton alloc_site  (* Found an allocation! *)
        | Assign ->
            search visited' edge.source
        | Load field ->
            (* Need to find matching store *)
            let base = get_base_var edge in
            let base_pts = search visited' (edge.source_node, base) in
            Set.concat_map (fun alloc ->
              (* Find stores to this field on this allocation *)
              let stores = find_stores peg alloc field in
              Set.concat_map (fun store_edge ->
                search visited' store_edge.source
              ) stores
            ) base_pts
        | Store _ ->
            Set.empty  (* Stores are targets, not sources *)
      ) edges
  in
  search Set.empty (point, var)
\end{fstarcode}


%--------------------------------------------------
\section{Interleaved Dyck and the Combined Context+Field Problem}
\label{sec:interleaved-dyck}
%--------------------------------------------------

\textbf{Sources}: Reps 2000, Conrado et al. 2025

\CFL{}-reachability (Section~\ref{sec:cfl-framework}) uses a \textbf{single Dyck language} for matched call/return. Field-sensitive alias analysis uses another Dyck language for matched load/store. \textbf{Combining both} requires \textbf{interleaved Dyck reachability}, which is \textbf{undecidable}.

\begin{pillarbox}[title={The Interleaved Dyck Problem}]
\textbf{Context sensitivity}: $D_\alpha$ = matched parentheses $(\quad)$

\textbf{Field sensitivity}: $D_\beta$ = matched brackets $[\quad]$

\textbf{Interleaved Language} $I_{\alpha,\beta}$: A string $s$ is in $I_{\alpha,\beta}$ iff:
\begin{itemize}
  \item $s$ restricted to $(\,)$ is in $D_\alpha$ (valid call/return)
  \item $s$ restricted to $[\,]$ is in $D_\beta$ (valid load/store)
\end{itemize}

\textbf{Example valid string}: $(_{1}\, [_f\, (_{2}\, ]_f\, )_{2}\, [_g\, ]_g\, )_{1}$

Projections: $(_{1} (_{2} )_{2} )_{1}$ = valid $D_\alpha$; $[_f ]_f [_g ]_g$ = valid $D_\beta$

\begin{theorem}[Reps 2000 --- Undecidability]
Interleaved Dyck reachability is UNDECIDABLE. Reduction from Post Correspondence Problem.
\end{theorem}

\textbf{Practical Consequence}: Cannot have BOTH context-sensitivity AND field-sensitivity with: (1) Soundness (no false negatives), (2) Completeness (no false positives), (3) Decidability (termination). Must sacrifice ONE property.
\end{pillarbox}

Two principled solutions exist: \textbf{MCFL underapproximation} (Section~\ref{sec:mcfl}) sacrifices completeness, while \textbf{SPDS overapproximation} (Section~\ref{sec:spds}) sacrifices soundness of the precision claim.


%--------------------------------------------------
\section{Multiple Context-Free Language Reachability (MCFL)}
\label{sec:mcfl}
%--------------------------------------------------

\textbf{Paper}: Conrado, Kjelstrom, Pavlogiannis, van de Pol 2025

MCFL provides a \textbf{decidable underapproximation} of interleaved Dyck via a hierarchy of increasingly expressive languages.

\begin{pillarbox}[title={MCFL Hierarchy}]
\begin{itemize}
  \item 1-MCFL = CFL (context-free languages, $\BigO{n^3}$ reachability)
  \item 2-MCFL strictly contains 1-MCFL ($\BigO{n^4}$ reachability)
  \item $d$-MCFL strictly contains $(d-1)$-MCFL ($\BigO{n^{2d}}$ reachability)
\end{itemize}

\textbf{Completeness in Limit}: For any string $s \in I_{\alpha,\beta}$, there exists $d$ such that $s$ is in $d$-MCFL. Union over all $d$ gives exactly $I_{\alpha,\beta}$.

\textbf{Practical Finding (Conrado 2025)}: 2-MCFL matches overapproximation in 8/11 benchmarks. 2-MCFL confirms 94.3\% of paths on remaining benchmarks. $d=2$ suffices for most real taint analysis problems.
\end{pillarbox}

The following F* code formalizes MCFGs. The key insight is that MCFG nonterminals have \emph{arity}: they derive \emph{tuples} of strings rather than single strings. A $d$-MCFG(r) grammar has dimension $d$ (maximum arity) and rank $r$ (maximum nonterminals per rule). The type signatures enforce well-formedness invariants: \texttt{wf\_arity} ensures each production produces the correct tuple size, \texttt{wf\_rank} bounds rule complexity, and \texttt{wf\_dimension} bounds nonterminal arity.

\begin{fstarcode}[title={Multiple Context-Free Grammar (MCFG) Definition}]
module BrrrMachine.MCFG

(* A nonterminal with arity k derives k-tuples of strings *)
type mcfg_nonterminal = {
  name: string;
  arity: pos  (* Number of string components it derives, >= 1 *)
}

(* Right-hand side element: terminal or variable reference *)
type mcfg_rhs_elem =
  | MCFGTerminal : char -> mcfg_rhs_elem
  | MCFGVariable : nt_idx:nat -> component:nat -> mcfg_rhs_elem

(* Production rule in d-MCFG(r) *)
type mcfg_rule (d r: pos) = {
  lhs: mcfg_nonterminal;
  lhs_patterns: list (list mcfg_rhs_elem);  (* arity-many patterns *)
  rhs_nts: list mcfg_nonterminal;           (* up to r nonterminals *)

  (* Well-formedness invariants *)
  wf_arity: List.length lhs_patterns = lhs.arity;
  wf_rank: List.length rhs_nts <= r;
  wf_dimension: lhs.arity <= d
}

(* d-MCFG(r): dimension d, rank r *)
type mcfg (d r: pos) = {
  nonterminals: list mcfg_nonterminal;
  terminals: set char;
  rules: list (mcfg_rule d r);
  start: mcfg_nonterminal;
  start_arity_1: start.arity = 1
}

(* The G_d^+ grammar for approximating interleaved Dyck *)
val construct_interleaved_grammar : d:pos -> k:pos -> mcfg d 2

(* Soundness: derived strings are in interleaved Dyck *)
val grammar_sound : d:pos -> k:pos -> s:string ->
  Lemma (requires s `in_language` (construct_interleaved_grammar d k))
        (ensures is_interleaved_dyck s)

(* Completeness in limit: every interleaved Dyck string is captured *)
val grammar_complete_limit : k:pos -> s:string ->
  Lemma (requires is_interleaved_dyck s)
        (ensures exists d. s `in_language` (construct_interleaved_grammar d k))
\end{fstarcode}

\textbf{Complexity Bounds (Conrado 2025)}:

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Language Class} & \textbf{Reachability Complexity} & \textbf{Lower Bound} \\
\hline
CFL / 1-MCFL & $\BigO{n^3}$ & BMM ($n^3$) \\
$d$-MCFL(1) & $\BigO{n^{2d}}$ & SETH \\
$d$-MCFL($r$) & $\BigO{n^{d(r+1)}}$ & SETH \\
Interleaved & Undecidable & PCP \\
\hline
\end{tabular}
\end{center}

The SETH lower bound shows $\BigO{n^{2d}}$ is essentially optimal for $d$-MCFL(1).


%--------------------------------------------------
\section{Synchronized Pushdown Systems (SPDS)}
\label{sec:spds}
%--------------------------------------------------

\textbf{Paper}: Spath, Ali, Bodden 2019

SPDS provides an \textbf{automaton-based approach} to combined context+field sensitivity via synchronized pushdown systems, achieving polynomial complexity under a \textbf{precision hypothesis}.

\begin{pillarbox}[title={Synchronized Pushdown Systems (SPDS)}]
\textbf{Idea}: Use TWO pushdown automata that operate synchronously:
\begin{itemize}
  \item $P_F$: Field PDS (stack encodes field access sequence)
  \item $P_S$: Stack PDS (stack encodes calling context)
  \item Sync: Synchronization predicate on transitions
\end{itemize}

\textbf{Encoding}:
\begin{itemize}
  \item Field store \texttt{x.f = y}: push rule $(l, \varepsilon) \longrightarrow (l', f)$
  \item Field load \texttt{y = x.f}: pop rule $(l, f) \longrightarrow (l', \varepsilon)$
  \item Method call: push rule $(l, \varepsilon) \longrightarrow (l', c)$
  \item Method return: pop rule $(l, c) \longrightarrow (l', \varepsilon)$
\end{itemize}

\textbf{Key Innovation}: Field automaton $A_F$ represents set of valid access paths IMPLICITLY. Avoids exponential enumeration of access paths. $\BigO{N}$ automaton states vs $\BigO{2^N}$ explicit access paths.

\textbf{Precision Hypothesis (Spath 2019)}: An improperly matched call site does not induce a properly matched field access, and vice versa. Under this hypothesis, SPDS = infinite access path precision.
\end{pillarbox}

\begin{fstarcode}[title={Synchronized Pushdown Systems (Spath et al. 2019)}]
module BrrrMachine.SPDS

(* Stack symbols *)
type field_symbol = | FieldSym : string -> field_symbol | FEps
type call_symbol = | CallSiteSym : nat -> call_symbol | CEps

(* Pushdown configuration *)
type field_config = { f_state: nat; f_stack: list field_symbol }
type call_config = { c_state: nat; c_stack: list call_symbol }
type spds_config = field_config * call_config

(* Pushdown rules *)
type field_rule =
  | FPush : nat -> field_symbol -> nat -> field_symbol -> field_rule
  | FPop : nat -> field_symbol -> nat -> field_rule

type call_rule =
  | CPush : nat -> call_symbol -> nat -> call_symbol -> call_rule
  | CPop : nat -> call_symbol -> nat -> call_rule

(* Synchronization predicate *)
type sync_spec = field_rule -> call_rule -> bool

(* The full SPDS *)
type spds = {
  field_rules: set field_rule;
  call_rules: set call_rule;
  sync: sync_spec;
  initial: spds_config
}

(* Field automaton: implicitly represents set of valid access paths *)
type field_automaton = {
  fa_states: set nat;
  fa_initial: nat;
  fa_final: set nat;
  fa_transitions: map (nat * field_symbol) (set nat)
}

(* Post* computation via saturation *)
val post_star : set field_rule -> field_config -> field_automaton

(* SPDS synchronized reachability *)
val spds_post_star : spds -> set spds_config
let spds_post_star sys =
  let fa = post_star sys.field_rules (fst sys.initial) in
  let ca = post_star sys.call_rules (snd sys.initial) in
  (* Intersect and filter by synchronization *)
  filter_by_sync sys.sync (cartesian fa ca)

(* Complexity: O(|P_F|^3 * |P_S|^3 * |Q|^3) *)
val spds_complexity :
  sys:spds ->
  Lemma (time_complexity (spds_post_star sys) <=
         pow3 (size sys.field_rules) * pow3 (size sys.call_rules))
\end{fstarcode}

\textbf{Performance Results (Spath 2019, DaCapo Benchmark)}:

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Analysis} & \textbf{SPDS Speedup} & \textbf{Timeouts (Before/After)} \\
\hline
IO Property & 64x & 160 $\rightarrow$ 28 \\
Iterator Property & 83x & 137 $\rightarrow$ 3 \\
Vector Property & 1.8x & 57 $\rightarrow$ 25 \\
\hline
\end{tabular}
\end{center}

SPDS matches access-graph precision on all benchmarks with no false positives.

\begin{pillarbox}[title={Tension Resolution: CFL vs MCFL vs SPDS}]
\textbf{MCFL (Conrado 2025)}:
\begin{itemize}
  \item Grammar-based formalism
  \item Underapproximation (sound)
  \item First decidable interleaved Dyck
  \item Tight complexity bounds (SETH)
  \item Optimal for verification
\end{itemize}

\textbf{SPDS (Spath 2019)}:
\begin{itemize}
  \item Automaton-based formalism
  \item Overapproximation under hypothesis
  \item Practical WPDS encoding
  \item Proven speedups (64--83x)
  \item Optimal for bug finding
\end{itemize}

\textbf{Combined Use}:
\begin{itemize}
  \item Run MCFL underapprox: paths found are DEFINITELY reachable
  \item Run SPDS overapprox: paths NOT found are DEFINITELY unreachable
  \item Intersection: sound AND complete when they agree
  \item Conrado 2025 shows agreement in 8/11 benchmarks
\end{itemize}

\textbf{Recommendation}:
\begin{itemize}
  \item For taint verification (need soundness): Use MCFL
  \item For bug finding (need precision): Use SPDS
  \item For maximum precision: Combine both
\end{itemize}
\end{pillarbox}


%--------------------------------------------------
\section{Cross-Reference: Sparse Value-Flow Analysis (SVF)}
\label{sec:cfl-svf-crossref}
%--------------------------------------------------

For \textbf{source-sink reachability} problems (memory leaks, use-after-free, taint-to-sink), an alternative to \IFDS{}-based dataflow is \textbf{Sparse Value-Flow Analysis} (Section~5.6).

\begin{pillarbox}[title={SVF vs IFDS for Source-Sink Problems}]
Both use \CFL{}-reachability for context-sensitivity (Section~\ref{sec:cfl-framework}). The difference is in REPRESENTATION and PREREQUISITES:

\textbf{\IFDS{} (Section~\ref{sec:ifds})}:
\begin{itemize}
  \item Exploded supergraph: (program\_point, dataflow\_fact) pairs
  \item Self-contained: no pre-analysis required
  \item Best for: general dataflow, small finite domains
\end{itemize}

\textbf{SVF (Section~5.6)}:
\begin{itemize}
  \item Sparse VFG: nodes are variable definitions, edges are def-use chains
  \item REQUIRES pointer analysis for Memory SSA construction
  \item Best for: source-sink problems, address-taken variable tracking
\end{itemize}

For leak detection in C/C++, SVF typically achieves 10--50x speedup over dense \IFDS{} approaches (ISSTA 2012) due to sparse traversal.
\end{pillarbox}

\textbf{See Section~5.6} for complete SVF formalization including Memory SSA, SVFG construction rules, leak detection algorithms, and comparison with \IFDS{}.


%==================================================
\chapter{Under-Approximate Analysis (Bug Finding)}
\label{sec:under-approx}
%==================================================

\textbf{Sources}: Le et al. 2022 (ISL), Vanegue 2025 (Pulse-infinity), O'Hearn 2020

\begin{pillarbox}[title={Critical: IFDS is Over-Approximate. For Bug Finding, We Need Under-Approx.}]
\textbf{Over-Approximation (\IFDS{}, Section~\ref{sec:ifds})}:
\begin{itemize}
  \item Sound for ABSENCE: ``No taint found'' means truly safe
  \item May have FALSE POSITIVES: Reports bugs that don't exist
\end{itemize}

\textbf{Under-Approximation (This section)}:
\begin{itemize}
  \item Sound for PRESENCE: ``Bug found'' means truly a bug
  \item May have FALSE NEGATIVES: Misses some bugs
\end{itemize}

\textbf{Combined}: Use \IFDS{} to find candidates, then under-approx to verify.
\end{pillarbox}


%--------------------------------------------------
\section{The Eval Algorithm (Pulse/Infer)}
\label{sec:eval-algorithm}
%--------------------------------------------------

\textbf{Paper}: Calcagno et al. 2009, 2011 (Bi-Abduction, Infer)

The Eval algorithm performs forward symbolic execution with bi-abduction to discover both bugs AND missing preconditions.

\begin{fstarcode}[title={Eval: Forward Symbolic Execution with Bi-Abduction}]
(* --------------------------------------------------
   Unlike IFDS which propagates dataflow facts, Eval propagates
   separation logic assertions through the program.
   -------------------------------------------------- *)

type eval_state = {
  pre : assertion;      (* Discovered precondition (accumulated anti-frame) *)
  post : assertion;     (* Current symbolic state *)
  path : list node_id;  (* Execution path for witness *)
  exit : exit_condition; (* Ok or Er *)
}

val eval_stmt : eval_state -> ir_stmt -> list eval_state
(* May return multiple states for conditionals/loops *)

let eval_stmt state stmt =
  match stmt with
  | Assign (x, e) ->
      (* x := e --- update symbolic state *)
      let new_post = substitute state.post x (eval_expr e state.post) in
      [{ state with post = new_post }]

  | Load (x, ptr, field) ->
      (* x := ptr->field --- need ptr |-> {field: v} *)
      let required = points_to ptr field (fresh_var "v") in
      match biabduct state.post required with
      | None ->
          (* NULL DEREFERENCE: can't satisfy requirement *)
          [{ state with exit = Er;
             post = state.post `star` error "null_deref" }]
      | Some { anti_frame = m; frame = f } ->
          (* Add anti-frame to precondition, update post *)
          let state' = { state with
            pre = state.pre `star` m;
            post = f `star` (x |-> fresh_var "v");
          } in
          [state']

  | Store (ptr, field, v) ->
      (* ptr->field := v *)
      let required = points_to ptr field (fresh_var "_") in
      match biabduct state.post required with
      | None ->
          [{ state with exit = Er;
             post = state.post `star` error "null_deref" }]
      | Some { anti_frame = m; frame = f } ->
          [{ state with
            pre = state.pre `star` m;
            post = f `star` points_to ptr field v;
          }]

  | Free ptr ->
      (* free(ptr) --- need ptr |-> _ with UNIQUE capability *)
      let required = points_to ptr "_" (fresh_var "_") in
      match biabduct state.post required with
      | None ->
          [{ state with exit = Er; post = error "double_free_or_invalid" }]
      | Some { anti_frame = m; frame = f } ->
          (* Remove the freed memory from post *)
          [{ state with pre = state.pre `star` m; post = f }]

  | If (cond, then_branch, else_branch) ->
      (* Fork execution for both branches *)
      let then_state = { state with post = state.post `star` (cond = true) } in
      let else_state = { state with post = state.post `star` (cond = false) } in
      (* Prune infeasible paths *)
      let then_results = if sat then_state.post
                         then eval_block then_state then_branch
                         else [] in
      let else_results = if sat else_state.post
                         then eval_block else_state else_branch
                         else [] in
      then_results @ else_results

  | While (cond, body) ->
      (* UNDER-APPROXIMATE: Bounded unrolling, NOT widening *)
      eval_loop_bounded state cond body 3  (* k=3 unrollings *)

  | Call (ret, func, args) ->
      (* Use function summary if available *)
      match get_summary func with
      | Some summary ->
          apply_summary state summary args ret
      | None ->
          (* Inline or skip with havoc *)
          [{ state with post = havoc ret state.post }]

(* --------------------------------------------------
   BOUNDED LOOP UNROLLING (UNDER-APPROXIMATE)
   For BUG FINDING: unroll k times, then cut off.
   This is SOUND for finding bugs: any bug found is real.
   May MISS bugs that require more iterations.
   -------------------------------------------------- *)

val eval_loop_bounded : eval_state -> ir_expr -> ir_block -> nat ->
                        list eval_state
let eval_loop_bounded init_state cond body max_unroll =
  let rec unroll fuel state =
    if fuel = 0 then
      (* Cut off: return current state as "exited loop" *)
      [{ state with post = state.post `star` (cond = false) }]
    else
      (* Check loop condition *)
      let continue_state = { state with
                             post = state.post `star` (cond = true) } in
      let exit_state = { state with
                         post = state.post `star` (cond = false) } in
      let continue_results =
        if sat continue_state.post then
          let body_results = eval_block continue_state body in
          List.concat_map (fun s -> unroll (fuel - 1) s) body_results
        else []
      in
      let exit_results =
        if sat exit_state.post then [exit_state] else []
      in
      continue_results @ exit_results
  in
  unroll max_unroll init_state
\end{fstarcode}


%--------------------------------------------------
\section{ISL Triple Semantics}
\label{sec:isl-triples}
%--------------------------------------------------

\textbf{Paper}: Le et al. 2022 --- ``Finding Real Bugs in Big Programs with ISL''

Incorrectness Separation Logic (ISL) inverts the meaning of Hoare triples. While Hoare logic's $\{P\} C \{Q\}$ means ``ALL executions from $P$ end in $Q$'' (over-approximation), ISL's $[p]\ C\ [q]$ means ``SOME execution from $p$ ends in $q$'' (under-approximation). This makes ISL ideal for bug finding: if we prove $[p]\ C\ [\texttt{error}]$, we have demonstrated that an error is \emph{actually reachable}.

The following code shows how to convert Eval's exploration results into ISL triples. The function \texttt{eval\_to\_isl\_triple} runs Eval on a function and collects all states that terminate with errors. The \texttt{presumption} field captures what conditions were required (accumulated anti-frames), and the \texttt{result} field describes the error state.

\begin{fstarcode}[title={Incorrectness Separation Logic (ISL) Triples}]
(* --------------------------------------------------
   ISL Triple: [p] C [q; exit]
   Meaning: If execution starts in state satisfying p,
            and terminates with exit condition,
            then final state satisfies q.

   Key difference from Hoare logic:
   - Hoare: {P} C {Q} --- ALL executions from P end in Q (over-approx)
   - ISL: [p] C [q] --- SOME execution from p ends in q (under-approx)
   -------------------------------------------------- *)

(* ISL triple computed by Eval *)
val eval_to_isl_triple : cpg -> func_id -> isl_triple
let eval_to_isl_triple cpg func =
  let init_state = {
    pre = emp;  (* Start with empty precondition *)
    post = emp; (* Start with empty postcondition *)
    path = [];
    exit = Ok;
  } in
  let final_states = eval_func cpg func init_state in
  (* Collect error states *)
  let error_states = List.filter (fun s -> s.exit = Er) final_states in
  match error_states with
  | [] ->
      (* No bugs found *)
      { presumption = emp; code = func; result = emp; exit_cond = Ok }
  | errors ->
      (* Combine error states *)
      let combined_pre = List.fold_left star emp
                           (List.map (fun s -> s.pre) errors) in
      let combined_post = List.fold_left disj bot
                            (List.map (fun s -> s.post) errors) in
      { presumption = combined_pre;
        code = func;
        result = combined_post;
        exit_cond = Er }
\end{fstarcode}


%--------------------------------------------------
\section{Latent vs Manifest Errors}
\label{sec:latent-manifest}
%--------------------------------------------------

\textbf{Paper}: Le, Raad, Villard, Berdine, Dreyer, O'Hearn 2022 ``Finding Real Bugs in Big Programs with ISL''

\begin{pillarbox}[title={Key Contribution: Compositional Bug Reporting via Manifest/Latent Split}]
\textbf{Problem}: ISL generates many error specs. Which to report?

\textbf{Example}: \texttt{deref(x) \{ *x = 10; \}}

ISL triple: $[\texttt{x = NULL}]\ \texttt{deref(x)}\ [\texttt{er : x = NULL}]$

Is this a bug? Only if called with NULL. But we don't know callers.

\textbf{Solution}: Distinguish MANIFEST from LATENT errors.
\begin{itemize}
  \item \textbf{Manifest}: Bug reachable from ANY calling context
  \item \textbf{Latent}: Bug only reachable under specific preconditions
\end{itemize}

\textbf{Policy}: Report manifest bugs unconditionally. Use latent specs compositionally to find manifest bugs in callers.
\end{pillarbox}

\begin{definition}[Manifest Error (Le 2022, Section 3.2)]
An error triple $\models [p]\ C\ [\texttt{er} : q]$ denotes a MANIFEST error if:
\begin{enumerate}
  \item The presumption is trivial: $p \equiv \texttt{emp} \land \texttt{true}$
  \item The result is satisfiable: $\texttt{sat}(q)$
  \item All heap locations in $q$ are existentially quantified (fresh)
  \item All pure constraints in $q$ are satisfiable under any valuation
\end{enumerate}

Formally, for $q = \exists X_q.\, \kappa_q \land \pi_q$:
\begin{enumerate}
  \item $p \equiv \texttt{emp} \land \texttt{true}$ --- No precondition requirements
  \item $\texttt{sat}(q)$ holds --- Error state is reachable
  \item $\texttt{locs}(\kappa_q) \subseteq X_q$ --- Heap is fresh (not from caller)
  \item $\forall v.\, \texttt{sat}(\pi_q[v / Y \cup \texttt{locs}(\kappa_q)])$ --- Pure part always satisfiable
\end{enumerate}
\end{definition}

\textbf{Intuition}: Manifest = error reachable regardless of how function is called. The heap portion is freshly allocated (condition 3), so caller can't prevent error by providing different inputs.

\begin{theorem}[True Positives Property (Le 2022, Theorem 3.4)]
If procedure \texttt{f()} in a complete program has a MANIFEST error, then either:
\begin{enumerate}[label=(\alph*)]
  \item \texttt{f()} is dead code (not reachable from \texttt{main()}), OR
  \item There exists a concrete trace from \texttt{main()} to the error.
\end{enumerate}

\textbf{Consequence}: Manifest errors have 0\% false positive rate. If we report it, it's a real bug (unless dead code).
\end{theorem}

\begin{fstarcode}[title={Manifest Error Detection (Algorithmic)}]
type error_classification =
  | Manifest : error_classification      (* Report unconditionally *)
  | Latent : precondition:assertion -> error_classification
      (* Report at call site *)
  | LatentLeak : error_classification
      (* Report anyway - leaks are caller's fault rarely *)

val classify_error : isl_triple -> error_classification
let classify_error triple =
  match triple.exit_cond with
  | Ok -> failwith "Not an error triple"
  | Er ->
      let p = triple.presumption in
      let q = triple.result in
      (* Condition 1: Trivial presumption *)
      let trivial_pre = is_emp_and_true p in
      (* Condition 2: Satisfiable result *)
      let sat_result = sat q in
      (* Condition 3: Fresh heap locations *)
      let fresh_heap = all_locs_existentially_quantified q in
      (* Condition 4: Pure constraints satisfiable *)
      let pure_sat = pure_always_satisfiable q in

      if trivial_pre && sat_result && fresh_heap && pure_sat then
        Manifest
      else if is_memory_leak_error triple then
        LatentLeak  (* Report leaks even when latent *)
      else
        Latent triple.presumption

(* BUG REPORTING POLICY (Le 2022 Section 2.3) *)
val should_report : func_id -> isl_triple -> bool
let should_report func triple =
  match classify_error triple with
  | Manifest -> true
  | LatentLeak -> true  (* Always report leaks *)
  | Latent _ ->
      (* Report latent NPE only in main() *)
      is_main_function func && is_null_deref_error triple
\end{fstarcode}

\textbf{Practical Results (Pulse-X tool)}:

\textit{OpenSSL-1.0.1h} (2015, 2.83M bytes IR, 8,658 procedures):
\begin{itemize}
  \item Pulse-X: 26 bugs reported, 19 fixed (73\% fix rate)
  \item Infer: 80 bugs reported, 39 fixed (49\% fix rate)
  \item Pulse-X has HIGHER fix rate due to manifest filtering
\end{itemize}

\textit{OpenSSL-3.0.0} (2021):
\begin{itemize}
  \item Pulse-X found 15 NEW bugs, all confirmed and fixed by maintainers
  \item Including NPEs and memory leaks in core crypto code
\end{itemize}

\textbf{Comparison to Infer}:

\begin{center}
\begin{tabular}{|l|l|}
\hline
\textbf{INFER (Over-Approximate)} & \textbf{PULSE-X (Under-Approximate)} \\
\hline
Based on separation logic & Based on ISL \\
Proves ABSENCE of bugs & Proves PRESENCE of bugs \\
Uses heuristics for reporting & Uses manifest criterion \\
May have false positives & 0\% FP for manifest bugs \\
Wider coverage (all paths) & Targeted (bounded paths) \\
Needs widening for loops & Simple bounded unrolling \\
\hline
\end{tabular}
\end{center}

\textbf{Algorithmic Simplification}: Le 2022 Remark 1: The ISL-based algorithm is ``strikingly simple'' compared to over-approximate biabduction. Key reason: NO LOOP INVARIANTS NEEDED. Under-approximation uses bounded unrolling---sound for finding bugs that trigger within $k$ iterations.


%--------------------------------------------------
\section{Integration: IFDS + Eval Hybrid}
\label{sec:ifds-eval-hybrid}
%--------------------------------------------------

\begin{center}
\textbf{Hybrid Analysis Architecture}
\end{center}

\textbf{Phase 1: \IFDS{} (Fast, Over-Approximate)}

Run \IFDS{} with complexity $\BigO{ED^3}$ to produce candidate bugs (may include false positives), e.g., ``taint reaches sink at line 42''.

\textbf{Phase 2: Eval (Precise, Under-Approximate)}

Run Eval on backward slice to produce ISL triples with paths, e.g., $[\texttt{emp}]\ \text{slice}\ [\texttt{err; Er}]$.

\textbf{Phase 3: Classification}

For each \IFDS{} finding:
\begin{enumerate}
  \item Compute backward slice from finding
  \item Run Eval on slice
  \item Check manifest conditions (Le 2022 Definition 3.3)
  \item Classify as Manifest/Latent/Refuted
\end{enumerate}

Results:
\begin{itemize}
  \item \textbf{Manifest} $\rightarrow$ TRUE BUG (0\% FP by theorem)
  \item \textbf{Latent} $\rightarrow$ TRUE BUG with required context
  \item \textbf{Refuted} $\rightarrow$ FALSE POSITIVE (don't report)
\end{itemize}

\begin{fstarcode}[title={Hybrid Analysis Implementation}]
type hybrid_result =
  | Confirmed : classification:bug_classification ->
                witness:list node_id -> hybrid_result
  | Refuted : reason:string -> hybrid_result
  | Timeout : partial:option eval_state -> hybrid_result

val verify_ifds_finding_with_eval :
  cpg:cpg -> finding:dataflow_fact -> timeout_ms:nat -> hybrid_result

let verify_ifds_finding_with_eval cpg finding timeout =
  (* Step 1: Compute backward slice *)
  let slice = backward_slice cpg finding.sink_node in
  (* Step 2: Run Eval on slice with timeout *)
  match eval_with_timeout slice timeout with
  | Timeout partial -> Timeout partial
  | Complete final_states ->
      (* Step 3: Check if any state confirms the finding *)
      let confirming = List.filter (confirms_finding finding) final_states in
      match confirming with
      | [] -> Refuted "Eval found no path to error"
      | states ->
          (* Step 4: Build ISL triple and classify *)
          let triple = states_to_isl_triple states in
          let classification = classify_bug triple in
          Confirmed classification (extract_witness states)
\end{fstarcode}


% ==================================================
% END OF PART 4A - CONTINUES IN PART 4B
% Part 4B will contain:
%   - Section 4.4: Symbolic Execution (Path-Sensitive)
%     Including: King 1976, DART/CUTE, KLEE, QSYM, Soundness Spectrum
% ==================================================
\chapter{Symbolic Execution (Path-Sensitive)}
\label{ch:symex}

\textbf{Source}: King 1976 -- ``Symbolic Execution and Program Testing''

\begin{pillarbox}[title={Symbolic Execution vs Eval vs \IFDS}]
\textbf{\IFDS} (Section~\ref{ch:ifds}):
\begin{itemize}
    \item Path-\emph{insensitive} (merges at join points)
    \item Tracks \textsc{dataflow facts} (finite domain)
    \item $\BigO(ED^3)$ complexity
\end{itemize}

\textbf{Eval} (Section~\ref{sec:eval-algorithm}):
\begin{itemize}
    \item Path-\emph{sensitive} (explores paths separately)
    \item Tracks \textsc{separation logic assertions}
    \item Bi-abduction for compositionality
\end{itemize}

\textbf{Symbolic Execution} (This chapter):
\begin{itemize}
    \item Path-\emph{sensitive} with \textbf{path condition}
    \item Tracks \textsc{symbolic values} (expressions over inputs)
    \item SMT solver for path feasibility
\end{itemize}

\textbf{Use Case Guidance}:
\begin{itemize}
    \item Taint analysis $\to$ \IFDS (fast, whole-program)
    \item Memory bugs $\to$ Eval (separation logic)
    \item Numeric bugs $\to$ Symbolic Execution (precise arithmetic)
\end{itemize}
\end{pillarbox}

\begin{pillarbox}[title={Historical Evolution: Symbolic Execution Foundations}]
\textbf{1976: King} -- Pure Symbolic Execution
\begin{itemize}
    \item Original formulation: execute with symbolic values
    \item Path conditions track branch decisions
    \item \textbf{Limitation}: Path explosion, constraint complexity
\end{itemize}

\textbf{2005: DART (Godefroid) \& CUTE (Sen)} -- Concolic Execution
\begin{itemize}
    \item \textbf{Key insight}: Run concrete + symbolic \emph{simultaneously}
    \item Concrete guides symbolic; fallback when symbolic fails
    \item \textbf{Result}: Practical symbolic execution for real programs
\end{itemize}

\textbf{2008: KLEE (Cadar)} -- Scalable Symbolic Execution
\begin{itemize}
    \item LLVM bitcode as symbolic target (language-independent)
    \item Constraint solver optimizations: 95\% query reduction
    \item \textbf{Result}: 90\%+ coverage on COREUTILS, 56 bugs found
\end{itemize}

\textbf{2018: QSYM (Yun)} -- Optimistic Concolic for Hybrid Fuzzing
\begin{itemize}
    \item Native instrumentation (2--5$\times$ vs 10--100$\times$ IR interpretation)
    \item Optimistic solving: drop hard constraints, fuzzer validates
    \item \textbf{Result}: 13 new bugs in heavily-fuzzed software
\end{itemize}
\end{pillarbox}

% --------------------------------------------------
\section{Execution Tree vs CPG}
\label{sec:exec-tree-vs-cpg}

\begin{center}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{\CPG (Static)} & \textbf{Execution Tree (Dynamic)} \\
\hline
Static structure & Dynamic exploration \\
All edges exist & Forking at branches \\
No path condition & PC at each node \\
Finite & Potentially infinite \\
\hline
\end{tabular}
\end{center}

\textbf{Relationship}: Execution tree is \emph{computed from} \CPG on-demand. \CPG provides structure; execution tree provides path-sensitive state.

% --------------------------------------------------
\section{On-Demand Symbolic Execution}
\label{sec:on-demand-symex}

Unlike IFDS which merges states at join points, symbolic execution maintains \emph{path-sensitive} state by exploring each execution path separately. The key data structure is a \texttt{symbolic\_state} containing: (1) a symbolic environment mapping variables to symbolic expressions, (2) a path condition (PC) accumulating branch decisions, and (3) the current program location.

The algorithm uses a worklist of symbolic states. At each branch, it \emph{forks} into two states with extended path conditions. The SMT solver checks path feasibility: infeasible paths (unsatisfiable PC) are pruned. This approach is \emph{exact} for reachability but may not terminate due to loops.

The following code demonstrates on-demand symbolic execution from a CPG. The function \texttt{symbolic\_execute\_from\_cpg} explores paths from \texttt{entry} to \texttt{target}, returning all feasible symbolic states that reach the target. The depth bound prevents infinite exploration of loops.

\begin{fstarcode}[title={Symbolic Execution: On-Demand from CPG}]
(* We don't store the execution tree. We compute it lazily when needed
   to verify specific findings or explore specific paths. *)
val symbolic_execute_from_cpg :
  cpg:cpg ->
  entry:node_id ->
  target:node_id ->        (* Stop when we reach target *)
  max_depth:nat ->
  list symbolic_state      (* All paths that reach target *)

let symbolic_execute_from_cpg cpg entry target max_depth =
  let init = {
    env = init_symbolic_env cpg entry;
    pc = [];  (* Empty path condition *)
    stmt = entry;
    depth = 0;
  } in
  let rec explore worklist results =
    match worklist with
    | [] -> results
    | state :: rest ->
        if state.stmt = target then
          (* Reached target - add to results if path is feasible *)
          if pc_satisfiable state.pc then
            explore rest (state :: results)
          else
            explore rest results
        else if state.depth >= max_depth then
          (* Depth bound - cut off *)
          explore rest results
        else
          (* Get successors from CPG *)
          let succs = cpg_successors cpg state.stmt in
          let new_states = List.concat_map (step_symbolic state) succs in
          explore (new_states @ rest) results
  in
  explore [init] []
\end{fstarcode}

\begin{fstarcode}[title={SMT Integration for Path Feasibility}]
(* King 1976: "The symbolic execution of IF statements requires theorem
   proving which, even for modest programming languages, is mechanically
   impossible."

   REALITY: SMT solvers (Z3, CVC5) are incomplete but practical.
   We accept Unknown as a valid result. *)
type smt_result = Sat of model | Unsat | Unknown of string

val pc_satisfiable : path_condition -> bool
let pc_satisfiable pc =
  match smt_check pc with
  | Sat _ -> true
  | Unsat -> false
  | Unknown _ -> true  (* Conservatively assume satisfiable *)

val pc_implies : path_condition -> symbolic_expr -> trilean
let pc_implies pc expr =
  (* Check if pc ==> expr *)
  match smt_check (pc @ [NegAtom expr]) with
  | Unsat -> Definitely         (* pc /\ not expr is unsat ==> pc ==> expr *)
  | Sat _ -> DefinitelyNot      (* Found counterexample *)
  | Unknown _ -> Unknown        (* SMT timeout or incomplete *)
\end{fstarcode}

\begin{fstarcode}[title={Speculative Symbolic Execution Variant (SPECTECTOR)}]
(* Source: Guarnieri et al. 2020

   For detecting speculative execution vulnerabilities (Spectre), we need
   a variant that forks on BOTH branch outcomes, modeling misprediction.

   KEY DIFFERENCES from standard symbolic execution:
   1. At branches, fork on BOTH outcomes (not just feasible paths)
   2. Track speculation depth (bounded by hardware window ~200)
   3. Collect observation traces (memory accesses, jumps)
   4. Check Speculative Non-Interference (SNI) property *)

type symex_mode =
  | StandardSymex     (* Fork on feasible paths only *)
  | SpeculativeSymex  (* Fork on BOTH outcomes up to window *)

val symbolic_execute_speculative :
  cpg:cpg ->
  entry:node_id ->
  spec_window:nat ->
  list (symbolic_state * obs_trace)

let symbolic_execute_speculative cpg entry spec_window =
  let init = {
    env = init_symbolic_env cpg entry;
    pc = [];
    stmt = entry;
    depth = 0;
    spec_depth = 0;
    obs_trace = [];
  } in
  let rec explore worklist results =
    match worklist with
    | [] -> results
    | state :: rest ->
        match get_node_kind cpg state.stmt with
        | NBranch cond t_target f_target ->
            if state.spec_depth < spec_window then
              (* SPECULATIVE: fork on BOTH outcomes *)
              let obs = ObsJumpTarget state.stmt in
              let state_true = { state with
                stmt = t_target;
                obs_trace = obs :: state.obs_trace
              } in
              let state_false = { state with
                stmt = f_target;
                spec_depth = state.spec_depth + 1;
                obs_trace = obs :: state.obs_trace
              } in
              explore (state_true :: state_false :: rest) results
            else
              (* Speculation window exhausted *)
              explore rest ((state, state.obs_trace) :: results)
        | NLoad addr _ ->
            let obs = ObsMemAccess (eval_addr state addr) in
            let state' = { state with obs_trace = obs :: state.obs_trace } in
            explore (advance state' :: rest) results
        | NTerminal ->
            explore rest ((state, state.obs_trace) :: results)
        | _ ->
            explore (advance state :: rest) results
  in
  explore [init] []
\end{fstarcode}

% --------------------------------------------------
\section{Witness Generation}
\label{sec:witness-gen}

A critical capability of symbolic execution is \emph{witness generation}: converting a symbolic execution path into a concrete test case that triggers the bug. When symbolic execution finds a path to an error state, the path condition (PC) encodes exactly which inputs lead there. By asking the SMT solver for a satisfying assignment to the PC, we obtain concrete input values.

The following code defines \texttt{concrete\_witness} containing the input assignments, execution path, and final variable values. The function \texttt{generate\_witness} queries the SMT solver for a model satisfying the path condition, then extracts concrete values for all input variables. The function \texttt{confirm\_bug\_with\_witness} integrates witness generation with bug classification: manifest bugs should always yield witnesses, while latent bugs require the specified preconditions to be satisfied.

\begin{fstarcode}[title={Witness Generation: Convert Symbolic Path to Concrete Test Case}]
type concrete_witness = {
  inputs : map string int;     (* Variable assignments *)
  path : list node_id;         (* Execution path *)
  final_state : map string int; (* Final variable values *)
}

val generate_witness : symbolic_state -> option concrete_witness
let generate_witness sym_state =
  match smt_check sym_state.pc with
  | Sat model ->
      (* Extract concrete values from model *)
      let inputs = extract_input_values model sym_state.env in
      let final = instantiate_env sym_state.env model in
      Some { inputs = inputs; path = sym_state.path; final_state = final }
  | Unsat -> None
  | Unknown _ -> None

(* Integration with bug classification *)
val confirm_bug_with_witness :
  cpg:cpg -> finding:bug_classification -> option concrete_witness
let confirm_bug_with_witness cpg finding =
  match finding with
  | Manifest proof ->
      (* Manifest bugs should always have witnesses *)
      let sym_states = symbolic_execute_from_cpg cpg
                         proof.triple.entry proof.triple.error_loc 100 in
      List.find_map generate_witness sym_states
  | Latent ctx ->
      (* Latent bugs need context satisfied *)
      let sym_states = symbolic_execute_with_precond cpg ctx in
      List.find_map generate_witness sym_states
  | _ -> None
\end{fstarcode}

% --------------------------------------------------
\section{Constraint Solver Optimizations}
\label{sec:klee-optimizations}

\textbf{Source}: Cadar, Dunbar, Engler 2008 -- ``KLEE: Unassisted and Automatic Generation of High-Coverage Tests''

\begin{pillarbox}[title={KLEE Constraint Optimization: 95\% Query Reduction, 10$\times$+ Speedup}]
SMT solving is the \textbf{bottleneck} of symbolic execution. KLEE demonstrates that simple optimizations can dramatically reduce solver load:

\textbf{Optimization Stack} (in order of application):
\begin{enumerate}
    \item \textbf{Expression rewriting} -- Simplify before sending to solver
    \item \textbf{Constraint independence} -- Partition unrelated constraints
    \item \textbf{Counter-example cache} -- Reuse previous solver results
    \item \textbf{Implied value concretization} -- Extract concrete values when possible
\end{enumerate}

\textbf{Empirical Results} (from KLEE paper, Table 3):
\begin{itemize}
    \item STP queries reduced by 95\% on COREUTILS
    \item 10$\times$ speedup in overall analysis time
    \item Counter-example cache hit rate: 92--98\%
\end{itemize}
\end{pillarbox}

\begin{fstarcode}[title={Optimization 1: Expression Rewriting}]
(* Simplify symbolic expressions before sending to SMT solver.
   Many expressions simplify to constants or simpler forms. *)
val simplify_expr : symbolic_expr -> symbolic_expr
let rec simplify_expr e =
  match e with
  (* Additive identity: x + 0 = 0 + x = x *)
  | SymAdd (e1, SymConst 0) -> simplify_expr e1
  | SymAdd (SymConst 0, e2) -> simplify_expr e2

  (* Multiplicative identity: x * 1 = 1 * x = x *)
  | SymMul (e1, SymConst 1) -> simplify_expr e1
  | SymMul (SymConst 1, e2) -> simplify_expr e2

  (* Multiplicative zero: x * 0 = 0 * x = 0 *)
  | SymMul (_, SymConst 0) -> SymConst 0
  | SymMul (SymConst 0, _) -> SymConst 0

  (* Power-of-two multiplication to shift: x * 2^n = x << n *)
  | SymMul (e1, SymConst c) when is_power_of_two c ->
      SymShl (simplify_expr e1, SymConst (log2 c))

  (* Constant folding: combine adjacent constants *)
  | SymAdd (SymConst c1, SymConst c2) -> SymConst (c1 + c2)
  | SymMul (SymConst c1, SymConst c2) -> SymConst (c1 * c2)
  | SymSub (SymConst c1, SymConst c2) -> SymConst (c1 - c2)

  (* Self-subtraction: x - x = 0 *)
  | SymSub (e1, e2) when expr_equal e1 e2 -> SymConst 0

  (* Boolean simplifications *)
  | SymAnd (SymTrue, e2) -> simplify_expr e2
  | SymAnd (e1, SymTrue) -> simplify_expr e1
  | SymAnd (SymFalse, _) -> SymFalse
  | SymOr (SymTrue, _) -> SymTrue
  | SymNot (SymNot e1) -> simplify_expr e1

  (* Recursive simplification *)
  | SymAdd (e1, e2) -> SymAdd (simplify_expr e1, simplify_expr e2)
  | _ -> e
\end{fstarcode}

\begin{fstarcode}[title={Optimization 2: Constraint Independence}]
(* Partition constraints by shared variables. If constraints share no
   variables, they can be solved INDEPENDENTLY. This dramatically reduces
   solver complexity since SAT is exponential in variable count.

   KLEE INSIGHT: Most path conditions decompose into independent subsets.
   A 50-constraint problem might split into 10 independent 5-constraint
   problems --- exponentially easier to solve. *)

type constraint_set = {
  constraints : list symbolic_expr;
  variables : set var_id;
}

(* Extract variables from a symbolic expression *)
val get_variables : symbolic_expr -> set var_id
let rec get_variables e =
  match e with
  | SymVar v -> Set.singleton v
  | SymConst _ -> Set.empty
  | SymAdd (e1, e2) | SymSub (e1, e2) | SymMul (e1, e2) ->
      Set.union (get_variables e1) (get_variables e2)
  | SymIte (c, t, f) ->
      Set.union (get_variables c)
                (Set.union (get_variables t) (get_variables f))
  | SymRead (arr, idx) ->
      Set.add arr (get_variables idx)
  | _ -> Set.empty

(* Partition constraints into independent sets using union-find *)
val partition_independent : list symbolic_expr -> list constraint_set
let partition_independent constraints =
  (* Build union-find over variables *)
  let uf = UnionFind.create () in

  (* For each constraint, union all its variables together *)
  List.iter (fun c ->
    let vars = Set.to_list (get_variables c) in
    match vars with
    | [] -> ()
    | v :: rest ->
        List.iter (fun v' -> UnionFind.union uf v v') rest
  ) constraints;

  (* Group constraints by representative variable *)
  (* ... partition logic ... *)
\end{fstarcode}

\begin{fstarcode}[title={Optimization 3: Counter-Example Cache}]
(* Cache solver results and exploit subset/superset relationships:

   KEY INSIGHTS (from KLEE):
   1. If constraint set S is UNSATISFIABLE, any SUPERSET S' is also unsat
   2. If constraint set S is SATISFIABLE with model M, any SUBSET S' is
      also satisfiable (possibly with M)
   3. If S has solution M, try M on superset S' --- it might work!

   This exploits the incremental nature of symbolic execution where
   path conditions grow by adding constraints one at a time. *)

type cex_cache = {
  (* Map from constraint hash to satisfying assignment *)
  sat_cache : map constraint_hash (model * set constraint_hash);
  (* Set of unsatisfiable constraint set hashes *)
  unsat_cache : set constraint_hash;
  (* Statistics *)
  mutable hits : nat;
  mutable misses : nat;
}

val check_with_cache : cex_cache -> list symbolic_expr -> smt_result
let check_with_cache cache constraints =
  let constraint_set = Set.of_list (List.map hash_constraint constraints) in

  (* CHECK 1: Is any subset unsatisfiable? *)
  let subset_unsat = Set.exists (fun h ->
    Set.mem h cache.unsat_cache
  ) (power_set constraint_set) in
  if subset_unsat then begin
    cache.hits <- cache.hits + 1;
    Unsat
  end
  else
    (* CHECK 2: Does a superset have a solution that works? *)
    (* ... cache lookup logic ... *)

    (* CACHE MISS: Call actual SMT solver *)
    cache.misses <- cache.misses + 1;
    let result = smt_check constraints in
    (* Update cache with result *)
    result
\end{fstarcode}

\begin{fstarcode}[title={Optimization 4: Implied Value Concretization}]
(* When a constraint directly implies a variable's value, extract and
   substitute it. This reduces symbolic expression complexity.

   EXAMPLE: If path condition contains (x + 1 = 10), we can derive x = 9
   and replace all occurrences of x with concrete value 9.

   KLEE: Writes concretized values back to memory, avoiding future
   symbolic operations on those values entirely. *)

val extract_implied_values : list symbolic_expr -> map var_id int
let extract_implied_values constraints =
  List.fold_left (fun implied c ->
    match c with
    (* Direct equality: x = c *)
    | SymEq (SymVar v, SymConst c) -> Map.add v c implied
    | SymEq (SymConst c, SymVar v) -> Map.add v c implied

    (* Linear equation: x + c1 = c2 ==> x = c2 - c1 *)
    | SymEq (SymAdd (SymVar v, SymConst c1), SymConst c2) ->
        Map.add v (c2 - c1) implied

    | _ -> implied
  ) Map.empty constraints
\end{fstarcode}

% --------------------------------------------------
\section{Concolic Testing Optimizations}
\label{sec:concolic-optimizations}

\textbf{Sources}:
\begin{itemize}
    \item Godefroid, Klarlund, Sen 2005 -- ``DART: Directed Automated Random Testing'' (PLDI)
    \item Sen, Marinov, Agha 2005 -- ``CUTE: A Concolic Unit Testing Engine for C'' (ESEC/FSE)
\end{itemize}

\begin{pillarbox}[title={Concolic Execution: Concrete + Symbolic (DART/CUTE 2005)}]
\textbf{Key Insight}: Run concrete execution \emph{alongside} symbolic tracking. When symbolic reasoning becomes intractable (e.g., pointers to arrays), \textbf{substitute} concrete values and continue.

\textbf{CUTE Optimizations}:
\begin{enumerate}
    \item \textbf{Logical input map} -- Decouple memory layout from logical structure
    \item \textbf{Constraint separation} -- Pointer vs arithmetic solved \emph{separately}
    \item \textbf{Fast unsat check} -- Syntactic contradiction detection (60--95\% skip)
    \item \textbf{Incremental solving} -- Only re-solve dependent constraints
\end{enumerate}

\textbf{Empirical Results} (from CUTE paper):
\begin{itemize}
    \item Fast unsat check eliminates 60--95\% of SMT calls
    \item Common sub-constraint elimination: 64--90\% reduction
    \item Incremental solving: only 1/8 constraints re-solved on average
\end{itemize}
\end{pillarbox}

\begin{fstarcode}[title={Optimization 1: Logical Input Map}]
(* Decouples LOGICAL structure from PHYSICAL memory layout.

   Traditional approach: symbolic pointers are PHYSICAL addresses
   Problem: Address arithmetic is undecidable with arrays

   CUTE approach: logical input map I : N -> N U V
   - Maps LOGICAL addresses to values or other logical addresses
   - Pointer operations become SIMPLE equality/disequality
   - Memory allocation creates NEW logical addresses

   EXAMPLE: For input struct { int x; Node* next; }
     I = { 1 |-> 42,      // p->x = 42
           2 |-> 3,       // p->next points to logical addr 3
           3 |-> 17,      // p->next->x = 17
           4 |-> NULL }   // p->next->next = NULL *)

type logical_address = nat
type primitive_value = int

type logical_value =
  | LVPrimitive : v:primitive_value -> logical_value
  | LVPointer : addr:logical_address -> logical_value
  | LVNull : logical_value

type logical_input_map = {
  mapping : map logical_address logical_value;
  next_addr : logical_address;
  type_info : map logical_address ir_type;
}
\end{fstarcode}

\begin{fstarcode}[title={Optimization 2: Constraint Separation}]
(* CUTE separates constraints into TWO independent classes:

   POINTER CONSTRAINTS: p = q, p <> q, p = NULL, p <> NULL
     - Solved via EQUIVALENCE GRAPH (union-find + diseq edges)
     - Decidable in near-linear time
     - No SMT solver needed!

   ARITHMETIC CONSTRAINTS: linear arithmetic over integers
     - a1*x1 + a2*x2 + ... + an*xn + c <cmp> 0  where <cmp> in {=,<>,<,<=,>,>=}
     - Solved via ILP solver (lp_solve) or SMT

   KEY INSIGHT: Pointer and arithmetic constraints share NO variables
   (pointers are logical addresses, arithmetic is over values).
   They can be solved COMPLETELY INDEPENDENTLY. *)

type ptr_constraint =
  | PCEq : p1:symbolic_ptr -> p2:symbolic_ptr -> ptr_constraint
  | PCNeq : p1:symbolic_ptr -> p2:symbolic_ptr -> ptr_constraint

type arith_constraint =
  (* Linear: sum(ai * xi) + c <cmp> 0 *)
  | ACLinear : coeffs:list (int * var_id) -> constant:int ->
               cmp:comparison -> arith_constraint

type separated_constraints = {
  ptr_constraints : list ptr_constraint;
  arith_constraints : list arith_constraint;
}

(* Solve pointer constraints via equivalence graph *)
val solve_ptr_constraints : list ptr_constraint -> option (map var_id logical_address)
(* Near-linear time via union-find! *)
\end{fstarcode}

\begin{fstarcode}[title={Optimization 3: Fast Unsatisfiability Check}]
(* Before calling the SMT solver, check for SYNTACTIC contradictions.
   If we can detect unsatisfiability cheaply, skip the expensive SMT call.

   CUTE reports: 60-95% of negated constraints are syntactically unsat!

   CHECK 1: Negated constraint equals existing constraint
     Path: [x > 0, y < 5]
     Negate x > 0 to get x <= 0
     If path contains x <= 0, trivially unsat

   CHECK 2: Implied contradiction
     Path: [x = 5]
     Negate to get x <> 5
     Combined with x = 5, trivially unsat *)

val fast_unsat_check : list symbolic_expr -> symbolic_expr -> bool
let fast_unsat_check path_condition negated =
  (* CHECK 1: Is negated the negation of something in path? *)
  let syntactic_contradiction = List.exists (fun c ->
    is_negation_of c negated || is_negation_of negated c
  ) path_condition in

  if syntactic_contradiction then true
  else
    (* CHECK 2: Simple propagation for equality chains *)
    match negated with
    | SymNeq (SymVar v, SymConst c) ->
        List.exists (fun pc ->
          match pc with
          | SymEq (SymVar v', SymConst c') when v = v' && c = c' -> true
          | _ -> false
        ) path_condition
    | _ -> false
\end{fstarcode}

\begin{fstarcode}[title={Optimization 4: Incremental Solving}]
(* When we negate a constraint to explore a new path, we only need to
   re-solve the constraints that DEPEND on the changed predicate.

   DEPENDENCY: Constraint C1 depends on C2 if they share variables.

   INCREMENTAL ALGORITHM:
   1. Find constraints dependent on negated predicate
   2. Solve ONLY the dependent subset
   3. If satisfiable, try to extend old solution
   4. Only full re-solve if extension fails

   CUTE reports: On average, only 1/8 of constraints need re-solving! *)

type incremental_solver_state = {
  constraints : list symbolic_expr;
  solution : option model;
  dependency_graph : map var_id (set nat);
}

val solve_incremental :
  incremental_solver_state ->
  negated_idx:nat ->
  (incremental_solver_state * option model)
(* Try old model first, only re-solve dependent subset *)
\end{fstarcode}

% --------------------------------------------------
\section{Chopped Symbolic Execution}
\label{sec:chopped-se}

\textbf{Source}: Trabish, Mattavelli, Rinetzky, Cadar 2018 -- ``Chopped Symbolic Execution''

\begin{pillarbox}[title={Chopped Symbolic Execution: Lazy Recovery for Path Explosion}]
\textbf{The Problem}: Despite KLEE optimizations (Section~\ref{sec:klee-optimizations}), symbolic execution still suffers from exponential path explosion. Many explored paths are \emph{irrelevant} to the analysis goal.

\textbf{Example}: Hunting heap overflow in libtasn1 requires traversing 2,945 calls to 98 functions (386,727 instructions) -- most unrelated to the vulnerability.

\textbf{The Insight}: Allow \emph{skipping} irrelevant code, but don't simply ignore it. Execute skipped code \textbf{lazily} when side effects become \emph{observable}.

\textbf{Results}: 10--100$\times$ speedup over baseline KLEE on failure reproduction. CVE-2012-1569: KLEE runs out of memory; Chopper reproduces in $<$ 4 minutes.
\end{pillarbox}

\subsection{The Path Explosion Problem}

KLEE (Section~\ref{sec:klee-optimizations}) reduces \emph{constraint solving} cost. CSE addresses \emph{number of paths}:
\begin{itemize}
    \item Exponential growth: $2^N$ paths for $N$ branches
    \item Most paths are \emph{irrelevant} to analysis goal
    \item Skip irrelevant code, recover on-demand
\end{itemize}

\textbf{Complementary}: Use \emph{both} for maximum effectiveness:
\begin{enumerate}
    \item CSE to skip irrelevant code regions
    \item KLEE optimizations for constraint solving in relevant regions
\end{enumerate}

\subsection{The Four State Types}

\begin{fstarcode}[title={Chopped Symbolic Execution State Types}]
(* STATE KIND HIERARCHY:
   Normal -> [call skip] -> Snapshot created
   Normal -> [load mayMod] -> Dependent (suspended)
   Snapshot -> [recovery initiated] -> Recovery
   Recovery -> [return] -> Dependent resumes as Normal *)

type cse_state_kind =
  | CseNormal      (* Standard symbolic execution state *)
  | CseSnapshot    (* Clone saved before entering skip region *)
  | CseDependent   (* Suspended state awaiting recovery *)
  | CseRecovery    (* Executing sliced skipped function *)

type skip_entry = {
  skipped_func : func_id;
  snapshot : cse_snapshot_state;
  call_context : path_condition;
}

type cse_state = {
  store : symbolic_store;
  heap : symbolic_heap;
  pc : path_condition;
  kind : cse_state_kind;
  skipped : list skip_entry;

  (* For Dependent states *)
  snapshot_ref : option cse_snapshot_state;
  guiding_constraints : path_condition;
  dep_addr : option address;

  (* For Recovery states *)
  recovery_link : option cse_state;
  target_addr : option address;
  sliced_func : option (list ir_stmt);

  (* Optimization: track addresses written after skip *)
  overwritten_set : set address;
}
\end{fstarcode}

\paragraph{Normal States:} Standard symbolic execution state (King 1976). No special handling, code executed symbolically.

\paragraph{Snapshot States:} Clone of Normal state created \emph{before} entering skip region. Preserves complete symbolic state at call site boundary. Immutable after creation.

\paragraph{Dependent States:} Suspended Normal state that encountered a load where the address \emph{may} have been modified by a skipped function.

\paragraph{Recovery States:} State forked from Snapshot with guiding constraints, executing a \emph{statically sliced} version of skipped function to compute value at dependent load address.

\subsection{Guiding Constraints}

\textbf{Problem}: Recovery state forked from snapshot might explore paths \emph{inconsistent} with the dependent state's execution context.

\textbf{Solution}: Add path constraints accumulated \emph{since snapshot} to Recovery state.
\[
\mathsf{guiding\_constraints} = \mathsf{dependent.pc} - \mathsf{snapshot.pc}
\]
\[
\mathsf{recovery.pc} = \mathsf{snapshot.pc} \land \mathsf{guiding\_constraints}
\]

\begin{fstarcode}[title={Guiding Constraints Computation}]
val get_guiding_constraints :
  current:cse_state{current.kind = CseDependent} ->
  snapshot:cse_snapshot_state ->
  path_condition
let get_guiding_constraints current snapshot =
  (* Filter: constraints in current.pc but not in snapshot.snap_pc *)
  List.filter (fun c -> not (List.mem c snapshot.snap_pc)) current.pc
\end{fstarcode}

\subsection{The Recovery Mechanism}

\textbf{When Recovery Triggers}:
\begin{enumerate}
    \item Normal state executes load instruction
    \item $\mathsf{mayMod}(\mathsf{state}, \mathsf{state.skipped}, \mathsf{addr})$ returns true
    \item Recovery initiated for dependent load
\end{enumerate}

\textbf{May-Mod Analysis}: Uses Andersen-style pointer analysis to compute set of allocation sites each function may modify.

\textbf{Backward Slicing}: Recovery executes \emph{sliced} version of skipped function using PDG.

\begin{fstarcode}[title={Recovery State Creation}]
type recovery_result =
  | RecoveryCreated : recovery:cse_state -> recovery_result
  | RecoveryInfeasible : recovery_result

val create_recovery_state :
  dependent:cse_state{dependent.kind = CseDependent} ->
  addr:address ->
  entry:skip_entry ->
  recovery_result
let create_recovery_state dependent addr entry =
  let gc = get_guiding_constraints dependent entry.snapshot in
  let recovery_pc = concat entry.snapshot.snap_pc gc in

  (* Check feasibility: guiding constraints must not contradict snapshot *)
  if not (smt_satisfiable recovery_pc) then
    RecoveryInfeasible
  else
    let sliced = static_backward_slice entry.skipped_func addr in
    RecoveryCreated {
      store = entry.snapshot.snap_store;
      heap = entry.snapshot.snap_heap;
      pc = recovery_pc;
      kind = CseRecovery;
      skipped = entry.snapshot.snap_skipped;
      recovery_link = Some dependent;
      target_addr = Some addr;
      sliced_func = Some sliced;
      (* ... other fields ... *)
    }
\end{fstarcode}

\subsection{Correctness Properties}

\begin{theorem}[CSE Soundness]
All paths explored by CSE are feasible (satisfiable PC). Exception: Non-termination in skipped functions not detected.
\end{theorem}

\begin{theorem}[Guiding Constraints Correctness]
For all models $M$: $M \models \mathsf{recovery.pc} \Rightarrow M \models \mathsf{dependent.pc}$
\end{theorem}

\begin{theorem}[Recovery Equivalence]
After recovery completes, dependent has correct value at target address:
\[
\mathsf{lookup}(s'.\mathsf{heap}, \mathsf{addr}) = \mathsf{lookup}(s''.\mathsf{heap}, \mathsf{addr})
\]
where $s'$ is full execution and $s''$ is skip-and-recover execution.
\end{theorem}

\begin{theorem}[Relative Completeness]
For bugs not depending on skip internals, CSE will find them (assuming skipped functions terminate).
\end{theorem}

\subsection{Integration with Outcome Logic}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Aspect} & \textbf{Outcome Logic} & \textbf{Chopped SE} \\
\hline
Goal & Find bugs (under-approx) & Find bugs (directed) \\
Path selection & Witness paths to bugs & Skip irrelevant code \\
Completeness & Partial (by design) & Relative to skip regions \\
False positives & None (manifest bugs) & None (concrete execution) \\
Recovery & N/A (permanent drop) & On-demand when relevant \\
\hline
\multicolumn{3}{|c|}{\emph{Both focus on relevant paths, not exhaustive exploration}} \\
\hline
\end{tabular}
\end{center}

% --------------------------------------------------
\section{Optimistic Concolic Execution (QSYM)}
\label{sec:qsym}

\textbf{Source}: Yun, Lee, Xu, Jang, Kim 2018 -- ``QSYM: A Practical Concolic Execution Engine Tailored for Hybrid Fuzzing'' (USENIX Security)

\begin{pillarbox}[title={Optimistic Concolic Execution: 10--100$\times$ Faster via Validation-Based Soundness}]
\textbf{QSYM Key Insight}: In hybrid fuzzing, the fuzzer provides \emph{validation}. The concolic executor doesn't need to be perfectly sound -- generate candidate inputs optimistically, let the fuzzer validate them by execution.

\textbf{Scalability Wall} (why traditional concolic fails):
\begin{enumerate}
    \item Symbolic emulation overhead: IR translation (VEX/LLVM) is 10--100$\times$ slow
    \item Environment modeling: syscalls, libraries often unsupported
    \item Constraint explosion: full soundness = massive constraint sets
    \item Path explosion: even with fuzzer help, too many paths
\end{enumerate}

\textbf{QSYM Solutions}:
\begin{enumerate}
    \item Native execution with Intel Pin instrumentation (2--5$\times$ vs 10--100$\times$)
    \item Optimistic constraint solving with fuzzer validation
    \item Basic block pruning by CFG distance to targets
    \item Concrete fallback for complex operations (FP, syscalls)
\end{enumerate}

\textbf{Empirical Results}: 13 new bugs in heavily-fuzzed software (ffmpeg, OpenJPEG)
\end{pillarbox}

\begin{fstarcode}[title={Execution Models: IR Interpretation vs Native Instrumentation}]
(* Traditional (KLEE, Driller): Binary -> IR -> Interpret symbolically (SLOW)
   QSYM: Binary -> Native execution + selective instrumentation (FAST) *)

type execution_model =
  | IRInterpretation     (* KLEE-style: lift to IR, interpret symbolically *)
  | NativeInstrumented   (* QSYM-style: native exec + symbolic tracking *)
  | FullEmulation        (* S2E-style: full system emulation *)

type instrumentation_granularity =
  | AllInstructions      (* Every instruction runs symbolic *)
  | SymbolicDataOnly     (* Only when symbolic data touched - QSYM default *)
  | CFGRelevantOnly      (* Only at branch points affecting targets *)

(* QSYM instruments ONLY instructions touching symbolic data.
   Non-symbolic code runs at near-native speed. *)
\end{fstarcode}

\begin{fstarcode}[title={Optimistic Constraint Simplification}]
(* QSYM drops constraints that are expensive to solve, relying on
   the fuzzer to validate generated inputs by concrete execution. *)

type simplification_strategy =
  | DropFloatingPoint          (* FP operations are hard for SMT *)
  | DropUnmodeledCalls         (* Use return value from concrete exec *)
  | ConcreteSymbolicPointers   (* Resolve symbolic ptrs to concrete addrs *)
  | PruneDistantBlocks         (* Drop constraints from far-away code *)

let qsym_optimistic_config : optimistic_config = {
  strategies = [
    DropFloatingPoint;
    DropUnmodeledCalls;
    ConcreteSymbolicPointers;
    PruneDistantBlocks;
  ];
  max_constraint_size = 1000;
  solver_timeout_ms = 1000;     (* 1 second per query - fail fast *)
  validation_required = true;
}

val simplify_optimistically :
  config:optimistic_config ->
  constraints:list symbolic_expr ->
  concrete:concrete_state ->
  list symbolic_expr
(* Apply strategies, drop oversized constraints *)
\end{fstarcode}

\begin{fstarcode}[title={Basic Block Pruning by CFG Distance}]
(* Not all code is equally relevant. QSYM prioritizes blocks CLOSE to
   uncovered branches, pruning constraints from distant code. *)

type block_relevance = {
  cfg_distance : nat;           (* Hops to nearest uncovered branch *)
  data_flow_score : float;      (* How much data flows to branches *)
  execution_count : nat;        (* Times hit in concrete trace *)
}

val compute_block_relevance :
  cfg:cfg ->
  block:basic_block_id ->
  uncovered:set basic_block_id ->
  block_relevance

type pruning_config = {
  max_cfg_distance : nat;      (* Prune if further than this *)
  prune_unexecuted : bool;     (* Prune blocks not in concrete trace *)
}

val prune_constraints_by_distance :
  constraints:list (basic_block_id * symbolic_expr) ->
  cfg:cfg ->
  targets:set basic_block_id ->
  config:pruning_config ->
  list symbolic_expr
\end{fstarcode}

\begin{fstarcode}[title={Hybrid Fuzzing Integration}]
(* Fuzzer and concolic executor work cooperatively:
   - Fuzzer finds easy paths quickly (loose constraints)
   - Concolic solves hard constraints (tight like x == 0xdeadbeef)
   - Fuzzer validates concolic-generated inputs *)

type hybrid_result =
  | NewCoverage : inputs:list bytes -> new_blocks:set basic_block_id -> hybrid_result
  | CrashFound : input:bytes -> crash_info:crash_info -> hybrid_result
  | NoProgress : hybrid_result

val hybrid_iteration :
  program:string ->
  inputs:list bytes ->
  coverage:set basic_block_id ->
  hybrid_result

let hybrid_iteration program inputs coverage =
  (* 1. Run fuzzer for a while *)
  let (fuzz_inputs, fuzz_coverage) = run_fuzzer program inputs in

  (* 2. Find branches where fuzzer is stuck *)
  let uncovered = Set.diff (get_all_branches program) fuzz_coverage in
  let stuck = find_most_promising uncovered 5 in

  (* 3. Run optimistic concolic on stuck branches *)
  let concolic_inputs = List.concat_map (fun target ->
    let trace = get_concrete_trace program inputs target in
    let constraints = collect_path_constraints trace in
    let simplified = simplify_optimistically
                       qsym_optimistic_config constraints trace in
    match optimistic_solve simplified 1000 with
    | Sat model -> [model_to_input model]
    | _ -> []
  ) stuck in

  (* 4. Validate concolic inputs with fuzzer *)
  let validated = List.filter_map (fun input ->
    match run_with_coverage program input with
    | (cov, NormalExit) when not (Set.is_empty (Set.diff cov coverage)) ->
        Some input  (* New coverage! *)
    | (_, Crash crash) ->
        Some input  (* Crashes are valuable! *)
    | _ -> None     (* Didn't help - optimistic solving produced junk *)
  ) concolic_inputs in
  (* ... return result ... *)
\end{fstarcode}

\subsection{Soundness Model: Validation-Based}

QSYM is \emph{not} sound for path reachability (may generate invalid inputs). QSYM \emph{is} sound for bug finding: every reported crash is validated.

\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
& \textbf{Sound (KLEE)} & \textbf{Best-Effort (CUTE)} & \textbf{Optimistic (QSYM)} \\
\hline
Guarantees & Correct + Complete & Correctness & Neither (validated) \\
False positives & None & Rare & Frequent but validated away \\
Scalability & $\sim$100K LOC & Medium & Millions of LOC \\
Use case & Verification & Testing & Bug hunting \\
\hline
\end{tabular}
\end{center}

\textbf{Complementary Use}:
\begin{itemize}
    \item KLEE for small, critical components (crypto, parsers) -- proof quality
    \item QSYM for large codebases (ffmpeg, Chrome) -- bug hunting at scale
\end{itemize}

\textbf{Cross-References}:
\begin{itemize}
    \item Section~\ref{sec:klee-optimizations}: KLEE optimizations (sound -- apply first)
    \item Section~\ref{sec:concolic-optimizations}: CUTE optimizations (constraint separation)
    \item Section~\ref{sec:chopped-se}: Chopped Symbolic Execution (function-level pruning)
    \item Section~\ref{sec:ifds-eval-hybrid}: Hybrid \IFDS + Eval architecture (add fuzzer cooperation)
\end{itemize}
