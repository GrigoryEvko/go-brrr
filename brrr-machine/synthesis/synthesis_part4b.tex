% PART 4B - CONTINUATION FROM PART 4A
% Starting from Section 4.3 (Under-Approximate Analysis)
% Part 4A covered: 4.1 IFDS, 4.2 CFL-Reachability

% ==================================================
% CHAPTER: UNDER-APPROXIMATE ANALYSIS (BUG FINDING)
% ==================================================
\chapter{Under-Approximate Analysis (Bug Finding)}
\label{ch:under-approx}

\textbf{Sources}: Le et al. 2022 (ISL), Vanegue 2025 (Pulse-infinity), O'Hearn 2020

\begin{pillarbox}[title={Critical: IFDS is Over-Approximate. For Bug Finding, We Need Under-Approximation}]
\textbf{Over-Approximation} (\IFDS, Section~\ref{ch:ifds}):
\begin{itemize}
    \item Sound for \emph{absence}: ``No taint found'' means truly safe
    \item May have \textbf{false positives}: Reports bugs that don't exist
\end{itemize}

\textbf{Under-Approximation} (This chapter):
\begin{itemize}
    \item Sound for \emph{presence}: ``Bug found'' means truly a bug
    \item May have \textbf{false negatives}: Misses some bugs
\end{itemize}

\textbf{Combined}: Use \IFDS to find candidates, then under-approximation to verify.
\end{pillarbox}

% --------------------------------------------------
\section{The Eval Algorithm (Pulse/Infer)}
\label{sec:eval-algorithm}

\textbf{Paper}: Calcagno et al. 2009, 2011 (Bi-Abduction, Infer)

The Eval algorithm performs forward symbolic execution with bi-abduction to discover both bugs \emph{and} missing preconditions.

\begin{fstarcode}[title={Eval: Forward Symbolic Execution with Bi-Abduction}]
(* Unlike IFDS which propagates dataflow facts, Eval propagates
   separation logic assertions through the program. *)
type eval_state = {
  pre : assertion;      (* Discovered precondition (accumulated anti-frame) *)
  post : assertion;     (* Current symbolic state *)
  path : list node_id;  (* Execution path for witness *)
  exit : exit_condition; (* Ok or Er *)
}

val eval_stmt : eval_state -> ir_stmt -> list eval_state
(* May return multiple states for conditionals/loops *)
let eval_stmt state stmt =
  match stmt with
  | Assign (x, e) ->
      (* x := e --- update symbolic state *)
      let new_post = substitute state.post x (eval_expr e state.post) in
      [{ state with post = new_post }]

  | Load (x, ptr, field) ->
      (* x := ptr->field --- need ptr |-> {field: v} *)
      let required = points_to ptr field (fresh_var "v") in
      match biabduct state.post required with
      | None ->
          (* NULL DEREFERENCE: can't satisfy requirement *)
          [{ state with exit = Er; post = state.post `star` error "null_deref" }]
      | Some { anti_frame = m; frame = f } ->
          (* Add anti-frame to precondition, update post *)
          let state' = { state with
            pre = state.pre `star` m;
            post = f `star` (x |-> fresh_var "v");
          } in
          [state']

  | Store (ptr, field, v) ->
      (* ptr->field := v *)
      let required = points_to ptr field (fresh_var "_") in
      match biabduct state.post required with
      | None ->
          [{ state with exit = Er; post = state.post `star` error "null_deref" }]
      | Some { anti_frame = m; frame = f } ->
          [{ state with
            pre = state.pre `star` m;
            post = f `star` points_to ptr field v;
          }]

  | Free ptr ->
      (* free(ptr) --- need ptr |-> _ with UNIQUE capability *)
      let required = points_to ptr "_" (fresh_var "_") in
      match biabduct state.post required with
      | None ->
          [{ state with exit = Er; post = error "double_free_or_invalid" }]
      | Some { anti_frame = m; frame = f } ->
          (* Remove the freed memory from post *)
          [{ state with pre = state.pre `star` m; post = f }]

  | If (cond, then_branch, else_branch) ->
      (* Fork execution for both branches *)
      let then_state = { state with post = state.post `star` (cond = true) } in
      let else_state = { state with post = state.post `star` (cond = false) } in
      (* Prune infeasible paths *)
      let then_results = if sat then_state.post
                         then eval_block then_state then_branch
                         else [] in
      let else_results = if sat else_state.post
                         then eval_block else_state else_branch
                         else [] in
      then_results @ else_results

  | While (cond, body) ->
      (* UNDER-APPROXIMATE: Bounded unrolling, NOT widening *)
      eval_loop_bounded state cond body 3  (* k=3 unrollings *)

  | Call (ret, func, args) ->
      (* Use function summary if available *)
      match get_summary func with
      | Some summary ->
          apply_summary state summary args ret
      | None ->
          (* Inline or skip with havoc *)
          [{ state with post = havoc ret state.post }]
\end{fstarcode}

\begin{fstarcode}[title={Bounded Loop Unrolling (Under-Approximate)}]
(* For BUG FINDING: unroll k times, then cut off.
   This is SOUND for finding bugs: any bug found is real.
   May MISS bugs that require more iterations. *)
val eval_loop_bounded : eval_state -> ir_expr -> ir_block -> nat -> list eval_state
let eval_loop_bounded init_state cond body max_unroll =
  let rec unroll fuel state =
    if fuel = 0 then
      (* Cut off: return current state as "exited loop" *)
      [{ state with post = state.post `star` (cond = false) }]
    else
      (* Check loop condition *)
      let continue_state = { state with post = state.post `star` (cond = true) } in
      let exit_state = { state with post = state.post `star` (cond = false) } in
      let continue_results =
        if sat continue_state.post then
          let body_results = eval_block continue_state body in
          List.concat_map (fun s -> unroll (fuel - 1) s) body_results
        else []
      in
      let exit_results =
        if sat exit_state.post then [exit_state] else []
      in
      continue_results @ exit_results
  in
  unroll max_unroll init_state
\end{fstarcode}

% --------------------------------------------------
\section{ISL Triple Semantics}
\label{sec:isl-triples}

\textbf{Paper}: Le et al. 2022 -- ``Finding Real Bugs in Big Programs with ISL''

\begin{fstarcode}[title={Incorrectness Separation Logic (ISL) Triples}]
(* ISL Triple: [p] C [q; exit]
   Meaning: If execution starts in state satisfying p,
            and terminates with exit condition,
            then final state satisfies q.

   Key difference from Hoare logic:
   - Hoare: {P} C {Q} --- ALL executions from P end in Q (over-approx)
   - ISL: [p] C [q] --- SOME execution from p ends in q (under-approx) *)

(* ISL triple computed by Eval *)
val eval_to_isl_triple : cpg -> func_id -> isl_triple
let eval_to_isl_triple cpg func =
  let init_state = {
    pre = emp;  (* Start with empty precondition *)
    post = emp; (* Start with empty postcondition *)
    path = [];
    exit = Ok;
  } in
  let final_states = eval_func cpg func init_state in
  (* Collect error states *)
  let error_states = List.filter (fun s -> s.exit = Er) final_states in
  match error_states with
  | [] ->
      (* No bugs found *)
      { presumption = emp; code = func; result = emp; exit_cond = Ok }
  | errors ->
      (* Combine error states *)
      let combined_pre = List.fold_left star emp (List.map (fun s -> s.pre) errors) in
      let combined_post = List.fold_left disj bot (List.map (fun s -> s.post) errors) in
      { presumption = combined_pre;
        code = func;
        result = combined_post;
        exit_cond = Er }
\end{fstarcode}

% --------------------------------------------------
\section{Latent vs Manifest Errors}
\label{sec:latent-manifest}

\textbf{Paper}: Le, Raad, Villard, Berdine, Dreyer, O'Hearn 2022 ``Finding Real Bugs in Big Programs with ISL''

\begin{pillarbox}[title={Key Contribution: Compositional Bug Reporting via Manifest/Latent Split}]
\textbf{Problem}: ISL generates many error specs. Which to report?

\textbf{Example}: \texttt{deref(x) \{ *x = 10; \}}
\begin{itemize}
    \item ISL triple: $[\texttt{x = NULL}]\ \texttt{deref(x)}\ [\mathsf{er} : \texttt{x = NULL}]$
    \item Is this a bug? Only if called with NULL. But we don't know callers.
\end{itemize}

\textbf{Solution}: Distinguish \emph{manifest} from \emph{latent} errors.
\begin{itemize}
    \item \textbf{Manifest}: Bug reachable from ANY calling context
    \item \textbf{Latent}: Bug only reachable under specific preconditions
\end{itemize}

\textbf{Policy}: Report manifest bugs unconditionally. Use latent specs compositionally to find manifest bugs in callers.
\end{pillarbox}

\begin{definition}[Manifest Error (Le 2022, Section 3.2)]
An error triple $\models [p]\ C\ [\mathsf{er} : q]$ denotes a \textbf{manifest error} if:
\begin{enumerate}
    \item The presumption is trivial: $p \equiv \mathsf{emp} \land \mathsf{true}$
    \item The result is satisfiable: $\mathsf{sat}(q)$
    \item All heap locations in $q$ are existentially quantified (fresh)
    \item All pure constraints in $q$ are satisfiable under any valuation
\end{enumerate}

Formally, for $q = \exists X_q.\ \kappa_q \land \pi_q$:
\begin{align}
    (1) &\quad p \equiv \mathsf{emp} \land \mathsf{true} && \text{(No precondition requirements)} \\
    (2) &\quad \mathsf{sat}(q) && \text{(Error state is reachable)} \\
    (3) &\quad \mathsf{locs}(\kappa_q) \subseteq X_q && \text{(Heap is fresh, not from caller)} \\
    (4) &\quad \forall v.\ \mathsf{sat}(\pi_q[v / Y \cup \mathsf{locs}(\kappa_q)]) && \text{(Pure part always satisfiable)}
\end{align}
\end{definition}

\begin{theorem}[True Positives Property (Le 2022, Theorem 3.4)]
If procedure $f()$ in a complete program has a \textbf{manifest error}, then either:
\begin{enumerate}[label=(\alph*)]
    \item $f()$ is dead code (not reachable from \texttt{main()}), or
    \item There exists a concrete trace from \texttt{main()} to the error.
\end{enumerate}
\textbf{Consequence}: Manifest errors have 0\% false positive rate. If we report it, it's a real bug (unless dead code).
\end{theorem}

\begin{fstarcode}[title={Manifest Error Detection (Algorithmic)}]
type error_classification =
  | Manifest : error_classification      (* Report unconditionally *)
  | Latent : precondition:assertion -> error_classification  (* Report at call site *)
  | LatentLeak : error_classification    (* Report anyway - leaks are caller's fault rarely *)

val classify_error : isl_triple -> error_classification
let classify_error triple =
  match triple.exit_cond with
  | Ok -> failwith "Not an error triple"
  | Er ->
      let p = triple.presumption in
      let q = triple.result in
      (* Condition 1: Trivial presumption *)
      let trivial_pre = is_emp_and_true p in
      (* Condition 2: Satisfiable result *)
      let sat_result = sat q in
      (* Condition 3: Fresh heap locations *)
      let fresh_heap = all_locs_existentially_quantified q in
      (* Condition 4: Pure constraints satisfiable *)
      let pure_sat = pure_always_satisfiable q in

      if trivial_pre && sat_result && fresh_heap && pure_sat then
        Manifest
      else if is_memory_leak_error triple then
        LatentLeak  (* Report leaks even when latent *)
      else
        Latent triple.presumption

(* BUG REPORTING POLICY (Le 2022 Section 2.3) *)
val should_report : func_id -> isl_triple -> bool
let should_report func triple =
  match classify_error triple with
  | Manifest -> true
  | LatentLeak -> true  (* Always report leaks *)
  | Latent _ ->
      (* Report latent NPE only in main() *)
      is_main_function func && is_null_deref_error triple
\end{fstarcode}

\paragraph{Practical Results (Pulse-X tool):}

\begin{itemize}
    \item \textbf{OpenSSL-1.0.1h} (2015, 2.83M bytes IR, 8,658 procedures):
    \begin{itemize}
        \item Pulse-X: 26 bugs reported, 19 fixed (73\% fix rate)
        \item Infer: 80 bugs reported, 39 fixed (49\% fix rate)
        \item Pulse-X has \emph{higher} fix rate due to manifest filtering
    \end{itemize}
    \item \textbf{OpenSSL-3.0.0} (2021): Pulse-X found 15 new bugs, all confirmed and fixed
\end{itemize}

\begin{center}
\begin{tabular}{|l|l|}
\hline
\textbf{INFER (Over-Approximate)} & \textbf{PULSE-X (Under-Approximate)} \\
\hline
Based on separation logic & Based on ISL \\
Proves ABSENCE of bugs & Proves PRESENCE of bugs \\
Uses heuristics for reporting & Uses manifest criterion \\
May have false positives & 0\% FP for manifest bugs \\
Wider coverage (all paths) & Targeted (bounded paths) \\
Needs widening for loops & Simple bounded unrolling \\
\hline
\end{tabular}
\end{center}

% --------------------------------------------------
\section{Integration: IFDS + Eval Hybrid}
\label{sec:ifds-eval-hybrid}

\begin{figure}[h]
\centering
\begin{tikzpicture}[
    box/.style={rectangle, draw, minimum width=2.5cm, minimum height=1cm, align=center},
    arrow/.style={->, thick}
]
\node[box] (ifds) at (0,2) {Run \IFDS\\$\BigO(ED^3)$};
\node[box] (eval) at (0,0) {Run Eval\\on slice};
\node[box] (classify) at (0,-2) {Classify\\bug};

\node[right=2cm of ifds] (cand) {Candidate bugs\\(may include FPs)};
\node[right=2cm of eval] (isl) {ISL triples\\with paths};
\node[right=2cm of classify] (result) {Manifest/Latent/Refuted};

\draw[arrow] (ifds) -- (eval);
\draw[arrow] (eval) -- (classify);
\draw[arrow] (ifds) -- (cand);
\draw[arrow] (eval) -- (isl);
\draw[arrow] (classify) -- (result);
\end{tikzpicture}
\caption{Hybrid Analysis Architecture: \IFDS for fast candidate generation, Eval for precise verification}
\end{figure}

\begin{fstarcode}[title={Hybrid Analysis Implementation}]
type hybrid_result =
  | Confirmed : classification:bug_classification -> witness:list node_id -> hybrid_result
  | Refuted : reason:string -> hybrid_result
  | Timeout : partial:option eval_state -> hybrid_result

val verify_ifds_finding_with_eval :
  cpg:cpg -> finding:dataflow_fact -> timeout_ms:nat -> hybrid_result
let verify_ifds_finding_with_eval cpg finding timeout =
  (* Step 1: Compute backward slice *)
  let slice = backward_slice cpg finding.sink_node in

  (* Step 2: Run Eval on slice with timeout *)
  match eval_with_timeout slice timeout with
  | Timeout partial -> Timeout partial
  | Complete final_states ->
      (* Step 3: Check if any state confirms the finding *)
      let confirming = List.filter (confirms_finding finding) final_states in
      match confirming with
      | [] -> Refuted "Eval found no path to error"
      | states ->
          (* Step 4: Build ISL triple and classify *)
          let triple = states_to_isl_triple states in
          let classification = classify_bug triple in
          Confirmed classification (extract_witness states)
\end{fstarcode}

% ==================================================
% CHAPTER: SYMBOLIC EXECUTION (PATH-SENSITIVE)
% ==================================================
\chapter{Symbolic Execution (Path-Sensitive)}
\label{ch:symex}

\textbf{Source}: King 1976 -- ``Symbolic Execution and Program Testing''

\begin{pillarbox}[title={Symbolic Execution vs Eval vs \IFDS}]
\textbf{\IFDS} (Section~\ref{ch:ifds}):
\begin{itemize}
    \item Path-\emph{insensitive} (merges at join points)
    \item Tracks \textsc{dataflow facts} (finite domain)
    \item $\BigO(ED^3)$ complexity
\end{itemize}

\textbf{Eval} (Section~\ref{sec:eval-algorithm}):
\begin{itemize}
    \item Path-\emph{sensitive} (explores paths separately)
    \item Tracks \textsc{separation logic assertions}
    \item Bi-abduction for compositionality
\end{itemize}

\textbf{Symbolic Execution} (This chapter):
\begin{itemize}
    \item Path-\emph{sensitive} with \textbf{path condition}
    \item Tracks \textsc{symbolic values} (expressions over inputs)
    \item SMT solver for path feasibility
\end{itemize}

\textbf{Use Case Guidance}:
\begin{itemize}
    \item Taint analysis $\to$ \IFDS (fast, whole-program)
    \item Memory bugs $\to$ Eval (separation logic)
    \item Numeric bugs $\to$ Symbolic Execution (precise arithmetic)
\end{itemize}
\end{pillarbox}

\begin{pillarbox}[title={Historical Evolution: Symbolic Execution Foundations}]
\textbf{1976: King} -- Pure Symbolic Execution
\begin{itemize}
    \item Original formulation: execute with symbolic values
    \item Path conditions track branch decisions
    \item \textbf{Limitation}: Path explosion, constraint complexity
\end{itemize}

\textbf{2005: DART (Godefroid) \& CUTE (Sen)} -- Concolic Execution
\begin{itemize}
    \item \textbf{Key insight}: Run concrete + symbolic \emph{simultaneously}
    \item Concrete guides symbolic; fallback when symbolic fails
    \item \textbf{Result}: Practical symbolic execution for real programs
\end{itemize}

\textbf{2008: KLEE (Cadar)} -- Scalable Symbolic Execution
\begin{itemize}
    \item LLVM bitcode as symbolic target (language-independent)
    \item Constraint solver optimizations: 95\% query reduction
    \item \textbf{Result}: 90\%+ coverage on COREUTILS, 56 bugs found
\end{itemize}

\textbf{2018: QSYM (Yun)} -- Optimistic Concolic for Hybrid Fuzzing
\begin{itemize}
    \item Native instrumentation (2--5$\times$ vs 10--100$\times$ IR interpretation)
    \item Optimistic solving: drop hard constraints, fuzzer validates
    \item \textbf{Result}: 13 new bugs in heavily-fuzzed software
\end{itemize}
\end{pillarbox}

% --------------------------------------------------
\section{Execution Tree vs CPG}
\label{sec:exec-tree-vs-cpg}

\begin{center}
\begin{tabular}{|p{6cm}|p{6cm}|}
\hline
\textbf{\CPG (Static)} & \textbf{Execution Tree (Dynamic)} \\
\hline
Static structure & Dynamic exploration \\
All edges exist & Forking at branches \\
No path condition & PC at each node \\
Finite & Potentially infinite \\
\hline
\end{tabular}
\end{center}

\textbf{Relationship}: Execution tree is \emph{computed from} \CPG on-demand. \CPG provides structure; execution tree provides path-sensitive state.

% --------------------------------------------------
\section{On-Demand Symbolic Execution}
\label{sec:on-demand-symex}

\begin{fstarcode}[title={Symbolic Execution: On-Demand from CPG}]
(* We don't store the execution tree. We compute it lazily when needed
   to verify specific findings or explore specific paths. *)
val symbolic_execute_from_cpg :
  cpg:cpg ->
  entry:node_id ->
  target:node_id ->        (* Stop when we reach target *)
  max_depth:nat ->
  list symbolic_state      (* All paths that reach target *)

let symbolic_execute_from_cpg cpg entry target max_depth =
  let init = {
    env = init_symbolic_env cpg entry;
    pc = [];  (* Empty path condition *)
    stmt = entry;
    depth = 0;
  } in
  let rec explore worklist results =
    match worklist with
    | [] -> results
    | state :: rest ->
        if state.stmt = target then
          (* Reached target - add to results if path is feasible *)
          if pc_satisfiable state.pc then
            explore rest (state :: results)
          else
            explore rest results
        else if state.depth >= max_depth then
          (* Depth bound - cut off *)
          explore rest results
        else
          (* Get successors from CPG *)
          let succs = cpg_successors cpg state.stmt in
          let new_states = List.concat_map (step_symbolic state) succs in
          explore (new_states @ rest) results
  in
  explore [init] []
\end{fstarcode}

\begin{fstarcode}[title={SMT Integration for Path Feasibility}]
(* King 1976: "The symbolic execution of IF statements requires theorem
   proving which, even for modest programming languages, is mechanically
   impossible."

   REALITY: SMT solvers (Z3, CVC5) are incomplete but practical.
   We accept Unknown as a valid result. *)
type smt_result = Sat of model | Unsat | Unknown of string

val pc_satisfiable : path_condition -> bool
let pc_satisfiable pc =
  match smt_check pc with
  | Sat _ -> true
  | Unsat -> false
  | Unknown _ -> true  (* Conservatively assume satisfiable *)

val pc_implies : path_condition -> symbolic_expr -> trilean
let pc_implies pc expr =
  (* Check if pc ==> expr *)
  match smt_check (pc @ [NegAtom expr]) with
  | Unsat -> Definitely         (* pc /\ not expr is unsat ==> pc ==> expr *)
  | Sat _ -> DefinitelyNot      (* Found counterexample *)
  | Unknown _ -> Unknown        (* SMT timeout or incomplete *)
\end{fstarcode}

\begin{fstarcode}[title={Speculative Symbolic Execution Variant (SPECTECTOR)}]
(* Source: Guarnieri et al. 2020

   For detecting speculative execution vulnerabilities (Spectre), we need
   a variant that forks on BOTH branch outcomes, modeling misprediction.

   KEY DIFFERENCES from standard symbolic execution:
   1. At branches, fork on BOTH outcomes (not just feasible paths)
   2. Track speculation depth (bounded by hardware window ~200)
   3. Collect observation traces (memory accesses, jumps)
   4. Check Speculative Non-Interference (SNI) property *)

type symex_mode =
  | StandardSymex     (* Fork on feasible paths only *)
  | SpeculativeSymex  (* Fork on BOTH outcomes up to window *)

val symbolic_execute_speculative :
  cpg:cpg ->
  entry:node_id ->
  spec_window:nat ->
  list (symbolic_state * obs_trace)

let symbolic_execute_speculative cpg entry spec_window =
  let init = {
    env = init_symbolic_env cpg entry;
    pc = [];
    stmt = entry;
    depth = 0;
    spec_depth = 0;
    obs_trace = [];
  } in
  let rec explore worklist results =
    match worklist with
    | [] -> results
    | state :: rest ->
        match get_node_kind cpg state.stmt with
        | NBranch cond t_target f_target ->
            if state.spec_depth < spec_window then
              (* SPECULATIVE: fork on BOTH outcomes *)
              let obs = ObsJumpTarget state.stmt in
              let state_true = { state with
                stmt = t_target;
                obs_trace = obs :: state.obs_trace
              } in
              let state_false = { state with
                stmt = f_target;
                spec_depth = state.spec_depth + 1;
                obs_trace = obs :: state.obs_trace
              } in
              explore (state_true :: state_false :: rest) results
            else
              (* Speculation window exhausted *)
              explore rest ((state, state.obs_trace) :: results)
        | NLoad addr _ ->
            let obs = ObsMemAccess (eval_addr state addr) in
            let state' = { state with obs_trace = obs :: state.obs_trace } in
            explore (advance state' :: rest) results
        | NTerminal ->
            explore rest ((state, state.obs_trace) :: results)
        | _ ->
            explore (advance state :: rest) results
  in
  explore [init] []
\end{fstarcode}

% --------------------------------------------------
\section{Witness Generation}
\label{sec:witness-gen}

\begin{fstarcode}[title={Witness Generation: Convert Symbolic Path to Concrete Test Case}]
type concrete_witness = {
  inputs : map string int;     (* Variable assignments *)
  path : list node_id;         (* Execution path *)
  final_state : map string int; (* Final variable values *)
}

val generate_witness : symbolic_state -> option concrete_witness
let generate_witness sym_state =
  match smt_check sym_state.pc with
  | Sat model ->
      (* Extract concrete values from model *)
      let inputs = extract_input_values model sym_state.env in
      let final = instantiate_env sym_state.env model in
      Some { inputs = inputs; path = sym_state.path; final_state = final }
  | Unsat -> None
  | Unknown _ -> None

(* Integration with bug classification *)
val confirm_bug_with_witness :
  cpg:cpg -> finding:bug_classification -> option concrete_witness
let confirm_bug_with_witness cpg finding =
  match finding with
  | Manifest proof ->
      (* Manifest bugs should always have witnesses *)
      let sym_states = symbolic_execute_from_cpg cpg
                         proof.triple.entry proof.triple.error_loc 100 in
      List.find_map generate_witness sym_states
  | Latent ctx ->
      (* Latent bugs need context satisfied *)
      let sym_states = symbolic_execute_with_precond cpg ctx in
      List.find_map generate_witness sym_states
  | _ -> None
\end{fstarcode}

% --------------------------------------------------
\section{Constraint Solver Optimizations}
\label{sec:klee-optimizations}

\textbf{Source}: Cadar, Dunbar, Engler 2008 -- ``KLEE: Unassisted and Automatic Generation of High-Coverage Tests''

\begin{pillarbox}[title={KLEE Constraint Optimization: 95\% Query Reduction, 10$\times$+ Speedup}]
SMT solving is the \textbf{bottleneck} of symbolic execution. KLEE demonstrates that simple optimizations can dramatically reduce solver load:

\textbf{Optimization Stack} (in order of application):
\begin{enumerate}
    \item \textbf{Expression rewriting} -- Simplify before sending to solver
    \item \textbf{Constraint independence} -- Partition unrelated constraints
    \item \textbf{Counter-example cache} -- Reuse previous solver results
    \item \textbf{Implied value concretization} -- Extract concrete values when possible
\end{enumerate}

\textbf{Empirical Results} (from KLEE paper, Table 3):
\begin{itemize}
    \item STP queries reduced by 95\% on COREUTILS
    \item 10$\times$ speedup in overall analysis time
    \item Counter-example cache hit rate: 92--98\%
\end{itemize}
\end{pillarbox}

\begin{fstarcode}[title={Optimization 1: Expression Rewriting}]
(* Simplify symbolic expressions before sending to SMT solver.
   Many expressions simplify to constants or simpler forms. *)
val simplify_expr : symbolic_expr -> symbolic_expr
let rec simplify_expr e =
  match e with
  (* Additive identity: x + 0 = 0 + x = x *)
  | SymAdd (e1, SymConst 0) -> simplify_expr e1
  | SymAdd (SymConst 0, e2) -> simplify_expr e2

  (* Multiplicative identity: x * 1 = 1 * x = x *)
  | SymMul (e1, SymConst 1) -> simplify_expr e1
  | SymMul (SymConst 1, e2) -> simplify_expr e2

  (* Multiplicative zero: x * 0 = 0 * x = 0 *)
  | SymMul (_, SymConst 0) -> SymConst 0
  | SymMul (SymConst 0, _) -> SymConst 0

  (* Power-of-two multiplication to shift: x * 2^n = x << n *)
  | SymMul (e1, SymConst c) when is_power_of_two c ->
      SymShl (simplify_expr e1, SymConst (log2 c))

  (* Constant folding: combine adjacent constants *)
  | SymAdd (SymConst c1, SymConst c2) -> SymConst (c1 + c2)
  | SymMul (SymConst c1, SymConst c2) -> SymConst (c1 * c2)
  | SymSub (SymConst c1, SymConst c2) -> SymConst (c1 - c2)

  (* Self-subtraction: x - x = 0 *)
  | SymSub (e1, e2) when expr_equal e1 e2 -> SymConst 0

  (* Boolean simplifications *)
  | SymAnd (SymTrue, e2) -> simplify_expr e2
  | SymAnd (e1, SymTrue) -> simplify_expr e1
  | SymAnd (SymFalse, _) -> SymFalse
  | SymOr (SymTrue, _) -> SymTrue
  | SymNot (SymNot e1) -> simplify_expr e1

  (* Recursive simplification *)
  | SymAdd (e1, e2) -> SymAdd (simplify_expr e1, simplify_expr e2)
  | _ -> e
\end{fstarcode}

\begin{fstarcode}[title={Optimization 2: Constraint Independence}]
(* Partition constraints by shared variables. If constraints share no
   variables, they can be solved INDEPENDENTLY. This dramatically reduces
   solver complexity since SAT is exponential in variable count.

   KLEE INSIGHT: Most path conditions decompose into independent subsets.
   A 50-constraint problem might split into 10 independent 5-constraint
   problems --- exponentially easier to solve. *)

type constraint_set = {
  constraints : list symbolic_expr;
  variables : set var_id;
}

(* Extract variables from a symbolic expression *)
val get_variables : symbolic_expr -> set var_id
let rec get_variables e =
  match e with
  | SymVar v -> Set.singleton v
  | SymConst _ -> Set.empty
  | SymAdd (e1, e2) | SymSub (e1, e2) | SymMul (e1, e2) ->
      Set.union (get_variables e1) (get_variables e2)
  | SymIte (c, t, f) ->
      Set.union (get_variables c)
                (Set.union (get_variables t) (get_variables f))
  | SymRead (arr, idx) ->
      Set.add arr (get_variables idx)
  | _ -> Set.empty

(* Partition constraints into independent sets using union-find *)
val partition_independent : list symbolic_expr -> list constraint_set
let partition_independent constraints =
  (* Build union-find over variables *)
  let uf = UnionFind.create () in

  (* For each constraint, union all its variables together *)
  List.iter (fun c ->
    let vars = Set.to_list (get_variables c) in
    match vars with
    | [] -> ()
    | v :: rest ->
        List.iter (fun v' -> UnionFind.union uf v v') rest
  ) constraints;

  (* Group constraints by representative variable *)
  (* ... partition logic ... *)
\end{fstarcode}

\begin{fstarcode}[title={Optimization 3: Counter-Example Cache}]
(* Cache solver results and exploit subset/superset relationships:

   KEY INSIGHTS (from KLEE):
   1. If constraint set S is UNSATISFIABLE, any SUPERSET S' is also unsat
   2. If constraint set S is SATISFIABLE with model M, any SUBSET S' is
      also satisfiable (possibly with M)
   3. If S has solution M, try M on superset S' --- it might work!

   This exploits the incremental nature of symbolic execution where
   path conditions grow by adding constraints one at a time. *)

type cex_cache = {
  (* Map from constraint hash to satisfying assignment *)
  sat_cache : map constraint_hash (model * set constraint_hash);
  (* Set of unsatisfiable constraint set hashes *)
  unsat_cache : set constraint_hash;
  (* Statistics *)
  mutable hits : nat;
  mutable misses : nat;
}

val check_with_cache : cex_cache -> list symbolic_expr -> smt_result
let check_with_cache cache constraints =
  let constraint_set = Set.of_list (List.map hash_constraint constraints) in

  (* CHECK 1: Is any subset unsatisfiable? *)
  let subset_unsat = Set.exists (fun h ->
    Set.mem h cache.unsat_cache
  ) (power_set constraint_set) in
  if subset_unsat then begin
    cache.hits <- cache.hits + 1;
    Unsat
  end
  else
    (* CHECK 2: Does a superset have a solution that works? *)
    (* ... cache lookup logic ... *)

    (* CACHE MISS: Call actual SMT solver *)
    cache.misses <- cache.misses + 1;
    let result = smt_check constraints in
    (* Update cache with result *)
    result
\end{fstarcode}

\begin{fstarcode}[title={Optimization 4: Implied Value Concretization}]
(* When a constraint directly implies a variable's value, extract and
   substitute it. This reduces symbolic expression complexity.

   EXAMPLE: If path condition contains (x + 1 = 10), we can derive x = 9
   and replace all occurrences of x with concrete value 9.

   KLEE: Writes concretized values back to memory, avoiding future
   symbolic operations on those values entirely. *)

val extract_implied_values : list symbolic_expr -> map var_id int
let extract_implied_values constraints =
  List.fold_left (fun implied c ->
    match c with
    (* Direct equality: x = c *)
    | SymEq (SymVar v, SymConst c) -> Map.add v c implied
    | SymEq (SymConst c, SymVar v) -> Map.add v c implied

    (* Linear equation: x + c1 = c2 ==> x = c2 - c1 *)
    | SymEq (SymAdd (SymVar v, SymConst c1), SymConst c2) ->
        Map.add v (c2 - c1) implied

    | _ -> implied
  ) Map.empty constraints
\end{fstarcode}

% --------------------------------------------------
\section{Concolic Testing Optimizations}
\label{sec:concolic-optimizations}

\textbf{Sources}:
\begin{itemize}
    \item Godefroid, Klarlund, Sen 2005 -- ``DART: Directed Automated Random Testing'' (PLDI)
    \item Sen, Marinov, Agha 2005 -- ``CUTE: A Concolic Unit Testing Engine for C'' (ESEC/FSE)
\end{itemize}

\begin{pillarbox}[title={Concolic Execution: Concrete + Symbolic (DART/CUTE 2005)}]
\textbf{Key Insight}: Run concrete execution \emph{alongside} symbolic tracking. When symbolic reasoning becomes intractable (e.g., pointers to arrays), \textbf{substitute} concrete values and continue.

\textbf{CUTE Optimizations}:
\begin{enumerate}
    \item \textbf{Logical input map} -- Decouple memory layout from logical structure
    \item \textbf{Constraint separation} -- Pointer vs arithmetic solved \emph{separately}
    \item \textbf{Fast unsat check} -- Syntactic contradiction detection (60--95\% skip)
    \item \textbf{Incremental solving} -- Only re-solve dependent constraints
\end{enumerate}

\textbf{Empirical Results} (from CUTE paper):
\begin{itemize}
    \item Fast unsat check eliminates 60--95\% of SMT calls
    \item Common sub-constraint elimination: 64--90\% reduction
    \item Incremental solving: only 1/8 constraints re-solved on average
\end{itemize}
\end{pillarbox}

\begin{fstarcode}[title={Optimization 1: Logical Input Map}]
(* Decouples LOGICAL structure from PHYSICAL memory layout.

   Traditional approach: symbolic pointers are PHYSICAL addresses
   Problem: Address arithmetic is undecidable with arrays

   CUTE approach: logical input map I : N -> N U V
   - Maps LOGICAL addresses to values or other logical addresses
   - Pointer operations become SIMPLE equality/disequality
   - Memory allocation creates NEW logical addresses

   EXAMPLE: For input struct { int x; Node* next; }
     I = { 1 |-> 42,      // p->x = 42
           2 |-> 3,       // p->next points to logical addr 3
           3 |-> 17,      // p->next->x = 17
           4 |-> NULL }   // p->next->next = NULL *)

type logical_address = nat
type primitive_value = int

type logical_value =
  | LVPrimitive : v:primitive_value -> logical_value
  | LVPointer : addr:logical_address -> logical_value
  | LVNull : logical_value

type logical_input_map = {
  mapping : map logical_address logical_value;
  next_addr : logical_address;
  type_info : map logical_address ir_type;
}
\end{fstarcode}

\begin{fstarcode}[title={Optimization 2: Constraint Separation}]
(* CUTE separates constraints into TWO independent classes:

   POINTER CONSTRAINTS: p = q, p <> q, p = NULL, p <> NULL
     - Solved via EQUIVALENCE GRAPH (union-find + diseq edges)
     - Decidable in near-linear time
     - No SMT solver needed!

   ARITHMETIC CONSTRAINTS: linear arithmetic over integers
     - a1*x1 + a2*x2 + ... + an*xn + c <cmp> 0  where <cmp> in {=,<>,<,<=,>,>=}
     - Solved via ILP solver (lp_solve) or SMT

   KEY INSIGHT: Pointer and arithmetic constraints share NO variables
   (pointers are logical addresses, arithmetic is over values).
   They can be solved COMPLETELY INDEPENDENTLY. *)

type ptr_constraint =
  | PCEq : p1:symbolic_ptr -> p2:symbolic_ptr -> ptr_constraint
  | PCNeq : p1:symbolic_ptr -> p2:symbolic_ptr -> ptr_constraint

type arith_constraint =
  (* Linear: sum(ai * xi) + c <cmp> 0 *)
  | ACLinear : coeffs:list (int * var_id) -> constant:int ->
               cmp:comparison -> arith_constraint

type separated_constraints = {
  ptr_constraints : list ptr_constraint;
  arith_constraints : list arith_constraint;
}

(* Solve pointer constraints via equivalence graph *)
val solve_ptr_constraints : list ptr_constraint -> option (map var_id logical_address)
(* Near-linear time via union-find! *)
\end{fstarcode}

\begin{fstarcode}[title={Optimization 3: Fast Unsatisfiability Check}]
(* Before calling the SMT solver, check for SYNTACTIC contradictions.
   If we can detect unsatisfiability cheaply, skip the expensive SMT call.

   CUTE reports: 60-95% of negated constraints are syntactically unsat!

   CHECK 1: Negated constraint equals existing constraint
     Path: [x > 0, y < 5]
     Negate x > 0 to get x <= 0
     If path contains x <= 0, trivially unsat

   CHECK 2: Implied contradiction
     Path: [x = 5]
     Negate to get x <> 5
     Combined with x = 5, trivially unsat *)

val fast_unsat_check : list symbolic_expr -> symbolic_expr -> bool
let fast_unsat_check path_condition negated =
  (* CHECK 1: Is negated the negation of something in path? *)
  let syntactic_contradiction = List.exists (fun c ->
    is_negation_of c negated || is_negation_of negated c
  ) path_condition in

  if syntactic_contradiction then true
  else
    (* CHECK 2: Simple propagation for equality chains *)
    match negated with
    | SymNeq (SymVar v, SymConst c) ->
        List.exists (fun pc ->
          match pc with
          | SymEq (SymVar v', SymConst c') when v = v' && c = c' -> true
          | _ -> false
        ) path_condition
    | _ -> false
\end{fstarcode}

\begin{fstarcode}[title={Optimization 4: Incremental Solving}]
(* When we negate a constraint to explore a new path, we only need to
   re-solve the constraints that DEPEND on the changed predicate.

   DEPENDENCY: Constraint C1 depends on C2 if they share variables.

   INCREMENTAL ALGORITHM:
   1. Find constraints dependent on negated predicate
   2. Solve ONLY the dependent subset
   3. If satisfiable, try to extend old solution
   4. Only full re-solve if extension fails

   CUTE reports: On average, only 1/8 of constraints need re-solving! *)

type incremental_solver_state = {
  constraints : list symbolic_expr;
  solution : option model;
  dependency_graph : map var_id (set nat);
}

val solve_incremental :
  incremental_solver_state ->
  negated_idx:nat ->
  (incremental_solver_state * option model)
(* Try old model first, only re-solve dependent subset *)
\end{fstarcode}

% --------------------------------------------------
\section{Chopped Symbolic Execution}
\label{sec:chopped-se}

\textbf{Source}: Trabish, Mattavelli, Rinetzky, Cadar 2018 -- ``Chopped Symbolic Execution''

\begin{pillarbox}[title={Chopped Symbolic Execution: Lazy Recovery for Path Explosion}]
\textbf{The Problem}: Despite KLEE optimizations (Section~\ref{sec:klee-optimizations}), symbolic execution still suffers from exponential path explosion. Many explored paths are \emph{irrelevant} to the analysis goal.

\textbf{Example}: Hunting heap overflow in libtasn1 requires traversing 2,945 calls to 98 functions (386,727 instructions) -- most unrelated to the vulnerability.

\textbf{The Insight}: Allow \emph{skipping} irrelevant code, but don't simply ignore it. Execute skipped code \textbf{lazily} when side effects become \emph{observable}.

\textbf{Results}: 10--100$\times$ speedup over baseline KLEE on failure reproduction. CVE-2012-1569: KLEE runs out of memory; Chopper reproduces in $<$ 4 minutes.
\end{pillarbox}

\subsection{The Path Explosion Problem}

KLEE (Section~\ref{sec:klee-optimizations}) reduces \emph{constraint solving} cost. CSE addresses \emph{number of paths}:
\begin{itemize}
    \item Exponential growth: $2^N$ paths for $N$ branches
    \item Most paths are \emph{irrelevant} to analysis goal
    \item Skip irrelevant code, recover on-demand
\end{itemize}

\textbf{Complementary}: Use \emph{both} for maximum effectiveness:
\begin{enumerate}
    \item CSE to skip irrelevant code regions
    \item KLEE optimizations for constraint solving in relevant regions
\end{enumerate}

\subsection{The Four State Types}

\begin{fstarcode}[title={Chopped Symbolic Execution State Types}]
(* STATE KIND HIERARCHY:
   Normal -> [call skip] -> Snapshot created
   Normal -> [load mayMod] -> Dependent (suspended)
   Snapshot -> [recovery initiated] -> Recovery
   Recovery -> [return] -> Dependent resumes as Normal *)

type cse_state_kind =
  | CseNormal      (* Standard symbolic execution state *)
  | CseSnapshot    (* Clone saved before entering skip region *)
  | CseDependent   (* Suspended state awaiting recovery *)
  | CseRecovery    (* Executing sliced skipped function *)

type skip_entry = {
  skipped_func : func_id;
  snapshot : cse_snapshot_state;
  call_context : path_condition;
}

type cse_state = {
  store : symbolic_store;
  heap : symbolic_heap;
  pc : path_condition;
  kind : cse_state_kind;
  skipped : list skip_entry;

  (* For Dependent states *)
  snapshot_ref : option cse_snapshot_state;
  guiding_constraints : path_condition;
  dep_addr : option address;

  (* For Recovery states *)
  recovery_link : option cse_state;
  target_addr : option address;
  sliced_func : option (list ir_stmt);

  (* Optimization: track addresses written after skip *)
  overwritten_set : set address;
}
\end{fstarcode}

\paragraph{Normal States:} Standard symbolic execution state (King 1976). No special handling, code executed symbolically.

\paragraph{Snapshot States:} Clone of Normal state created \emph{before} entering skip region. Preserves complete symbolic state at call site boundary. Immutable after creation.

\paragraph{Dependent States:} Suspended Normal state that encountered a load where the address \emph{may} have been modified by a skipped function.

\paragraph{Recovery States:} State forked from Snapshot with guiding constraints, executing a \emph{statically sliced} version of skipped function to compute value at dependent load address.

\subsection{Guiding Constraints}

\textbf{Problem}: Recovery state forked from snapshot might explore paths \emph{inconsistent} with the dependent state's execution context.

\textbf{Solution}: Add path constraints accumulated \emph{since snapshot} to Recovery state.
\[
\mathsf{guiding\_constraints} = \mathsf{dependent.pc} - \mathsf{snapshot.pc}
\]
\[
\mathsf{recovery.pc} = \mathsf{snapshot.pc} \land \mathsf{guiding\_constraints}
\]

\begin{fstarcode}[title={Guiding Constraints Computation}]
val get_guiding_constraints :
  current:cse_state{current.kind = CseDependent} ->
  snapshot:cse_snapshot_state ->
  path_condition
let get_guiding_constraints current snapshot =
  (* Filter: constraints in current.pc but not in snapshot.snap_pc *)
  List.filter (fun c -> not (List.mem c snapshot.snap_pc)) current.pc
\end{fstarcode}

\subsection{The Recovery Mechanism}

\textbf{When Recovery Triggers}:
\begin{enumerate}
    \item Normal state executes load instruction
    \item $\mathsf{mayMod}(\mathsf{state}, \mathsf{state.skipped}, \mathsf{addr})$ returns true
    \item Recovery initiated for dependent load
\end{enumerate}

\textbf{May-Mod Analysis}: Uses Andersen-style pointer analysis to compute set of allocation sites each function may modify.

\textbf{Backward Slicing}: Recovery executes \emph{sliced} version of skipped function using PDG.

\begin{fstarcode}[title={Recovery State Creation}]
type recovery_result =
  | RecoveryCreated : recovery:cse_state -> recovery_result
  | RecoveryInfeasible : recovery_result

val create_recovery_state :
  dependent:cse_state{dependent.kind = CseDependent} ->
  addr:address ->
  entry:skip_entry ->
  recovery_result
let create_recovery_state dependent addr entry =
  let gc = get_guiding_constraints dependent entry.snapshot in
  let recovery_pc = concat entry.snapshot.snap_pc gc in

  (* Check feasibility: guiding constraints must not contradict snapshot *)
  if not (smt_satisfiable recovery_pc) then
    RecoveryInfeasible
  else
    let sliced = static_backward_slice entry.skipped_func addr in
    RecoveryCreated {
      store = entry.snapshot.snap_store;
      heap = entry.snapshot.snap_heap;
      pc = recovery_pc;
      kind = CseRecovery;
      skipped = entry.snapshot.snap_skipped;
      recovery_link = Some dependent;
      target_addr = Some addr;
      sliced_func = Some sliced;
      (* ... other fields ... *)
    }
\end{fstarcode}

\subsection{Correctness Properties}

\begin{theorem}[CSE Soundness]
All paths explored by CSE are feasible (satisfiable PC). Exception: Non-termination in skipped functions not detected.
\end{theorem}

\begin{theorem}[Guiding Constraints Correctness]
For all models $M$: $M \models \mathsf{recovery.pc} \Rightarrow M \models \mathsf{dependent.pc}$
\end{theorem}

\begin{theorem}[Recovery Equivalence]
After recovery completes, dependent has correct value at target address:
\[
\mathsf{lookup}(s'.\mathsf{heap}, \mathsf{addr}) = \mathsf{lookup}(s''.\mathsf{heap}, \mathsf{addr})
\]
where $s'$ is full execution and $s''$ is skip-and-recover execution.
\end{theorem}

\begin{theorem}[Relative Completeness]
For bugs not depending on skip internals, CSE will find them (assuming skipped functions terminate).
\end{theorem}

\subsection{Integration with Outcome Logic}

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Aspect} & \textbf{Outcome Logic} & \textbf{Chopped SE} \\
\hline
Goal & Find bugs (under-approx) & Find bugs (directed) \\
Path selection & Witness paths to bugs & Skip irrelevant code \\
Completeness & Partial (by design) & Relative to skip regions \\
False positives & None (manifest bugs) & None (concrete execution) \\
Recovery & N/A (permanent drop) & On-demand when relevant \\
\hline
\multicolumn{3}{|c|}{\emph{Both focus on relevant paths, not exhaustive exploration}} \\
\hline
\end{tabular}
\end{center}

% --------------------------------------------------
\section{Optimistic Concolic Execution (QSYM)}
\label{sec:qsym}

\textbf{Source}: Yun, Lee, Xu, Jang, Kim 2018 -- ``QSYM: A Practical Concolic Execution Engine Tailored for Hybrid Fuzzing'' (USENIX Security)

\begin{pillarbox}[title={Optimistic Concolic Execution: 10--100$\times$ Faster via Validation-Based Soundness}]
\textbf{QSYM Key Insight}: In hybrid fuzzing, the fuzzer provides \emph{validation}. The concolic executor doesn't need to be perfectly sound -- generate candidate inputs optimistically, let the fuzzer validate them by execution.

\textbf{Scalability Wall} (why traditional concolic fails):
\begin{enumerate}
    \item Symbolic emulation overhead: IR translation (VEX/LLVM) is 10--100$\times$ slow
    \item Environment modeling: syscalls, libraries often unsupported
    \item Constraint explosion: full soundness = massive constraint sets
    \item Path explosion: even with fuzzer help, too many paths
\end{enumerate}

\textbf{QSYM Solutions}:
\begin{enumerate}
    \item Native execution with Intel Pin instrumentation (2--5$\times$ vs 10--100$\times$)
    \item Optimistic constraint solving with fuzzer validation
    \item Basic block pruning by CFG distance to targets
    \item Concrete fallback for complex operations (FP, syscalls)
\end{enumerate}

\textbf{Empirical Results}: 13 new bugs in heavily-fuzzed software (ffmpeg, OpenJPEG)
\end{pillarbox}

\begin{fstarcode}[title={Execution Models: IR Interpretation vs Native Instrumentation}]
(* Traditional (KLEE, Driller): Binary -> IR -> Interpret symbolically (SLOW)
   QSYM: Binary -> Native execution + selective instrumentation (FAST) *)

type execution_model =
  | IRInterpretation     (* KLEE-style: lift to IR, interpret symbolically *)
  | NativeInstrumented   (* QSYM-style: native exec + symbolic tracking *)
  | FullEmulation        (* S2E-style: full system emulation *)

type instrumentation_granularity =
  | AllInstructions      (* Every instruction runs symbolic *)
  | SymbolicDataOnly     (* Only when symbolic data touched - QSYM default *)
  | CFGRelevantOnly      (* Only at branch points affecting targets *)

(* QSYM instruments ONLY instructions touching symbolic data.
   Non-symbolic code runs at near-native speed. *)
\end{fstarcode}

\begin{fstarcode}[title={Optimistic Constraint Simplification}]
(* QSYM drops constraints that are expensive to solve, relying on
   the fuzzer to validate generated inputs by concrete execution. *)

type simplification_strategy =
  | DropFloatingPoint          (* FP operations are hard for SMT *)
  | DropUnmodeledCalls         (* Use return value from concrete exec *)
  | ConcreteSymbolicPointers   (* Resolve symbolic ptrs to concrete addrs *)
  | PruneDistantBlocks         (* Drop constraints from far-away code *)

let qsym_optimistic_config : optimistic_config = {
  strategies = [
    DropFloatingPoint;
    DropUnmodeledCalls;
    ConcreteSymbolicPointers;
    PruneDistantBlocks;
  ];
  max_constraint_size = 1000;
  solver_timeout_ms = 1000;     (* 1 second per query - fail fast *)
  validation_required = true;
}

val simplify_optimistically :
  config:optimistic_config ->
  constraints:list symbolic_expr ->
  concrete:concrete_state ->
  list symbolic_expr
(* Apply strategies, drop oversized constraints *)
\end{fstarcode}

\begin{fstarcode}[title={Basic Block Pruning by CFG Distance}]
(* Not all code is equally relevant. QSYM prioritizes blocks CLOSE to
   uncovered branches, pruning constraints from distant code. *)

type block_relevance = {
  cfg_distance : nat;           (* Hops to nearest uncovered branch *)
  data_flow_score : float;      (* How much data flows to branches *)
  execution_count : nat;        (* Times hit in concrete trace *)
}

val compute_block_relevance :
  cfg:cfg ->
  block:basic_block_id ->
  uncovered:set basic_block_id ->
  block_relevance

type pruning_config = {
  max_cfg_distance : nat;      (* Prune if further than this *)
  prune_unexecuted : bool;     (* Prune blocks not in concrete trace *)
}

val prune_constraints_by_distance :
  constraints:list (basic_block_id * symbolic_expr) ->
  cfg:cfg ->
  targets:set basic_block_id ->
  config:pruning_config ->
  list symbolic_expr
\end{fstarcode}

\begin{fstarcode}[title={Hybrid Fuzzing Integration}]
(* Fuzzer and concolic executor work cooperatively:
   - Fuzzer finds easy paths quickly (loose constraints)
   - Concolic solves hard constraints (tight like x == 0xdeadbeef)
   - Fuzzer validates concolic-generated inputs *)

type hybrid_result =
  | NewCoverage : inputs:list bytes -> new_blocks:set basic_block_id -> hybrid_result
  | CrashFound : input:bytes -> crash_info:crash_info -> hybrid_result
  | NoProgress : hybrid_result

val hybrid_iteration :
  program:string ->
  inputs:list bytes ->
  coverage:set basic_block_id ->
  hybrid_result

let hybrid_iteration program inputs coverage =
  (* 1. Run fuzzer for a while *)
  let (fuzz_inputs, fuzz_coverage) = run_fuzzer program inputs in

  (* 2. Find branches where fuzzer is stuck *)
  let uncovered = Set.diff (get_all_branches program) fuzz_coverage in
  let stuck = find_most_promising uncovered 5 in

  (* 3. Run optimistic concolic on stuck branches *)
  let concolic_inputs = List.concat_map (fun target ->
    let trace = get_concrete_trace program inputs target in
    let constraints = collect_path_constraints trace in
    let simplified = simplify_optimistically
                       qsym_optimistic_config constraints trace in
    match optimistic_solve simplified 1000 with
    | Sat model -> [model_to_input model]
    | _ -> []
  ) stuck in

  (* 4. Validate concolic inputs with fuzzer *)
  let validated = List.filter_map (fun input ->
    match run_with_coverage program input with
    | (cov, NormalExit) when not (Set.is_empty (Set.diff cov coverage)) ->
        Some input  (* New coverage! *)
    | (_, Crash crash) ->
        Some input  (* Crashes are valuable! *)
    | _ -> None     (* Didn't help - optimistic solving produced junk *)
  ) concolic_inputs in
  (* ... return result ... *)
\end{fstarcode}

\subsection{Soundness Model: Validation-Based}

QSYM is \emph{not} sound for path reachability (may generate invalid inputs). QSYM \emph{is} sound for bug finding: every reported crash is validated.

\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
& \textbf{Sound (KLEE)} & \textbf{Best-Effort (CUTE)} & \textbf{Optimistic (QSYM)} \\
\hline
Guarantees & Correct + Complete & Correctness & Neither (validated) \\
False positives & None & Rare & Frequent but validated away \\
Scalability & $\sim$100K LOC & Medium & Millions of LOC \\
Use case & Verification & Testing & Bug hunting \\
\hline
\end{tabular}
\end{center}

\textbf{Complementary Use}:
\begin{itemize}
    \item KLEE for small, critical components (crypto, parsers) -- proof quality
    \item QSYM for large codebases (ffmpeg, Chrome) -- bug hunting at scale
\end{itemize}

\textbf{Cross-References}:
\begin{itemize}
    \item Section~\ref{sec:klee-optimizations}: KLEE optimizations (sound -- apply first)
    \item Section~\ref{sec:concolic-optimizations}: CUTE optimizations (constraint separation)
    \item Section~\ref{sec:chopped-se}: Chopped Symbolic Execution (function-level pruning)
    \item Section~\ref{sec:ifds-eval-hybrid}: Hybrid \IFDS + Eval architecture (add fuzzer cooperation)
\end{itemize}
